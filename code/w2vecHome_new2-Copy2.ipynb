{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting and preprocessing the data\n",
    "First we get the dataset online, then apply subsampling, then divide the dataset in equally long sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19 µs, sys: 0 ns, total: 19 µs\n",
      "Wall time: 26.9 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import random\n",
    "from itertools import dropwhile\n",
    "\n",
    "def sampling(dataset,threshold=1e-4, min_count=5):\n",
    "    \n",
    "    # Count occurences of each word in the dataset \n",
    "    word_counts = Counter(dataset)\n",
    "    total_count = len(dataset)\n",
    "    \n",
    "    freqs = {word: count/total_count for word, count in word_counts.items() if count>5 }\n",
    "    p_drop = {word: 1 - np.sqrt(threshold/freqs[word]) for word in word_counts if word_counts[word]>5 }\n",
    "    print(str(p_drop['the']) + ' this is a test' )\n",
    "    #train_words = [word for word in dataset if (random.random() < (1 - p_drop[word])) and word_counts[word]>min_count]\n",
    "    #del dataset\n",
    "    return p_drop\n",
    "\n",
    "\"Transforms a list of words to a list of sentences with length=len_sen\"\n",
    "def words_to_sentences(words):\n",
    "    new_ds = []\n",
    "    len_sen = int(len(words)/1700)\n",
    "    len_sen = 20\n",
    "    for i in range(0, len(words), len_sen):\n",
    "        y = [words[i:i + len_sen]]\n",
    "        new_ds.extend(y)\n",
    "    return new_ds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ENWIK9 DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5f52f981c219>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#file = open(\"./data/enwik9\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0menwik9\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0menwik9\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menwik9\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0menwik9\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msampling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menwik9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0menwik9\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwords_to_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menwik9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'file' is not defined"
     ]
    }
   ],
   "source": [
    "#file = open(\"./data/enwik9\")\n",
    "enwik9 = file.readlines()\n",
    "enwik9 = enwik9[0].split()\n",
    "enwik9 = sampling(enwik9)\n",
    "enwik9 = words_to_sentences(enwik9)\n",
    "with open(\"enwik9_sampled_1e-4_as_list\", 'wb') as output:\n",
    "    pickle.dump(enwik9, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"enwik9_sampled_1e-4_as_list\", 'rb') as output:\n",
    "        enwik9 = pickle.load(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEXT8 DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ntm\n",
      "0.9599730740166865 this is a test\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import datapath\n",
    "import gensim.downloader as api\n",
    "# Get dataset online\n",
    "dataset = api.load('text8')\n",
    "print('ntm')\n",
    "# Convert to list of words\n",
    "text8_ds = []\n",
    "for x in dataset: \n",
    "    for y in x:\n",
    "        text8_ds.append(y)\n",
    "        \n",
    "# Subsampling\n",
    "#text8_ds = sampling(text8_ds)\n",
    "\n",
    "# New dataset with sentences of length=20\n",
    "sampling_dict_text8 = sampling(text8_ds)\n",
    "\n",
    "text8_ds_min_count = []\n",
    "word_counts = Counter(text8_ds)\n",
    "for x in text8_ds: \n",
    "    if word_counts[x] > 5:\n",
    "        text8_ds_min_count.append(x)\n",
    "    \n",
    "#text8_dataset = words_to_sentences(text8_ds)\n",
    "text8_dataset = words_to_sentences(text8_ds_min_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "834030"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text8_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "421010"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text8_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17005207"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text8_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8420183"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text8_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats, spatial \n",
    "import csv, numpy as np\n",
    "from scipy.stats.stats import pearsonr\n",
    "from scipy import spatial \n",
    "#IMPORT DATA\n",
    "def get_wordsim_data():\n",
    "    wordsim_data = [] \n",
    "    with open('./data/wordsim/set1.csv', newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=' ',quotechar='|')\n",
    "        for row in reader: \n",
    "            wordsim_data.append(row[0].split(',')[0:3])\n",
    "    del wordsim_data[0]\n",
    "    with open('./data/wordsim/set2.csv', newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=' ',quotechar='|')\n",
    "        for i,row in enumerate(reader):\n",
    "            if i!=0:\n",
    "                wordsim_data.append(row[0].split(',')[0:3])\n",
    "\n",
    "    wordsim_vocab = set()\n",
    "    for x in wordsim_data:\n",
    "        wordsim_vocab.add(x[0])\n",
    "        wordsim_vocab.add(x[1])\n",
    "    return wordsim_data\n",
    "\n",
    "#len(wordsim_vocab.intersection(text8_dataset_first_sentence.vocab))\n",
    "def wordsim_task(dict_emb):\n",
    "    wordsim_data = get_wordsim_data()\n",
    "    scores = []\n",
    "    distances = []\n",
    "    for task in wordsim_data: \n",
    "        if (task[0] in dict_emb.keys() ) and (task[1] in dict_emb.keys()):\n",
    "            scores.append(float(task[2]))\n",
    "            distances.append(spatial.distance.cosine(dict_emb[task[0]], dict_emb[task[1]]))\n",
    "            \n",
    "            \n",
    "    #return stats.zscore(np.array([x[1] for x in out],dtype=float))\n",
    "    return np.corrcoef(scores,distances)\n",
    "\n",
    "#print(wordsim_task(gensim_emb))\n",
    "#wordsim_task(dict_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pdb\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "cpu = torch.device('cpu')\n",
    "gpu = torch.device(\"cuda:0\")\n",
    "\n",
    "\n",
    "class SkipGramModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, emb_dimension):\n",
    "        super(SkipGramModel, self).__init__()\n",
    "        self.emb_dimension = emb_dimension\n",
    "        self.u_embeddings = nn.Embedding(vocab_size, emb_dimension, sparse=False)\n",
    "        self.v_embeddings = nn.Embedding(vocab_size, emb_dimension, sparse=False)\n",
    "        self.init_emb()\n",
    "        \n",
    "\n",
    "    def init_emb(self):\n",
    "        initrange = 0.5 / self.emb_dimension\n",
    "        self.u_embeddings.weight.data.uniform_(-initrange, initrange)\n",
    "        self.v_embeddings.weight.data.uniform_(-0,0)\n",
    "        \n",
    "            \n",
    "    def forward(self, pos_u, pos_v,neg_v):\n",
    "        pos_u = pos_u.view(-1).to(device)\n",
    "        pos_v = pos_v.to(device)\n",
    "        neg_v = neg_v.to(device)\n",
    "        emb_u = self.u_embeddings(pos_u)\n",
    "        samples = torch.cat([pos_v,Variable(neg_v)],1)\n",
    "        emb_v = self.v_embeddings(samples)\n",
    "        score = torch.bmm(emb_v, emb_u.unsqueeze(2)).squeeze()\n",
    "        score[:,1:]=score[:,1:].neg()\n",
    "        score = F.logsigmoid(score)\n",
    "        return -1 * (torch.sum(score))/ pos_u.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "class wDataSet(Dataset):\n",
    "    def __init__(self, dataset, sampling_dict, power=0.75,ctx_window=5):\n",
    "        self.LEN_SEN =20\n",
    "        self.sampling_dict=sampling_dict\n",
    "        #assert( all(len(sentence)== self.LEN_SEN) for sentence in dataset)\n",
    "        self.ctx_window = ctx_window\n",
    "        self.dataset = dataset\n",
    "        self.word2idx = dict()\n",
    "        self.idx2word = dict()\n",
    "        self.word_count = defaultdict(int)\n",
    "        self.vocab_size = int()\n",
    "        self.vocab = set()\n",
    "        self.create_vocab()\n",
    "        self.pairs = self.generate_pairs()\n",
    "        self.key_pairs = self.generate_key_pairs(self.pairs)\n",
    "        self.power = power        \n",
    "        self.neg_table = self.make_neg_table(self.power)\n",
    "        #self.len = self.__len__()\n",
    "        self.build_pair_dict()\n",
    "        \n",
    "    \n",
    "    def build_pair_dict(self):\n",
    "        self.pair_dict = defaultdict(list)\n",
    "        for x,y in self.key_pairs:\n",
    "            self.pair_dict[x].append(y)\n",
    "            \n",
    "\n",
    "        \n",
    "    def generate_pairs(self):\n",
    "        print(\"Generating pairs\")\n",
    "        pairs = []\n",
    "        for sentence in self.dataset:\n",
    "            for i,word in enumerate(sentence):\n",
    "                if(random.random() < 1- self.sampling_dict[word]):\n",
    "                    for j in range(1,self.ctx_window+1):\n",
    "                        if(i+j<len(sentence)):\n",
    "                            pairs.append((word,sentence[i+j]))\n",
    "                        if((i-j)>=0):\n",
    "                            pairs.append((word,sentence[i-j]))\n",
    "        return pairs\n",
    "        \n",
    "    def __len__(self):          \n",
    "        len_dataset = len(self.dataset)     \n",
    "        center_pairs = ((self.LEN_SEN - self.ctx_window*2)*self.ctx_window*2) \n",
    "        border_pairs = sum([self.ctx_window + i for i in range(self.ctx_window)])*2\n",
    "        len_sen_without_last = (center_pairs + border_pairs)* (len_dataset-1)\n",
    "        \n",
    "        # The last sentence does not has the same length as the other ones, hence it's length needs to be computed otherwise\n",
    "        len_last_sen = len(self.dataset[(len_dataset-1)])\n",
    "        pairs_last_sen = 0\n",
    "        for j in range(len_last_sen):\n",
    "            if(j<self.ctx_window):\n",
    "                # Checking if the rest of the sentence is smaller then the context window\n",
    "                if(j+self.ctx_window >= len_last_sen):\n",
    "                    diff = len_last_sen - 1- j \n",
    "                    pairs_last_sen += diff\n",
    "                    pairs_last_sen += j\n",
    "                else:\n",
    "                    pairs_last_sen += (j+self.ctx_window)\n",
    "            elif( j>= len_last_sen - self.ctx_window):\n",
    "                pairs_last_sen += (len_last_sen-1-j+self.ctx_window)\n",
    "            else:\n",
    "                pairs_last_sen += (2*self.ctx_window)\n",
    "    \n",
    "        return len_sen_without_last + pairs_last_sen\n",
    "        \n",
    "        \n",
    "   \n",
    "    \n",
    "    def get_neg_samples(self, count, batch_size):\n",
    "        return torch.tensor(np.random.choice(list(self.idx2word.keys()),size=(batch_size)*count,replace=True,p=self.neg_table)).view(batch_size,-1)\n",
    "   \n",
    "    \"\"\" Defines the probability of choosing a negative sampling, set empiraccaly by mikolov\"\"\"\n",
    "    def make_neg_table(self, power):\n",
    "        pow_frequency = np.array([self.word_count[self.idx2word[i]] for i in range(len(self.word_count))])**power\n",
    "        return pow_frequency / pow_frequency.sum()\n",
    "        \n",
    "\n",
    "    def generate_key_pairs(self,pairs):\n",
    "        print(\"Generating key_pairs\")\n",
    "        key_pairs = []\n",
    "        for x,y in pairs:\n",
    "            key_pairs.append((self.word2idx.get(x),self.word2idx.get(y)))\n",
    "        print(\"finished creating key_pairs\")\n",
    "        return key_pairs\n",
    "    \n",
    "    \"\"\"\"Creating vocabulary and creating dictionary with a one to one mapping int to word\"\"\"\n",
    "    def create_vocab(self):\n",
    "        print(\"Creating vocab\")\n",
    "        for i,sentence in enumerate(self.dataset):\n",
    "            for word in sentence:\n",
    "                self.word_count[word] += 1\n",
    "                self.vocab.add(word)\n",
    "        self.word2idx = {w: idx for (idx, w) in enumerate(self.vocab)}\n",
    "        self.idx2word = {idx: w for (idx, w) in enumerate(self.vocab)}\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        \n",
    "             \n",
    "    def __getitem__(self, idx):\n",
    "        #Getting the number of pairs per sentence\n",
    "        border_pairs = sum([self.ctx_window + i for i in range(self.ctx_window)])*2\n",
    "        center_pairs = ((self.LEN_SEN - self.ctx_window*2)*self.ctx_window*2)\n",
    "        n_pairs_in_sen = border_pairs + center_pairs\n",
    "        id_sen = int(idx/n_pairs_in_sen)\n",
    "        sen  = self.dataset[id_sen]\n",
    "        pair_id_in_sen = idx - id_sen*(n_pairs_in_sen)\n",
    "        counter = 0 \n",
    "        for i,word in enumerate(sen):\n",
    "            for j in range(1,self.ctx_window+1):\n",
    "                if(i+j< len(sen)):\n",
    "                    if(counter == pair_id_in_sen):\n",
    "                        return(self.word2idx[word],self.word2idx[sen[i+j]])\n",
    "                    counter+=1\n",
    "                    \n",
    "                if(i-j>=0):\n",
    "                    if(counter == pair_id_in_sen):\n",
    "                        return(self.word2idx[word],self.word2idx[sen[i-j]])\n",
    "                    counter+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "from torch.utils.data import DataLoader\n",
    "import copy\n",
    "import time\n",
    "import numbers\n",
    "import pdb\n",
    "\n",
    "class W2V():\n",
    "    def __init__(self, data,dim=100, neg_samples=10, alpha=0.4, iterations=20, batch_size=2000, \n",
    "                 shuffle=True,use_cuda=True,workers=2,momentum=0,nesterov=False,step_size=1,gamma=1):\n",
    "        self.momentum = momentum\n",
    "        self.nesterov = nesterov\n",
    "        self.step_size = step_size\n",
    "        self.gamma = gamma\n",
    "        self.shuffle = shuffle        \n",
    "        self.batch_size = batch_size\n",
    "        self.alpha = alpha\n",
    "        self.dim = dim\n",
    "        self.data = data\n",
    "        self.workers = workers\n",
    "        self.ctxw = self.data.ctx_window\n",
    "        self.neg_samples = neg_samples\n",
    "        self.use_cuda = use_cuda\n",
    "        self.models = []\n",
    "        self.optimizers = []\n",
    "        self.ws_list = []\n",
    "        self.loss_list = []\n",
    "        self.model = SkipGramModel(len(self.data.vocab), self.dim)\n",
    "        self.model.to(device)\n",
    "    \n",
    "        print(device)\n",
    "        #self.optimizer = torch.optim.SGD(self.model.parameters(), lr=alpha, momentum=momentum,nesterov=nesterov)\n",
    "        #self.scheduler = StepLR(self.optimizer, step_size=step_size, gamma=gamma)\n",
    "        #self.optimizer = torch.optim.Adagrad(self.model.parameters(), lr=alpha)\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(),lr=alpha)\n",
    "\n",
    "\n",
    "        self.iterations = iterations\n",
    " \n",
    "    def train_with_loader(self,save_embedding=True):\n",
    "        loader = DataLoader(self.data.key_pairs, self.batch_size, self.shuffle, num_workers=self.workers)\n",
    "        print('starting training')\n",
    "       \n",
    "\n",
    "        self.time=0\n",
    "        no_improvement = 0\n",
    "        best_score = -1\n",
    "        prev_score = -1\n",
    "        \n",
    "        \n",
    "        max_key = max(ds.pair_dict, key= lambda x: len(set(ds.pair_dict[x])))\n",
    "        max_value = len(self.data.pair_dict[max_key])\n",
    "        fifth = int(max_value/10)\n",
    "        \n",
    "        for epoch in range(self.iterations):\n",
    "\n",
    "            percent = 0\n",
    "            start = time.time()\n",
    "            processed_batches = 0 \n",
    "            pairs = 0\n",
    "            cum_loss = 0 \n",
    "            avg_loss =0\n",
    "            best_loss = 10 \n",
    "            \n",
    "\n",
    "            for i in range(max_value):\n",
    "                pos_v = []\n",
    "                pos_u = []\n",
    "                for x,y in ds.pair_dict.items():\n",
    "                    if(len(y)>i):\n",
    "                        pos_v.append(y[i])\n",
    "                        pos_u.append(x)\n",
    "                if(i>102):\n",
    "                        break\n",
    "                pos_v = torch.tensor(pos_v)\n",
    "                pos_u = torch.tensor(pos_u)\n",
    "                print(\"batch_size = \" + str(len(pos_v)) + \" || processed_batches = \" + str(i) + \"/\" + str(max_value),end =\"\\r\")\n",
    "                \n",
    "                if(i%fifth == 0 ):\n",
    "                    end = time.time()\n",
    "                    hours, rem = divmod(end-start, 3600)\n",
    "                    minutes, seconds = divmod(rem, 60)\n",
    "                    time_since_start = \"Time:  {:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds)\n",
    "                    if(processed_batches!=0):\n",
    "                        avg_loss = cum_loss / processed_batches\n",
    "                    print(\"0%\" + \"=\" *(int(percent/10))+ str(percent) +\"%, \" + time_since_start + \", cum_loss = {}\".format(cum_loss),end=\"\\r\" )\n",
    "                    percent+=5\n",
    "                    \n",
    "                neg_v = self.data.get_neg_samples(self.neg_samples,pos_v.size()[0])\n",
    "                pos_v = pos_v.view(len(neg_v),-1)\n",
    "                self.optimizer.zero_grad()\n",
    "                loss = self.model.forward(pos_u,pos_v,neg_v)\n",
    "                cum_loss += loss\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                pairs += len(pos_u)\n",
    "                processed_batches += 1\n",
    "                \n",
    "            print(\"\\n{0:d} epoch of {1:d}\".format(epoch+1, self.iterations))\n",
    "            avg_loss = cum_loss / processed_batches\n",
    "            print(\" {0:d} {1:d} batches, pairs {2:d}, cum loss: {3:.5f}\".format(i,processed_batches, pairs,cum_loss))\n",
    "            self.loss_list.append(cum_loss)\n",
    "            self.time = time_since_start\n",
    "            self.model = self.model.to(cpu)\n",
    "            score = -1*(wordsim_task(self.get_embedding())[0][1])\n",
    "            if(score < best_score):\n",
    "                best_score = score\n",
    "            print(\"Current score on wordsim Task: {}\".format(score))\n",
    "            self.ws_list.append(score)\n",
    "            self.model = self.model.to(gpu)\n",
    "            \n",
    "        \n",
    "            \n",
    "            prev_score = score \n",
    "        \n",
    "        if(save_embedding):\n",
    "            self.save_embedding()\n",
    "            \n",
    "\n",
    "    def get_embedding(self):\n",
    "        embedding_dict = dict()\n",
    "        embedding = self.model.u_embeddings.weight.data.numpy()\n",
    "        for i in range(len(self.data.idx2word)):\n",
    "            embedding_dict[self.data.idx2word[i]]= embedding[i]\n",
    "        return embedding_dict\n",
    "    \n",
    "    def save_embedding(self, with_loss=True):\n",
    "        print('ntm')\n",
    "        # Creating filename\n",
    "        optim = \"Optim\" + str(self.optimizer).split(\" \")[0] + \"_\"\n",
    "        filename = \"dict_emb_\" +  optim + \"_\".join([x + str(y) for x,y in vars(self).items() if isinstance(y, numbers.Number)]) + \".pkl\"\n",
    "        \n",
    "        # Getting Embedding\n",
    "        self.model.to(torch.device('cpu'))\n",
    "        dict_emb = w2v.get_embedding()\n",
    "        \n",
    "        # Adding loss history to embedding\n",
    "        dict_emb['loss_list'] = [x.to(torch.device('cpu')) for x in self.loss_list]\n",
    "        \n",
    "        # Adding score list to embedding \n",
    "        dict_emb['ws_list'] = self.ws_list\n",
    "        \n",
    "                \n",
    "        # Saving time spent to calculate 1 epoch\n",
    "        dict_emb['time'] = self.time\n",
    "        \n",
    "        # Logging\n",
    "        print(\"Saving embedding: {} to disk with ws_score: {} \".format(filename,dict_emb['ws_list']))\n",
    "    \n",
    "        # Writing embedding dictionnary to disk\n",
    "        with open(filename, 'wb') as output:\n",
    "            pickle.dump(dict_emb, output, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "        self.model.to(device)\n",
    "        self.loss_list = [x.to(device) for x in self.loss_list]\n",
    "    \n",
    " \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating vocab\n",
      "Generating pairs\n",
      "Generating key_pairs\n",
      "finished creating key_pairs\n"
     ]
    }
   ],
   "source": [
    "# Snippet to test changes on very small dataset\n",
    "ds = wDataSet(text8_dataset,sampling_dict_text8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141785090"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds.pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('anarchism', 'originated'),\n",
       " ('anarchism', 'as'),\n",
       " ('anarchism', 'a'),\n",
       " ('anarchism', 'term'),\n",
       " ('anarchism', 'of'),\n",
       " ('originated', 'as'),\n",
       " ('originated', 'anarchism'),\n",
       " ('originated', 'a'),\n",
       " ('originated', 'term'),\n",
       " ('originated', 'of'),\n",
       " ('originated', 'abuse'),\n",
       " ('as', 'a'),\n",
       " ('as', 'originated'),\n",
       " ('as', 'term'),\n",
       " ('as', 'anarchism'),\n",
       " ('as', 'of'),\n",
       " ('as', 'abuse'),\n",
       " ('as', 'first'),\n",
       " ('a', 'term'),\n",
       " ('a', 'as')]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.pairs[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('anarchism', 'originated'),\n",
       " ('anarchism', 'term'),\n",
       " ('anarchism', 'abuse'),\n",
       " ('anarchism', 'first'),\n",
       " ('anarchism', 'against'),\n",
       " ('originated', 'term'),\n",
       " ('originated', 'anarchism'),\n",
       " ('originated', 'abuse'),\n",
       " ('originated', 'first'),\n",
       " ('originated', 'against'),\n",
       " ('originated', 'early'),\n",
       " ('term', 'abuse'),\n",
       " ('term', 'originated'),\n",
       " ('term', 'first'),\n",
       " ('term', 'anarchism'),\n",
       " ('term', 'against'),\n",
       " ('term', 'early'),\n",
       " ('term', 'working'),\n",
       " ('abuse', 'first'),\n",
       " ('abuse', 'term')]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.pairs[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('anarchism', 'originated'),\n",
       " ('anarchism', 'as'),\n",
       " ('anarchism', 'a'),\n",
       " ('anarchism', 'term'),\n",
       " ('anarchism', 'of'),\n",
       " ('originated', 'as'),\n",
       " ('originated', 'anarchism'),\n",
       " ('originated', 'a'),\n",
       " ('originated', 'term'),\n",
       " ('originated', 'of'),\n",
       " ('originated', 'abuse'),\n",
       " ('term', 'of'),\n",
       " ('term', 'a'),\n",
       " ('term', 'abuse'),\n",
       " ('term', 'as'),\n",
       " ('term', 'first'),\n",
       " ('term', 'originated'),\n",
       " ('term', 'used'),\n",
       " ('term', 'anarchism'),\n",
       " ('term', 'against')]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.pairs[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71582962"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds.pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed_batches = 26951/360354\r"
     ]
    }
   ],
   "source": [
    "max_key = max(ds.pair_dict, key= lambda x: len(set(ds.pair_dict[x])))\n",
    "max_value = len(ds.pair_dict[max_key])\n",
    "batch_sizes = []\n",
    "for i in range(max_value):\n",
    "    bs = 0\n",
    "    for x,y in ds.pair_dict.items():\n",
    "        if(len(y)>i):\n",
    "            bs += 1\n",
    "    batch_sizes.append(bs)\n",
    "    print(\"processed_batches = \" + str(i) + \"/\" + str(max_value),end =\"\\r\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating vocab\n",
      "Generating pairs\n",
      "Generating key_pairs\n",
      "finished creating key_pairs\n"
     ]
    }
   ],
   "source": [
    "ds_with_sampling = wDataSet(text8_dataset,sampling_dict_text8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "starting training\n",
      "batch_size = 41392 || processed_batches = 102/360354\n",
      "1 epoch of 20\n",
      " 103 103 batches, pairs 8559121, cum loss: 427.60349\n",
      "Current score on wordsim Task: -0.01710125339880773\n",
      "batch_size = 41392 || processed_batches = 102/360354\n",
      "2 epoch of 20\n",
      " 103 103 batches, pairs 8559121, cum loss: 320.75479\n",
      "Current score on wordsim Task: 0.1159693797483314\n",
      "batch_size = 41392 || processed_batches = 102/360354\n",
      "3 epoch of 20\n",
      " 103 103 batches, pairs 8559121, cum loss: 299.71411\n",
      "Current score on wordsim Task: 0.20457110777390974\n",
      "batch_size = 41392 || processed_batches = 102/360354\n",
      "4 epoch of 20\n",
      " 103 103 batches, pairs 8559121, cum loss: 273.33902\n",
      "Current score on wordsim Task: 0.2443001314824141\n",
      "batch_size = 41392 || processed_batches = 102/360354\n",
      "5 epoch of 20\n",
      " 103 103 batches, pairs 8559121, cum loss: 243.42413\n",
      "Current score on wordsim Task: 0.25635244924099315\n",
      "batch_size = 41392 || processed_batches = 102/360354\n",
      "6 epoch of 20\n",
      " 103 103 batches, pairs 8559121, cum loss: 216.39835\n",
      "Current score on wordsim Task: 0.2714187450384755\n",
      "batch_size = 41392 || processed_batches = 102/360354\n",
      "7 epoch of 20\n",
      " 103 103 batches, pairs 8559121, cum loss: 195.97974\n",
      "Current score on wordsim Task: 0.28121768495378396\n",
      "batch_size = 41392 || processed_batches = 102/360354\n",
      "8 epoch of 20\n",
      " 103 103 batches, pairs 8559121, cum loss: 181.92715\n",
      "Current score on wordsim Task: 0.2852828070886074\n",
      "batch_size = 41392 || processed_batches = 102/360354\n",
      "9 epoch of 20\n",
      " 103 103 batches, pairs 8559121, cum loss: 172.32507\n",
      "Current score on wordsim Task: 0.27660177704532035\n",
      "batch_size = 41392 || processed_batches = 102/360354\n",
      "10 epoch of 20\n",
      " 103 103 batches, pairs 8559121, cum loss: 165.62958\n",
      "Current score on wordsim Task: 0.28006524360138213\n",
      "batch_size = 41392 || processed_batches = 102/360354\n",
      "11 epoch of 20\n",
      " 103 103 batches, pairs 8559121, cum loss: 160.75473\n",
      "Current score on wordsim Task: 0.2627403962599051\n",
      "batch_size = 41392 || processed_batches = 102/360354\n",
      "12 epoch of 20\n",
      " 103 103 batches, pairs 8559121, cum loss: 157.11815\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-903ebd37691c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#3qtr+1.5iqr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mw2v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mW2V\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.007\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mw2v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_with_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-62e83f9643de>\u001b[0m in \u001b[0;36mtrain_with_loader\u001b[0;34m(self, save_embedding)\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_since_start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwordsim_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0mbest_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-e03b37d75d0d>\u001b[0m in \u001b[0;36mwordsim_task\u001b[0;34m(dict_emb)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdict_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdict_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mdistances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspatial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_emb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_emb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/skg/lib/python3.7/site-packages/scipy/spatial/distance.py\u001b[0m in \u001b[0;36mcosine\u001b[0;34m(u, v, w)\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;31m# cosine distance is also referred to as 'uncentered correlation',\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;31m#   or 'reflective correlation'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcorrelation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcentered\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/skg/lib/python3.7/site-packages/scipy/spatial/distance.py\u001b[0m in \u001b[0;36mcorrelation\u001b[0;34m(u, v, w, centered)\u001b[0m\n\u001b[1;32m    693\u001b[0m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mumu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mvmu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m     \u001b[0muv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    696\u001b[0m     \u001b[0muu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m     \u001b[0mvv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/skg/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36maverage\u001b[0;34m(a, axis, weights, returned)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mavg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m         \u001b[0mscl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mavg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/skg/lib/python3.7/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mrcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mrcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mrcount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#3qtr+1.5iqr\n",
    "w2v = W2V(ds, neg_samples=10, alpha=0.007,shuffle=True)\n",
    "w2v.train_with_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_lists = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "for x,y in ds.pair_dict.items():\n",
    "     len_lists.append((len(y)))\n",
    "len_lists.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ds_with_sampling' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-f3acb6d7a21c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstatistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlen_lists_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mds_with_sampling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpair_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m      \u001b[0mlen_lists_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlen_lists_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ds_with_sampling' is not defined"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "len_lists_s = []\n",
    "for x,y in ds_with_sampling.pair_dict.items():\n",
    "     len_lists_s.append((len(y)))\n",
    "len_lists_s.sort()\n",
    "print((len_lists_s[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean = 2227.8890966515296\n",
      "median = 166\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'statistics' has no attribute 'min'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-123-93ef5e02e02d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"mean = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatistics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen_lists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"median = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatistics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen_lists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"minimum = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatistics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen_lists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'statistics' has no attribute 'min'"
     ]
    }
   ],
   "source": [
    "print( \"mean = \" + str(statistics.mean(len_lists)))\n",
    "print( \"median = \" + str(statistics.median(len_lists)))\n",
    "print( \"minimum = \" + str(statistics.min(len_lists)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "small = [x for x in len_lists if x<102.5]\n",
    "large = [x for x in len_lists if x >= 102.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41392\n",
      "212462\n",
      "4295745\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "70032984"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(large))\n",
    "print(len(small))\n",
    "print(np.sum(np.array(small)))\n",
    "np.sum(np.array(large))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92917296"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "55748945+37168351"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55750623"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.sum(np.array(len_lists[0:253351]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55750623"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.array(len_lists[0:253351]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31820.5"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(len_lists)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9021243"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(len_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([79., 34.]), array([ 533., 1214.])]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[item.get_ydata() for item in B['whiskers']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'whiskers': [<matplotlib.lines.Line2D at 0x7f0fb4f9deb8>,\n",
       "  <matplotlib.lines.Line2D at 0x7f0fb61999e8>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0x7f0fb6204320>,\n",
       "  <matplotlib.lines.Line2D at 0x7f0fb625b860>],\n",
       " 'boxes': [<matplotlib.lines.Line2D at 0x7f0fb610b6d8>],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0x7f0fb63bfef0>],\n",
       " 'fliers': [<matplotlib.lines.Line2D at 0x7f0fb6491e48>],\n",
       " 'means': []}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = [5,10]\n",
    "plt.yscale('log')\n",
    "plt.title('Box plot showing the distribution of the number of pairs per context word, w/ online subsampling')\n",
    "plt.ylabel('Number of pairs', fontsize=16)\n",
    "B = plt.boxplot(len_lists)\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5\n",
      "9402 5\n",
      "18804 6\n",
      "28206 7\n",
      "37608 8\n",
      "47010 8\n",
      "56412 9\n",
      "65814 10\n",
      "75216 10\n",
      "84618 10\n",
      "94020 10\n",
      "103422 10\n",
      "112824 10\n",
      "122226 14\n",
      "131628 16\n",
      "141030 18\n",
      "150432 20\n",
      "159834 25\n",
      "169236 29\n",
      "178638 35\n",
      "188040 45\n",
      "197442 58\n",
      "206844 81\n",
      "216246 122\n",
      "225648 205\n",
      "235050 410\n",
      "244452 1169\n"
     ]
    }
   ],
   "source": [
    "l = []\n",
    "for i in range(0,253854,9402):\n",
    "    print(i,len_lists[i])\n",
    "    l.append(len_lists[i])\n",
    "l.append(len_lists[253853])\n",
    "#print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "360354"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_lists[253853]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5\n",
      "100 5\n",
      "200 5\n",
      "300 5\n",
      "400 5\n",
      "500 5\n",
      "600 5\n",
      "700 5\n",
      "800 5\n",
      "900 5\n",
      "1000 5\n",
      "1100 5\n",
      "1200 5\n",
      "1300 5\n",
      "1400 5\n",
      "1500 5\n",
      "1600 5\n",
      "1700 5\n",
      "1800 5\n",
      "1900 5\n",
      "2000 5\n",
      "2100 5\n",
      "2200 5\n",
      "2300 5\n",
      "2400 5\n",
      "2500 5\n",
      "2600 5\n",
      "2700 5\n",
      "2800 5\n",
      "2900 5\n",
      "3000 5\n",
      "3100 5\n",
      "3200 5\n",
      "3300 5\n",
      "3400 5\n",
      "3500 5\n",
      "3600 5\n",
      "3700 5\n",
      "3800 5\n",
      "3900 5\n",
      "4000 5\n",
      "4100 5\n",
      "4200 5\n",
      "4300 5\n",
      "4400 5\n",
      "4500 5\n",
      "4600 5\n",
      "4700 5\n",
      "4800 5\n",
      "4900 5\n",
      "5000 5\n",
      "5100 5\n",
      "5200 5\n",
      "5300 5\n",
      "5400 5\n",
      "5500 5\n",
      "5600 5\n",
      "5700 5\n",
      "5800 5\n",
      "5900 5\n",
      "6000 5\n",
      "6100 5\n",
      "6200 5\n",
      "6300 5\n",
      "6400 5\n",
      "6500 5\n",
      "6600 5\n",
      "6700 5\n",
      "6800 5\n",
      "6900 5\n",
      "7000 5\n",
      "7100 5\n",
      "7200 5\n",
      "7300 5\n",
      "7400 5\n",
      "7500 5\n",
      "7600 5\n",
      "7700 5\n",
      "7800 5\n",
      "7900 5\n",
      "8000 5\n",
      "8100 5\n",
      "8200 5\n",
      "8300 5\n",
      "8400 5\n",
      "8500 5\n",
      "8600 5\n",
      "8700 5\n",
      "8800 5\n",
      "8900 5\n",
      "9000 5\n",
      "9100 5\n",
      "9200 5\n",
      "9300 5\n",
      "9400 5\n",
      "9500 5\n",
      "9600 5\n",
      "9700 5\n",
      "9800 5\n",
      "9900 5\n",
      "10000 5\n",
      "10100 5\n",
      "10200 5\n",
      "10300 5\n",
      "10400 5\n",
      "10500 5\n",
      "10600 5\n",
      "10700 5\n",
      "10800 5\n",
      "10900 5\n",
      "11000 5\n",
      "11100 5\n",
      "11200 5\n",
      "11300 5\n",
      "11400 5\n",
      "11500 5\n",
      "11600 5\n",
      "11700 5\n",
      "11800 5\n",
      "11900 6\n",
      "12000 6\n",
      "12100 6\n",
      "12200 6\n",
      "12300 6\n",
      "12400 6\n",
      "12500 6\n",
      "12600 6\n",
      "12700 6\n",
      "12800 6\n",
      "12900 6\n",
      "13000 6\n",
      "13100 6\n",
      "13200 6\n",
      "13300 6\n",
      "13400 6\n",
      "13500 6\n",
      "13600 6\n",
      "13700 6\n",
      "13800 6\n",
      "13900 6\n",
      "14000 6\n",
      "14100 6\n",
      "14200 6\n",
      "14300 6\n",
      "14400 6\n",
      "14500 6\n",
      "14600 6\n",
      "14700 6\n",
      "14800 6\n",
      "14900 6\n",
      "15000 6\n",
      "15100 6\n",
      "15200 6\n",
      "15300 6\n",
      "15400 6\n",
      "15500 6\n",
      "15600 6\n",
      "15700 6\n",
      "15800 6\n",
      "15900 6\n",
      "16000 6\n",
      "16100 6\n",
      "16200 6\n",
      "16300 6\n",
      "16400 6\n",
      "16500 6\n",
      "16600 6\n",
      "16700 6\n",
      "16800 6\n",
      "16900 6\n",
      "17000 6\n",
      "17100 6\n",
      "17200 6\n",
      "17300 6\n",
      "17400 6\n",
      "17500 6\n",
      "17600 6\n",
      "17700 6\n",
      "17800 6\n",
      "17900 6\n",
      "18000 6\n",
      "18100 6\n",
      "18200 6\n",
      "18300 6\n",
      "18400 6\n",
      "18500 6\n",
      "18600 6\n",
      "18700 6\n",
      "18800 6\n",
      "18900 6\n",
      "19000 6\n",
      "19100 6\n",
      "19200 6\n",
      "19300 6\n",
      "19400 6\n",
      "19500 6\n",
      "19600 6\n",
      "19700 6\n",
      "19800 6\n",
      "19900 6\n",
      "20000 6\n",
      "20100 6\n",
      "20200 6\n",
      "20300 6\n",
      "20400 6\n",
      "20500 6\n",
      "20600 6\n",
      "20700 6\n",
      "20800 6\n",
      "20900 6\n",
      "21000 6\n",
      "21100 6\n",
      "21200 6\n",
      "21300 6\n",
      "21400 6\n",
      "21500 6\n",
      "21600 6\n",
      "21700 6\n",
      "21800 6\n",
      "21900 6\n",
      "22000 6\n",
      "22100 6\n",
      "22200 6\n",
      "22300 6\n",
      "22400 6\n",
      "22500 6\n",
      "22600 6\n",
      "22700 6\n",
      "22800 6\n",
      "22900 6\n",
      "23000 6\n",
      "23100 6\n",
      "23200 6\n",
      "23300 6\n",
      "23400 6\n",
      "23500 6\n",
      "23600 6\n",
      "23700 7\n",
      "23800 7\n",
      "23900 7\n",
      "24000 7\n",
      "24100 7\n",
      "24200 7\n",
      "24300 7\n",
      "24400 7\n",
      "24500 7\n",
      "24600 7\n",
      "24700 7\n",
      "24800 7\n",
      "24900 7\n",
      "25000 7\n",
      "25100 7\n",
      "25200 7\n",
      "25300 7\n",
      "25400 7\n",
      "25500 7\n",
      "25600 7\n",
      "25700 7\n",
      "25800 7\n",
      "25900 7\n",
      "26000 7\n",
      "26100 7\n",
      "26200 7\n",
      "26300 7\n",
      "26400 7\n",
      "26500 7\n",
      "26600 7\n",
      "26700 7\n",
      "26800 7\n",
      "26900 7\n",
      "27000 7\n",
      "27100 7\n",
      "27200 7\n",
      "27300 7\n",
      "27400 7\n",
      "27500 7\n",
      "27600 7\n",
      "27700 7\n",
      "27800 7\n",
      "27900 7\n",
      "28000 7\n",
      "28100 7\n",
      "28200 7\n",
      "28300 7\n",
      "28400 7\n",
      "28500 7\n",
      "28600 7\n",
      "28700 7\n",
      "28800 7\n",
      "28900 7\n",
      "29000 7\n",
      "29100 7\n",
      "29200 7\n",
      "29300 7\n",
      "29400 7\n",
      "29500 7\n",
      "29600 7\n",
      "29700 7\n",
      "29800 7\n",
      "29900 7\n",
      "30000 7\n",
      "30100 7\n",
      "30200 7\n",
      "30300 7\n",
      "30400 7\n",
      "30500 7\n",
      "30600 7\n",
      "30700 7\n",
      "30800 7\n",
      "30900 7\n",
      "31000 7\n",
      "31100 7\n",
      "31200 7\n",
      "31300 7\n",
      "31400 7\n",
      "31500 7\n",
      "31600 7\n",
      "31700 7\n",
      "31800 7\n",
      "31900 7\n",
      "32000 7\n",
      "32100 7\n",
      "32200 7\n",
      "32300 7\n",
      "32400 7\n",
      "32500 7\n",
      "32600 7\n",
      "32700 7\n",
      "32800 7\n",
      "32900 7\n",
      "33000 7\n",
      "33100 7\n",
      "33200 7\n",
      "33300 7\n",
      "33400 7\n",
      "33500 7\n",
      "33600 7\n",
      "33700 7\n",
      "33800 7\n",
      "33900 7\n",
      "34000 7\n",
      "34100 7\n",
      "34200 7\n",
      "34300 7\n",
      "34400 7\n",
      "34500 7\n",
      "34600 7\n",
      "34700 7\n",
      "34800 7\n",
      "34900 7\n",
      "35000 7\n",
      "35100 7\n",
      "35200 7\n",
      "35300 7\n",
      "35400 7\n",
      "35500 7\n",
      "35600 7\n",
      "35700 8\n",
      "35800 8\n",
      "35900 8\n",
      "36000 8\n",
      "36100 8\n",
      "36200 8\n",
      "36300 8\n",
      "36400 8\n",
      "36500 8\n",
      "36600 8\n",
      "36700 8\n",
      "36800 8\n",
      "36900 8\n",
      "37000 8\n",
      "37100 8\n",
      "37200 8\n",
      "37300 8\n",
      "37400 8\n",
      "37500 8\n",
      "37600 8\n",
      "37700 8\n",
      "37800 8\n",
      "37900 8\n",
      "38000 8\n",
      "38100 8\n",
      "38200 8\n",
      "38300 8\n",
      "38400 8\n",
      "38500 8\n",
      "38600 8\n",
      "38700 8\n",
      "38800 8\n",
      "38900 8\n",
      "39000 8\n",
      "39100 8\n",
      "39200 8\n",
      "39300 8\n",
      "39400 8\n",
      "39500 8\n",
      "39600 8\n",
      "39700 8\n",
      "39800 8\n",
      "39900 8\n",
      "40000 8\n",
      "40100 8\n",
      "40200 8\n",
      "40300 8\n",
      "40400 8\n",
      "40500 8\n",
      "40600 8\n",
      "40700 8\n",
      "40800 8\n",
      "40900 8\n",
      "41000 8\n",
      "41100 8\n",
      "41200 8\n",
      "41300 8\n",
      "41400 8\n",
      "41500 8\n",
      "41600 8\n",
      "41700 8\n",
      "41800 8\n",
      "41900 8\n",
      "42000 8\n",
      "42100 8\n",
      "42200 8\n",
      "42300 8\n",
      "42400 8\n",
      "42500 8\n",
      "42600 8\n",
      "42700 8\n",
      "42800 8\n",
      "42900 8\n",
      "43000 8\n",
      "43100 8\n",
      "43200 8\n",
      "43300 8\n",
      "43400 8\n",
      "43500 8\n",
      "43600 8\n",
      "43700 8\n",
      "43800 8\n",
      "43900 8\n",
      "44000 8\n",
      "44100 8\n",
      "44200 8\n",
      "44300 8\n",
      "44400 8\n",
      "44500 8\n",
      "44600 8\n",
      "44700 8\n",
      "44800 8\n",
      "44900 8\n",
      "45000 8\n",
      "45100 8\n",
      "45200 8\n",
      "45300 8\n",
      "45400 8\n",
      "45500 8\n",
      "45600 8\n",
      "45700 8\n",
      "45800 8\n",
      "45900 8\n",
      "46000 8\n",
      "46100 8\n",
      "46200 8\n",
      "46300 8\n",
      "46400 8\n",
      "46500 8\n",
      "46600 8\n",
      "46700 8\n",
      "46800 8\n",
      "46900 8\n",
      "47000 8\n",
      "47100 8\n",
      "47200 8\n",
      "47300 8\n",
      "47400 8\n",
      "47500 8\n",
      "47600 9\n",
      "47700 9\n",
      "47800 9\n",
      "47900 9\n",
      "48000 9\n",
      "48100 9\n",
      "48200 9\n",
      "48300 9\n",
      "48400 9\n",
      "48500 9\n",
      "48600 9\n",
      "48700 9\n",
      "48800 9\n",
      "48900 9\n",
      "49000 9\n",
      "49100 9\n",
      "49200 9\n",
      "49300 9\n",
      "49400 9\n",
      "49500 9\n",
      "49600 9\n",
      "49700 9\n",
      "49800 9\n",
      "49900 9\n",
      "50000 9\n",
      "50100 9\n",
      "50200 9\n",
      "50300 9\n",
      "50400 9\n",
      "50500 9\n",
      "50600 9\n",
      "50700 9\n",
      "50800 9\n",
      "50900 9\n",
      "51000 9\n",
      "51100 9\n",
      "51200 9\n",
      "51300 9\n",
      "51400 9\n",
      "51500 9\n",
      "51600 9\n",
      "51700 9\n",
      "51800 9\n",
      "51900 9\n",
      "52000 9\n",
      "52100 9\n",
      "52200 9\n",
      "52300 9\n",
      "52400 9\n",
      "52500 9\n",
      "52600 9\n",
      "52700 9\n",
      "52800 9\n",
      "52900 9\n",
      "53000 9\n",
      "53100 9\n",
      "53200 9\n",
      "53300 9\n",
      "53400 9\n",
      "53500 9\n",
      "53600 9\n",
      "53700 9\n",
      "53800 9\n",
      "53900 9\n",
      "54000 9\n",
      "54100 9\n",
      "54200 9\n",
      "54300 9\n",
      "54400 9\n",
      "54500 9\n",
      "54600 9\n",
      "54700 9\n",
      "54800 9\n",
      "54900 9\n",
      "55000 9\n",
      "55100 9\n",
      "55200 9\n",
      "55300 9\n",
      "55400 9\n",
      "55500 9\n",
      "55600 9\n",
      "55700 9\n",
      "55800 9\n",
      "55900 9\n",
      "56000 9\n",
      "56100 9\n",
      "56200 9\n",
      "56300 9\n",
      "56400 9\n",
      "56500 9\n",
      "56600 9\n",
      "56700 9\n",
      "56800 9\n",
      "56900 9\n",
      "57000 9\n",
      "57100 9\n",
      "57200 9\n",
      "57300 9\n",
      "57400 9\n",
      "57500 9\n",
      "57600 9\n",
      "57700 9\n",
      "57800 9\n",
      "57900 9\n",
      "58000 9\n",
      "58100 9\n",
      "58200 9\n",
      "58300 9\n",
      "58400 9\n",
      "58500 9\n",
      "58600 9\n",
      "58700 9\n",
      "58800 9\n",
      "58900 9\n",
      "59000 9\n",
      "59100 9\n",
      "59200 9\n",
      "59300 10\n",
      "59400 10\n",
      "59500 10\n",
      "59600 10\n",
      "59700 10\n",
      "59800 10\n",
      "59900 10\n",
      "60000 10\n",
      "60100 10\n",
      "60200 10\n",
      "60300 10\n",
      "60400 10\n",
      "60500 10\n",
      "60600 10\n",
      "60700 10\n",
      "60800 10\n",
      "60900 10\n",
      "61000 10\n",
      "61100 10\n",
      "61200 10\n",
      "61300 10\n",
      "61400 10\n",
      "61500 10\n",
      "61600 10\n",
      "61700 10\n",
      "61800 10\n",
      "61900 10\n",
      "62000 10\n",
      "62100 10\n",
      "62200 10\n",
      "62300 10\n",
      "62400 10\n",
      "62500 10\n",
      "62600 10\n",
      "62700 10\n",
      "62800 10\n",
      "62900 10\n",
      "63000 10\n",
      "63100 10\n",
      "63200 10\n",
      "63300 10\n",
      "63400 10\n",
      "63500 10\n",
      "63600 10\n",
      "63700 10\n",
      "63800 10\n",
      "63900 10\n",
      "64000 10\n",
      "64100 10\n",
      "64200 10\n",
      "64300 10\n",
      "64400 10\n",
      "64500 10\n",
      "64600 10\n",
      "64700 10\n",
      "64800 10\n",
      "64900 10\n",
      "65000 10\n",
      "65100 10\n",
      "65200 10\n",
      "65300 10\n",
      "65400 10\n",
      "65500 10\n",
      "65600 10\n",
      "65700 10\n",
      "65800 10\n",
      "65900 10\n",
      "66000 10\n",
      "66100 10\n",
      "66200 10\n",
      "66300 10\n",
      "66400 10\n",
      "66500 10\n",
      "66600 10\n",
      "66700 10\n",
      "66800 10\n",
      "66900 10\n",
      "67000 10\n",
      "67100 10\n",
      "67200 10\n",
      "67300 10\n",
      "67400 10\n",
      "67500 10\n",
      "67600 10\n",
      "67700 10\n",
      "67800 10\n",
      "67900 10\n",
      "68000 10\n",
      "68100 10\n",
      "68200 10\n",
      "68300 10\n",
      "68400 10\n",
      "68500 10\n",
      "68600 10\n",
      "68700 10\n",
      "68800 10\n",
      "68900 10\n",
      "69000 10\n",
      "69100 10\n",
      "69200 10\n",
      "69300 10\n",
      "69400 10\n",
      "69500 10\n",
      "69600 10\n",
      "69700 10\n",
      "69800 10\n",
      "69900 10\n",
      "70000 10\n",
      "70100 10\n",
      "70200 10\n",
      "70300 10\n",
      "70400 10\n",
      "70500 10\n",
      "70600 10\n",
      "70700 10\n",
      "70800 10\n",
      "70900 10\n",
      "71000 10\n",
      "71100 10\n",
      "71200 10\n",
      "71300 10\n",
      "71400 10\n",
      "71500 10\n",
      "71600 10\n",
      "71700 10\n",
      "71800 10\n",
      "71900 10\n",
      "72000 10\n",
      "72100 10\n",
      "72200 10\n",
      "72300 10\n",
      "72400 10\n",
      "72500 10\n",
      "72600 10\n",
      "72700 10\n",
      "72800 10\n",
      "72900 10\n",
      "73000 10\n",
      "73100 10\n",
      "73200 10\n",
      "73300 10\n",
      "73400 10\n",
      "73500 10\n",
      "73600 10\n",
      "73700 10\n",
      "73800 10\n",
      "73900 10\n",
      "74000 10\n",
      "74100 10\n",
      "74200 10\n",
      "74300 10\n",
      "74400 10\n",
      "74500 10\n",
      "74600 10\n",
      "74700 10\n",
      "74800 10\n",
      "74900 10\n",
      "75000 10\n",
      "75100 10\n",
      "75200 10\n",
      "75300 10\n",
      "75400 10\n",
      "75500 10\n",
      "75600 10\n",
      "75700 10\n",
      "75800 10\n",
      "75900 10\n",
      "76000 10\n",
      "76100 10\n",
      "76200 10\n",
      "76300 10\n",
      "76400 10\n",
      "76500 10\n",
      "76600 10\n",
      "76700 10\n",
      "76800 10\n",
      "76900 10\n",
      "77000 10\n",
      "77100 10\n",
      "77200 10\n",
      "77300 10\n",
      "77400 10\n",
      "77500 10\n",
      "77600 10\n",
      "77700 10\n",
      "77800 10\n",
      "77900 10\n",
      "78000 10\n",
      "78100 10\n",
      "78200 10\n",
      "78300 10\n",
      "78400 10\n",
      "78500 10\n",
      "78600 10\n",
      "78700 10\n",
      "78800 10\n",
      "78900 10\n",
      "79000 10\n",
      "79100 10\n",
      "79200 10\n",
      "79300 10\n",
      "79400 10\n",
      "79500 10\n",
      "79600 10\n",
      "79700 10\n",
      "79800 10\n",
      "79900 10\n",
      "80000 10\n",
      "80100 10\n",
      "80200 10\n",
      "80300 10\n",
      "80400 10\n",
      "80500 10\n",
      "80600 10\n",
      "80700 10\n",
      "80800 10\n",
      "80900 10\n",
      "81000 10\n",
      "81100 10\n",
      "81200 10\n",
      "81300 10\n",
      "81400 10\n",
      "81500 10\n",
      "81600 10\n",
      "81700 10\n",
      "81800 10\n",
      "81900 10\n",
      "82000 10\n",
      "82100 10\n",
      "82200 10\n",
      "82300 10\n",
      "82400 10\n",
      "82500 10\n",
      "82600 10\n",
      "82700 10\n",
      "82800 10\n",
      "82900 10\n",
      "83000 10\n",
      "83100 10\n",
      "83200 10\n",
      "83300 10\n",
      "83400 10\n",
      "83500 10\n",
      "83600 10\n",
      "83700 10\n",
      "83800 10\n",
      "83900 10\n",
      "84000 10\n",
      "84100 10\n",
      "84200 10\n",
      "84300 10\n",
      "84400 10\n",
      "84500 10\n",
      "84600 10\n",
      "84700 10\n",
      "84800 10\n",
      "84900 10\n",
      "85000 10\n",
      "85100 10\n",
      "85200 10\n",
      "85300 10\n",
      "85400 10\n",
      "85500 10\n",
      "85600 10\n",
      "85700 10\n",
      "85800 10\n",
      "85900 10\n",
      "86000 10\n",
      "86100 10\n",
      "86200 10\n",
      "86300 10\n",
      "86400 10\n",
      "86500 10\n",
      "86600 10\n",
      "86700 10\n",
      "86800 10\n",
      "86900 10\n",
      "87000 10\n",
      "87100 10\n",
      "87200 10\n",
      "87300 10\n",
      "87400 10\n",
      "87500 10\n",
      "87600 10\n",
      "87700 10\n",
      "87800 10\n",
      "87900 10\n",
      "88000 10\n",
      "88100 10\n",
      "88200 10\n",
      "88300 10\n",
      "88400 10\n",
      "88500 10\n",
      "88600 10\n",
      "88700 10\n",
      "88800 10\n",
      "88900 10\n",
      "89000 10\n",
      "89100 10\n",
      "89200 10\n",
      "89300 10\n",
      "89400 10\n",
      "89500 10\n",
      "89600 10\n",
      "89700 10\n",
      "89800 10\n",
      "89900 10\n",
      "90000 10\n",
      "90100 10\n",
      "90200 10\n",
      "90300 10\n",
      "90400 10\n",
      "90500 10\n",
      "90600 10\n",
      "90700 10\n",
      "90800 10\n",
      "90900 10\n",
      "91000 10\n",
      "91100 10\n",
      "91200 10\n",
      "91300 10\n",
      "91400 10\n",
      "91500 10\n",
      "91600 10\n",
      "91700 10\n",
      "91800 10\n",
      "91900 10\n",
      "92000 10\n",
      "92100 10\n",
      "92200 10\n",
      "92300 10\n",
      "92400 10\n",
      "92500 10\n",
      "92600 10\n",
      "92700 10\n",
      "92800 10\n",
      "92900 10\n",
      "93000 10\n",
      "93100 10\n",
      "93200 10\n",
      "93300 10\n",
      "93400 10\n",
      "93500 10\n",
      "93600 10\n",
      "93700 10\n",
      "93800 10\n",
      "93900 10\n",
      "94000 10\n",
      "94100 10\n",
      "94200 10\n",
      "94300 10\n",
      "94400 10\n",
      "94500 10\n",
      "94600 10\n",
      "94700 10\n",
      "94800 10\n",
      "94900 10\n",
      "95000 10\n",
      "95100 10\n",
      "95200 10\n",
      "95300 10\n",
      "95400 10\n",
      "95500 10\n",
      "95600 10\n",
      "95700 10\n",
      "95800 10\n",
      "95900 10\n",
      "96000 10\n",
      "96100 10\n",
      "96200 10\n",
      "96300 10\n",
      "96400 10\n",
      "96500 10\n",
      "96600 10\n",
      "96700 10\n",
      "96800 10\n",
      "96900 10\n",
      "97000 10\n",
      "97100 10\n",
      "97200 10\n",
      "97300 10\n",
      "97400 10\n",
      "97500 10\n",
      "97600 10\n",
      "97700 10\n",
      "97800 10\n",
      "97900 10\n",
      "98000 10\n",
      "98100 10\n",
      "98200 10\n",
      "98300 10\n",
      "98400 10\n",
      "98500 10\n",
      "98600 10\n",
      "98700 10\n",
      "98800 10\n",
      "98900 10\n",
      "99000 10\n",
      "99100 10\n",
      "99200 10\n",
      "99300 10\n",
      "99400 10\n",
      "99500 10\n",
      "99600 10\n",
      "99700 10\n",
      "99800 10\n",
      "99900 10\n",
      "100000 10\n",
      "100100 10\n",
      "100200 10\n",
      "100300 10\n",
      "100400 10\n",
      "100500 10\n",
      "100600 10\n",
      "100700 10\n",
      "100800 10\n",
      "100900 10\n",
      "101000 10\n",
      "101100 10\n",
      "101200 10\n",
      "101300 10\n",
      "101400 10\n",
      "101500 10\n",
      "101600 10\n",
      "101700 10\n",
      "101800 10\n",
      "101900 10\n",
      "102000 10\n",
      "102100 10\n",
      "102200 10\n",
      "102300 10\n",
      "102400 10\n",
      "102500 10\n",
      "102600 10\n",
      "102700 10\n",
      "102800 10\n",
      "102900 10\n",
      "103000 10\n",
      "103100 10\n",
      "103200 10\n",
      "103300 10\n",
      "103400 10\n",
      "103500 10\n",
      "103600 10\n",
      "103700 10\n",
      "103800 10\n",
      "103900 10\n",
      "104000 10\n",
      "104100 10\n",
      "104200 10\n",
      "104300 10\n",
      "104400 10\n",
      "104500 10\n",
      "104600 10\n",
      "104700 10\n",
      "104800 10\n",
      "104900 10\n",
      "105000 10\n",
      "105100 10\n",
      "105200 10\n",
      "105300 10\n",
      "105400 10\n",
      "105500 10\n",
      "105600 10\n",
      "105700 10\n",
      "105800 10\n",
      "105900 10\n",
      "106000 10\n",
      "106100 10\n",
      "106200 10\n",
      "106300 10\n",
      "106400 10\n",
      "106500 10\n",
      "106600 10\n",
      "106700 10\n",
      "106800 10\n",
      "106900 10\n",
      "107000 10\n",
      "107100 10\n",
      "107200 10\n",
      "107300 10\n",
      "107400 10\n",
      "107500 10\n",
      "107600 10\n",
      "107700 10\n",
      "107800 10\n",
      "107900 10\n",
      "108000 10\n",
      "108100 10\n",
      "108200 10\n",
      "108300 10\n",
      "108400 10\n",
      "108500 10\n",
      "108600 10\n",
      "108700 10\n",
      "108800 10\n",
      "108900 10\n",
      "109000 10\n",
      "109100 10\n",
      "109200 10\n",
      "109300 10\n",
      "109400 10\n",
      "109500 10\n",
      "109600 10\n",
      "109700 10\n",
      "109800 10\n",
      "109900 10\n",
      "110000 10\n",
      "110100 10\n",
      "110200 10\n",
      "110300 10\n",
      "110400 10\n",
      "110500 10\n",
      "110600 10\n",
      "110700 10\n",
      "110800 10\n",
      "110900 10\n",
      "111000 10\n",
      "111100 10\n",
      "111200 10\n",
      "111300 10\n",
      "111400 10\n",
      "111500 10\n",
      "111600 10\n",
      "111700 10\n",
      "111800 10\n",
      "111900 10\n",
      "112000 10\n",
      "112100 10\n",
      "112200 10\n",
      "112300 10\n",
      "112400 10\n",
      "112500 10\n",
      "112600 10\n",
      "112700 10\n",
      "112800 10\n",
      "112900 10\n",
      "113000 10\n",
      "113100 10\n",
      "113200 10\n",
      "113300 10\n",
      "113400 10\n",
      "113500 10\n",
      "113600 10\n",
      "113700 10\n",
      "113800 10\n",
      "113900 10\n",
      "114000 10\n",
      "114100 10\n",
      "114200 10\n",
      "114300 10\n",
      "114400 10\n",
      "114500 10\n",
      "114600 10\n",
      "114700 10\n",
      "114800 10\n",
      "114900 10\n",
      "115000 10\n",
      "115100 10\n",
      "115200 10\n",
      "115300 10\n",
      "115400 10\n",
      "115500 10\n",
      "115600 10\n",
      "115700 10\n",
      "115800 10\n",
      "115900 10\n",
      "116000 10\n",
      "116100 10\n",
      "116200 10\n",
      "116300 10\n",
      "116400 10\n",
      "116500 10\n",
      "116600 10\n",
      "116700 10\n",
      "116800 10\n",
      "116900 10\n",
      "117000 10\n",
      "117100 10\n",
      "117200 10\n",
      "117300 10\n",
      "117400 10\n",
      "117500 10\n",
      "117600 10\n",
      "117700 10\n",
      "117800 10\n",
      "117900 10\n",
      "118000 10\n",
      "118100 10\n",
      "118200 10\n",
      "118300 10\n",
      "118400 10\n",
      "118500 10\n",
      "118600 10\n",
      "118700 10\n",
      "118800 10\n",
      "118900 11\n",
      "119000 11\n",
      "119100 11\n",
      "119200 11\n",
      "119300 11\n",
      "119400 11\n",
      "119500 11\n",
      "119600 12\n",
      "119700 12\n",
      "119800 12\n",
      "119900 12\n",
      "120000 12\n",
      "120100 12\n",
      "120200 12\n",
      "120300 12\n",
      "120400 12\n",
      "120500 12\n",
      "120600 12\n",
      "120700 13\n",
      "120800 13\n",
      "120900 13\n",
      "121000 13\n",
      "121100 13\n",
      "121200 13\n",
      "121300 13\n",
      "121400 13\n",
      "121500 13\n",
      "121600 13\n",
      "121700 13\n",
      "121800 13\n",
      "121900 13\n",
      "122000 13\n",
      "122100 14\n",
      "122200 14\n",
      "122300 14\n",
      "122400 14\n",
      "122500 14\n",
      "122600 14\n",
      "122700 14\n",
      "122800 14\n",
      "122900 14\n",
      "123000 14\n",
      "123100 14\n",
      "123200 14\n",
      "123300 14\n",
      "123400 14\n",
      "123500 14\n",
      "123600 14\n",
      "123700 14\n",
      "123800 14\n",
      "123900 15\n",
      "124000 15\n",
      "124100 15\n",
      "124200 15\n",
      "124300 15\n",
      "124400 15\n",
      "124500 15\n",
      "124600 15\n",
      "124700 15\n",
      "124800 15\n",
      "124900 15\n",
      "125000 15\n",
      "125100 15\n",
      "125200 15\n",
      "125300 15\n",
      "125400 15\n",
      "125500 15\n",
      "125600 15\n",
      "125700 15\n",
      "125800 15\n",
      "125900 15\n",
      "126000 15\n",
      "126100 15\n",
      "126200 15\n",
      "126300 15\n",
      "126400 15\n",
      "126500 15\n",
      "126600 15\n",
      "126700 15\n",
      "126800 15\n",
      "126900 15\n",
      "127000 15\n",
      "127100 15\n",
      "127200 15\n",
      "127300 15\n",
      "127400 15\n",
      "127500 15\n",
      "127600 15\n",
      "127700 15\n",
      "127800 15\n",
      "127900 15\n",
      "128000 15\n",
      "128100 15\n",
      "128200 15\n",
      "128300 15\n",
      "128400 15\n",
      "128500 15\n",
      "128600 15\n",
      "128700 15\n",
      "128800 15\n",
      "128900 16\n",
      "129000 16\n",
      "129100 16\n",
      "129200 16\n",
      "129300 16\n",
      "129400 16\n",
      "129500 16\n",
      "129600 16\n",
      "129700 16\n",
      "129800 16\n",
      "129900 16\n",
      "130000 16\n",
      "130100 16\n",
      "130200 16\n",
      "130300 16\n",
      "130400 16\n",
      "130500 16\n",
      "130600 16\n",
      "130700 16\n",
      "130800 16\n",
      "130900 16\n",
      "131000 16\n",
      "131100 16\n",
      "131200 16\n",
      "131300 16\n",
      "131400 16\n",
      "131500 16\n",
      "131600 16\n",
      "131700 16\n",
      "131800 16\n",
      "131900 16\n",
      "132000 16\n",
      "132100 16\n",
      "132200 16\n",
      "132300 16\n",
      "132400 16\n",
      "132500 16\n",
      "132600 16\n",
      "132700 16\n",
      "132800 16\n",
      "132900 16\n",
      "133000 16\n",
      "133100 16\n",
      "133200 16\n",
      "133300 16\n",
      "133400 16\n",
      "133500 17\n",
      "133600 17\n",
      "133700 17\n",
      "133800 17\n",
      "133900 17\n",
      "134000 17\n",
      "134100 17\n",
      "134200 17\n",
      "134300 17\n",
      "134400 17\n",
      "134500 17\n",
      "134600 17\n",
      "134700 17\n",
      "134800 17\n",
      "134900 17\n",
      "135000 17\n",
      "135100 17\n",
      "135200 17\n",
      "135300 17\n",
      "135400 17\n",
      "135500 17\n",
      "135600 17\n",
      "135700 17\n",
      "135800 17\n",
      "135900 17\n",
      "136000 17\n",
      "136100 17\n",
      "136200 17\n",
      "136300 17\n",
      "136400 17\n",
      "136500 17\n",
      "136600 17\n",
      "136700 17\n",
      "136800 17\n",
      "136900 17\n",
      "137000 17\n",
      "137100 17\n",
      "137200 17\n",
      "137300 17\n",
      "137400 17\n",
      "137500 17\n",
      "137600 17\n",
      "137700 18\n",
      "137800 18\n",
      "137900 18\n",
      "138000 18\n",
      "138100 18\n",
      "138200 18\n",
      "138300 18\n",
      "138400 18\n",
      "138500 18\n",
      "138600 18\n",
      "138700 18\n",
      "138800 18\n",
      "138900 18\n",
      "139000 18\n",
      "139100 18\n",
      "139200 18\n",
      "139300 18\n",
      "139400 18\n",
      "139500 18\n",
      "139600 18\n",
      "139700 18\n",
      "139800 18\n",
      "139900 18\n",
      "140000 18\n",
      "140100 18\n",
      "140200 18\n",
      "140300 18\n",
      "140400 18\n",
      "140500 18\n",
      "140600 18\n",
      "140700 18\n",
      "140800 18\n",
      "140900 18\n",
      "141000 18\n",
      "141100 18\n",
      "141200 18\n",
      "141300 18\n",
      "141400 18\n",
      "141500 18\n",
      "141600 18\n",
      "141700 18\n",
      "141800 19\n",
      "141900 19\n",
      "142000 19\n",
      "142100 19\n",
      "142200 19\n",
      "142300 19\n",
      "142400 19\n",
      "142500 19\n",
      "142600 19\n",
      "142700 19\n",
      "142800 19\n",
      "142900 19\n",
      "143000 19\n",
      "143100 19\n",
      "143200 19\n",
      "143300 19\n",
      "143400 19\n",
      "143500 19\n",
      "143600 19\n",
      "143700 19\n",
      "143800 19\n",
      "143900 19\n",
      "144000 19\n",
      "144100 19\n",
      "144200 19\n",
      "144300 19\n",
      "144400 19\n",
      "144500 19\n",
      "144600 19\n",
      "144700 19\n",
      "144800 19\n",
      "144900 19\n",
      "145000 19\n",
      "145100 19\n",
      "145200 19\n",
      "145300 19\n",
      "145400 19\n",
      "145500 19\n",
      "145600 20\n",
      "145700 20\n",
      "145800 20\n",
      "145900 20\n",
      "146000 20\n",
      "146100 20\n",
      "146200 20\n",
      "146300 20\n",
      "146400 20\n",
      "146500 20\n",
      "146600 20\n",
      "146700 20\n",
      "146800 20\n",
      "146900 20\n",
      "147000 20\n",
      "147100 20\n",
      "147200 20\n",
      "147300 20\n",
      "147400 20\n",
      "147500 20\n",
      "147600 20\n",
      "147700 20\n",
      "147800 20\n",
      "147900 20\n",
      "148000 20\n",
      "148100 20\n",
      "148200 20\n",
      "148300 20\n",
      "148400 20\n",
      "148500 20\n",
      "148600 20\n",
      "148700 20\n",
      "148800 20\n",
      "148900 20\n",
      "149000 20\n",
      "149100 20\n",
      "149200 20\n",
      "149300 20\n",
      "149400 20\n",
      "149500 20\n",
      "149600 20\n",
      "149700 20\n",
      "149800 20\n",
      "149900 20\n",
      "150000 20\n",
      "150100 20\n",
      "150200 20\n",
      "150300 20\n",
      "150400 20\n",
      "150500 20\n",
      "150600 20\n",
      "150700 20\n",
      "150800 20\n",
      "150900 20\n",
      "151000 20\n",
      "151100 20\n",
      "151200 20\n",
      "151300 20\n",
      "151400 20\n",
      "151500 20\n",
      "151600 20\n",
      "151700 20\n",
      "151800 20\n",
      "151900 20\n",
      "152000 20\n",
      "152100 20\n",
      "152200 20\n",
      "152300 20\n",
      "152400 20\n",
      "152500 20\n",
      "152600 20\n",
      "152700 20\n",
      "152800 20\n",
      "152900 20\n",
      "153000 20\n",
      "153100 20\n",
      "153200 20\n",
      "153300 20\n",
      "153400 20\n",
      "153500 20\n",
      "153600 20\n",
      "153700 20\n",
      "153800 20\n",
      "153900 20\n",
      "154000 20\n",
      "154100 20\n",
      "154200 20\n",
      "154300 20\n",
      "154400 20\n",
      "154500 20\n",
      "154600 20\n",
      "154700 20\n",
      "154800 20\n",
      "154900 20\n",
      "155000 21\n",
      "155100 21\n",
      "155200 21\n",
      "155300 21\n",
      "155400 21\n",
      "155500 21\n",
      "155600 21\n",
      "155700 21\n",
      "155800 21\n",
      "155900 22\n",
      "156000 22\n",
      "156100 22\n",
      "156200 22\n",
      "156300 22\n",
      "156400 22\n",
      "156500 22\n",
      "156600 22\n",
      "156700 22\n",
      "156800 22\n",
      "156900 22\n",
      "157000 23\n",
      "157100 23\n",
      "157200 23\n",
      "157300 23\n",
      "157400 23\n",
      "157500 23\n",
      "157600 23\n",
      "157700 23\n",
      "157800 23\n",
      "157900 23\n",
      "158000 23\n",
      "158100 23\n",
      "158200 23\n",
      "158300 23\n",
      "158400 24\n",
      "158500 24\n",
      "158600 24\n",
      "158700 24\n",
      "158800 24\n",
      "158900 24\n",
      "159000 24\n",
      "159100 24\n",
      "159200 24\n",
      "159300 24\n",
      "159400 24\n",
      "159500 24\n",
      "159600 24\n",
      "159700 24\n",
      "159800 25\n",
      "159900 25\n",
      "160000 25\n",
      "160100 25\n",
      "160200 25\n",
      "160300 25\n",
      "160400 25\n",
      "160500 25\n",
      "160600 25\n",
      "160700 25\n",
      "160800 25\n",
      "160900 25\n",
      "161000 25\n",
      "161100 25\n",
      "161200 25\n",
      "161300 25\n",
      "161400 25\n",
      "161500 25\n",
      "161600 25\n",
      "161700 25\n",
      "161800 25\n",
      "161900 25\n",
      "162000 25\n",
      "162100 25\n",
      "162200 25\n",
      "162300 25\n",
      "162400 25\n",
      "162500 26\n",
      "162600 26\n",
      "162700 26\n",
      "162800 26\n",
      "162900 26\n",
      "163000 26\n",
      "163100 26\n",
      "163200 26\n",
      "163300 26\n",
      "163400 26\n",
      "163500 26\n",
      "163600 26\n",
      "163700 26\n",
      "163800 26\n",
      "163900 26\n",
      "164000 26\n",
      "164100 26\n",
      "164200 26\n",
      "164300 26\n",
      "164400 26\n",
      "164500 26\n",
      "164600 26\n",
      "164700 26\n",
      "164800 27\n",
      "164900 27\n",
      "165000 27\n",
      "165100 27\n",
      "165200 27\n",
      "165300 27\n",
      "165400 27\n",
      "165500 27\n",
      "165600 27\n",
      "165700 27\n",
      "165800 27\n",
      "165900 27\n",
      "166000 27\n",
      "166100 27\n",
      "166200 27\n",
      "166300 27\n",
      "166400 27\n",
      "166500 27\n",
      "166600 27\n",
      "166700 27\n",
      "166800 27\n",
      "166900 28\n",
      "167000 28\n",
      "167100 28\n",
      "167200 28\n",
      "167300 28\n",
      "167400 28\n",
      "167500 28\n",
      "167600 28\n",
      "167700 28\n",
      "167800 28\n",
      "167900 28\n",
      "168000 28\n",
      "168100 28\n",
      "168200 28\n",
      "168300 28\n",
      "168400 28\n",
      "168500 28\n",
      "168600 28\n",
      "168700 28\n",
      "168800 29\n",
      "168900 29\n",
      "169000 29\n",
      "169100 29\n",
      "169200 29\n",
      "169300 29\n",
      "169400 29\n",
      "169500 29\n",
      "169600 29\n",
      "169700 29\n",
      "169800 29\n",
      "169900 29\n",
      "170000 29\n",
      "170100 29\n",
      "170200 29\n",
      "170300 29\n",
      "170400 29\n",
      "170500 29\n",
      "170600 30\n",
      "170700 30\n",
      "170800 30\n",
      "170900 30\n",
      "171000 30\n",
      "171100 30\n",
      "171200 30\n",
      "171300 30\n",
      "171400 30\n",
      "171500 30\n",
      "171600 30\n",
      "171700 30\n",
      "171800 30\n",
      "171900 30\n",
      "172000 30\n",
      "172100 30\n",
      "172200 30\n",
      "172300 30\n",
      "172400 30\n",
      "172500 30\n",
      "172600 30\n",
      "172700 30\n",
      "172800 30\n",
      "172900 30\n",
      "173000 30\n",
      "173100 30\n",
      "173200 30\n",
      "173300 30\n",
      "173400 30\n",
      "173500 31\n",
      "173600 31\n",
      "173700 31\n",
      "173800 31\n",
      "173900 31\n",
      "174000 31\n",
      "174100 31\n",
      "174200 31\n",
      "174300 31\n",
      "174400 32\n",
      "174500 32\n",
      "174600 32\n",
      "174700 32\n",
      "174800 32\n",
      "174900 32\n",
      "175000 32\n",
      "175100 32\n",
      "175200 32\n",
      "175300 32\n",
      "175400 33\n",
      "175500 33\n",
      "175600 33\n",
      "175700 33\n",
      "175800 33\n",
      "175900 33\n",
      "176000 33\n",
      "176100 33\n",
      "176200 33\n",
      "176300 33\n",
      "176400 34\n",
      "176500 34\n",
      "176600 34\n",
      "176700 34\n",
      "176800 34\n",
      "176900 34\n",
      "177000 34\n",
      "177100 34\n",
      "177200 34\n",
      "177300 34\n",
      "177400 34\n",
      "177500 34\n",
      "177600 35\n",
      "177700 35\n",
      "177800 35\n",
      "177900 35\n",
      "178000 35\n",
      "178100 35\n",
      "178200 35\n",
      "178300 35\n",
      "178400 35\n",
      "178500 35\n",
      "178600 35\n",
      "178700 35\n",
      "178800 35\n",
      "178900 35\n",
      "179000 36\n",
      "179100 36\n",
      "179200 36\n",
      "179300 36\n",
      "179400 36\n",
      "179500 36\n",
      "179600 36\n",
      "179700 36\n",
      "179800 36\n",
      "179900 36\n",
      "180000 36\n",
      "180100 36\n",
      "180200 36\n",
      "180300 36\n",
      "180400 37\n",
      "180500 37\n",
      "180600 37\n",
      "180700 37\n",
      "180800 37\n",
      "180900 37\n",
      "181000 37\n",
      "181100 37\n",
      "181200 37\n",
      "181300 37\n",
      "181400 37\n",
      "181500 37\n",
      "181600 38\n",
      "181700 38\n",
      "181800 38\n",
      "181900 38\n",
      "182000 38\n",
      "182100 38\n",
      "182200 38\n",
      "182300 38\n",
      "182400 38\n",
      "182500 38\n",
      "182600 38\n",
      "182700 39\n",
      "182800 39\n",
      "182900 39\n",
      "183000 39\n",
      "183100 39\n",
      "183200 39\n",
      "183300 39\n",
      "183400 39\n",
      "183500 39\n",
      "183600 39\n",
      "183700 40\n",
      "183800 40\n",
      "183900 40\n",
      "184000 40\n",
      "184100 40\n",
      "184200 40\n",
      "184300 40\n",
      "184400 40\n",
      "184500 40\n",
      "184600 40\n",
      "184700 40\n",
      "184800 40\n",
      "184900 41\n",
      "185000 41\n",
      "185100 41\n",
      "185200 41\n",
      "185300 41\n",
      "185400 41\n",
      "185500 41\n",
      "185600 42\n",
      "185700 42\n",
      "185800 42\n",
      "185900 42\n",
      "186000 42\n",
      "186100 42\n",
      "186200 42\n",
      "186300 42\n",
      "186400 43\n",
      "186500 43\n",
      "186600 43\n",
      "186700 43\n",
      "186800 43\n",
      "186900 43\n",
      "187000 43\n",
      "187100 43\n",
      "187200 44\n",
      "187300 44\n",
      "187400 44\n",
      "187500 44\n",
      "187600 44\n",
      "187700 44\n",
      "187800 44\n",
      "187900 44\n",
      "188000 45\n",
      "188100 45\n",
      "188200 45\n",
      "188300 45\n",
      "188400 45\n",
      "188500 45\n",
      "188600 45\n",
      "188700 45\n",
      "188800 45\n",
      "188900 45\n",
      "189000 46\n",
      "189100 46\n",
      "189200 46\n",
      "189300 46\n",
      "189400 46\n",
      "189500 46\n",
      "189600 46\n",
      "189700 46\n",
      "189800 46\n",
      "189900 47\n",
      "190000 47\n",
      "190100 47\n",
      "190200 47\n",
      "190300 47\n",
      "190400 47\n",
      "190500 47\n",
      "190600 48\n",
      "190700 48\n",
      "190800 48\n",
      "190900 48\n",
      "191000 48\n",
      "191100 48\n",
      "191200 48\n",
      "191300 49\n",
      "191400 49\n",
      "191500 49\n",
      "191600 49\n",
      "191700 49\n",
      "191800 49\n",
      "191900 49\n",
      "192000 50\n",
      "192100 50\n",
      "192200 50\n",
      "192300 50\n",
      "192400 50\n",
      "192500 50\n",
      "192600 50\n",
      "192700 50\n",
      "192800 51\n",
      "192900 51\n",
      "193000 51\n",
      "193100 51\n",
      "193200 51\n",
      "193300 51\n",
      "193400 52\n",
      "193500 52\n",
      "193600 52\n",
      "193700 52\n",
      "193800 52\n",
      "193900 52\n",
      "194000 53\n",
      "194100 53\n",
      "194200 53\n",
      "194300 53\n",
      "194400 53\n",
      "194500 53\n",
      "194600 54\n",
      "194700 54\n",
      "194800 54\n",
      "194900 54\n",
      "195000 54\n",
      "195100 54\n",
      "195200 55\n",
      "195300 55\n",
      "195400 55\n",
      "195500 55\n",
      "195600 55\n",
      "195700 55\n",
      "195800 56\n",
      "195900 56\n",
      "196000 56\n",
      "196100 56\n",
      "196200 56\n",
      "196300 56\n",
      "196400 57\n",
      "196500 57\n",
      "196600 57\n",
      "196700 57\n",
      "196800 57\n",
      "196900 57\n",
      "197000 58\n",
      "197100 58\n",
      "197200 58\n",
      "197300 58\n",
      "197400 58\n",
      "197500 59\n",
      "197600 59\n",
      "197700 59\n",
      "197800 59\n",
      "197900 59\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198000 60\n",
      "198100 60\n",
      "198200 60\n",
      "198300 60\n",
      "198400 60\n",
      "198500 61\n",
      "198600 61\n",
      "198700 61\n",
      "198800 61\n",
      "198900 61\n",
      "199000 62\n",
      "199100 62\n",
      "199200 62\n",
      "199300 62\n",
      "199400 62\n",
      "199500 63\n",
      "199600 63\n",
      "199700 63\n",
      "199800 63\n",
      "199900 64\n",
      "200000 64\n",
      "200100 64\n",
      "200200 64\n",
      "200300 64\n",
      "200400 65\n",
      "200500 65\n",
      "200600 65\n",
      "200700 65\n",
      "200800 65\n",
      "200900 66\n",
      "201000 66\n",
      "201100 66\n",
      "201200 66\n",
      "201300 66\n",
      "201400 67\n",
      "201500 67\n",
      "201600 67\n",
      "201700 67\n",
      "201800 68\n",
      "201900 68\n",
      "202000 68\n",
      "202100 68\n",
      "202200 69\n",
      "202300 69\n",
      "202400 69\n",
      "202500 69\n",
      "202600 70\n",
      "202700 70\n",
      "202800 70\n",
      "202900 70\n",
      "203000 71\n",
      "203100 71\n",
      "203200 71\n",
      "203300 71\n",
      "203400 72\n",
      "203500 72\n",
      "203600 72\n",
      "203700 72\n",
      "203800 73\n",
      "203900 73\n",
      "204000 73\n",
      "204100 73\n",
      "204200 74\n",
      "204300 74\n",
      "204400 74\n",
      "204500 74\n",
      "204600 75\n",
      "204700 75\n",
      "204800 75\n",
      "204900 76\n",
      "205000 76\n",
      "205100 76\n",
      "205200 76\n",
      "205300 77\n",
      "205400 77\n",
      "205500 77\n",
      "205600 78\n",
      "205700 78\n",
      "205800 78\n",
      "205900 78\n",
      "206000 79\n",
      "206100 79\n",
      "206200 79\n",
      "206300 80\n",
      "206400 80\n",
      "206500 80\n",
      "206600 81\n",
      "206700 81\n",
      "206800 81\n",
      "206900 81\n",
      "207000 82\n",
      "207100 82\n",
      "207200 82\n",
      "207300 83\n",
      "207400 83\n",
      "207500 83\n",
      "207600 84\n",
      "207700 84\n",
      "207800 84\n",
      "207900 85\n",
      "208000 85\n",
      "208100 85\n",
      "208200 86\n",
      "208300 86\n",
      "208400 86\n",
      "208500 87\n",
      "208600 87\n",
      "208700 88\n",
      "208800 88\n",
      "208900 88\n",
      "209000 89\n",
      "209100 89\n",
      "209200 89\n",
      "209300 90\n",
      "209400 90\n",
      "209500 90\n",
      "209600 91\n",
      "209700 91\n",
      "209800 91\n",
      "209900 92\n",
      "210000 92\n",
      "210100 93\n",
      "210200 93\n",
      "210300 93\n",
      "210400 94\n",
      "210500 94\n",
      "210600 95\n",
      "210700 95\n",
      "210800 95\n",
      "210900 96\n",
      "211000 96\n",
      "211100 97\n",
      "211200 97\n",
      "211300 97\n",
      "211400 98\n",
      "211500 98\n",
      "211600 99\n",
      "211700 99\n",
      "211800 100\n",
      "211900 100\n",
      "212000 100\n",
      "212100 101\n",
      "212200 101\n",
      "212300 102\n",
      "212400 102\n",
      "212500 103\n",
      "212600 103\n",
      "212700 104\n",
      "212800 104\n",
      "212900 105\n",
      "213000 105\n",
      "213100 105\n",
      "213200 106\n",
      "213300 107\n",
      "213400 107\n",
      "213500 108\n",
      "213600 108\n",
      "213700 108\n",
      "213800 109\n",
      "213900 110\n",
      "214000 110\n",
      "214100 111\n",
      "214200 111\n",
      "214300 112\n",
      "214400 112\n",
      "214500 113\n",
      "214600 113\n",
      "214700 114\n",
      "214800 114\n",
      "214900 115\n",
      "215000 115\n",
      "215100 116\n",
      "215200 116\n",
      "215300 117\n",
      "215400 118\n",
      "215500 118\n",
      "215600 119\n",
      "215700 119\n",
      "215800 120\n",
      "215900 120\n",
      "216000 121\n",
      "216100 121\n",
      "216200 122\n",
      "216300 123\n",
      "216400 123\n",
      "216500 124\n",
      "216600 124\n",
      "216700 125\n",
      "216800 126\n",
      "216900 126\n",
      "217000 127\n",
      "217100 128\n",
      "217200 128\n",
      "217300 129\n",
      "217400 130\n",
      "217500 130\n",
      "217600 131\n",
      "217700 132\n",
      "217800 132\n",
      "217900 133\n",
      "218000 134\n",
      "218100 134\n",
      "218200 135\n",
      "218300 136\n",
      "218400 136\n",
      "218500 137\n",
      "218600 138\n",
      "218700 138\n",
      "218800 139\n",
      "218900 140\n",
      "219000 141\n",
      "219100 141\n",
      "219200 142\n",
      "219300 143\n",
      "219400 144\n",
      "219500 145\n",
      "219600 145\n",
      "219700 146\n",
      "219800 147\n",
      "219900 148\n",
      "220000 148\n",
      "220100 149\n",
      "220200 150\n",
      "220300 151\n",
      "220400 152\n",
      "220500 153\n",
      "220600 153\n",
      "220700 154\n",
      "220800 155\n",
      "220900 156\n",
      "221000 157\n",
      "221100 158\n",
      "221200 159\n",
      "221300 160\n",
      "221400 160\n",
      "221500 161\n",
      "221600 162\n",
      "221700 163\n",
      "221800 164\n",
      "221900 165\n",
      "222000 166\n",
      "222100 167\n",
      "222200 168\n",
      "222300 169\n",
      "222400 170\n",
      "222500 171\n",
      "222600 171\n",
      "222700 172\n",
      "222800 173\n",
      "222900 174\n",
      "223000 175\n",
      "223100 177\n",
      "223200 178\n",
      "223300 179\n",
      "223400 180\n",
      "223500 181\n",
      "223600 182\n",
      "223700 183\n",
      "223800 184\n",
      "223900 185\n",
      "224000 186\n",
      "224100 187\n",
      "224200 188\n",
      "224300 189\n",
      "224400 191\n",
      "224500 192\n",
      "224600 193\n",
      "224700 194\n",
      "224800 195\n",
      "224900 197\n",
      "225000 197\n",
      "225100 198\n",
      "225200 200\n",
      "225300 201\n",
      "225400 202\n",
      "225500 204\n",
      "225600 205\n",
      "225700 206\n",
      "225800 207\n",
      "225900 208\n",
      "226000 210\n",
      "226100 211\n",
      "226200 212\n",
      "226300 214\n",
      "226400 215\n",
      "226500 216\n",
      "226600 218\n",
      "226700 219\n",
      "226800 221\n",
      "226900 222\n",
      "227000 224\n",
      "227100 225\n",
      "227200 227\n",
      "227300 228\n",
      "227400 230\n",
      "227500 231\n",
      "227600 233\n",
      "227700 234\n",
      "227800 236\n",
      "227900 237\n",
      "228000 239\n",
      "228100 240\n",
      "228200 242\n",
      "228300 244\n",
      "228400 246\n",
      "228500 247\n",
      "228600 249\n",
      "228700 251\n",
      "228800 252\n",
      "228900 254\n",
      "229000 256\n",
      "229100 258\n",
      "229200 259\n",
      "229300 261\n",
      "229400 263\n",
      "229500 264\n",
      "229600 266\n",
      "229700 268\n",
      "229800 270\n",
      "229900 272\n",
      "230000 274\n",
      "230100 276\n",
      "230200 278\n",
      "230300 281\n",
      "230400 282\n",
      "230500 284\n",
      "230600 287\n",
      "230700 289\n",
      "230800 291\n",
      "230900 293\n",
      "231000 295\n",
      "231100 297\n",
      "231200 299\n",
      "231300 302\n",
      "231400 304\n",
      "231500 306\n",
      "231600 308\n",
      "231700 310\n",
      "231800 313\n",
      "231900 315\n",
      "232000 318\n",
      "232100 320\n",
      "232200 323\n",
      "232300 326\n",
      "232400 328\n",
      "232500 331\n",
      "232600 334\n",
      "232700 336\n",
      "232800 339\n",
      "232900 342\n",
      "233000 345\n",
      "233100 348\n",
      "233200 351\n",
      "233300 354\n",
      "233400 357\n",
      "233500 360\n",
      "233600 364\n",
      "233700 366\n",
      "233800 369\n",
      "233900 372\n",
      "234000 376\n",
      "234100 379\n",
      "234200 382\n",
      "234300 385\n",
      "234400 389\n",
      "234500 392\n",
      "234600 395\n",
      "234700 398\n",
      "234800 401\n",
      "234900 404\n",
      "235000 408\n",
      "235100 412\n",
      "235200 415\n",
      "235300 420\n",
      "235400 423\n",
      "235500 426\n",
      "235600 430\n",
      "235700 434\n",
      "235800 437\n",
      "235900 441\n",
      "236000 445\n",
      "236100 449\n",
      "236200 453\n",
      "236300 458\n",
      "236400 462\n",
      "236500 466\n",
      "236600 470\n",
      "236700 474\n",
      "236800 478\n",
      "236900 483\n",
      "237000 487\n",
      "237100 492\n",
      "237200 497\n",
      "237300 501\n",
      "237400 506\n",
      "237500 510\n",
      "237600 515\n",
      "237700 521\n",
      "237800 527\n",
      "237900 532\n",
      "238000 537\n",
      "238100 542\n",
      "238200 548\n",
      "238300 553\n",
      "238400 559\n",
      "238500 564\n",
      "238600 571\n",
      "238700 577\n",
      "238800 584\n",
      "238900 589\n",
      "239000 594\n",
      "239100 600\n",
      "239200 605\n",
      "239300 612\n",
      "239400 619\n",
      "239500 626\n",
      "239600 634\n",
      "239700 641\n",
      "239800 648\n",
      "239900 655\n",
      "240000 663\n",
      "240100 670\n",
      "240200 677\n",
      "240300 685\n",
      "240400 692\n",
      "240500 701\n",
      "240600 710\n",
      "240700 716\n",
      "240800 724\n",
      "240900 735\n",
      "241000 743\n",
      "241100 751\n",
      "241200 760\n",
      "241300 768\n",
      "241400 779\n",
      "241500 789\n",
      "241600 798\n",
      "241700 810\n",
      "241800 820\n",
      "241900 832\n",
      "242000 842\n",
      "242100 852\n",
      "242200 863\n",
      "242300 875\n",
      "242400 887\n",
      "242500 898\n",
      "242600 907\n",
      "242700 919\n",
      "242800 931\n",
      "242900 946\n",
      "243000 958\n",
      "243100 971\n",
      "243200 984\n",
      "243300 995\n",
      "243400 1009\n",
      "243500 1023\n",
      "243600 1036\n",
      "243700 1051\n",
      "243800 1066\n",
      "243900 1080\n",
      "244000 1096\n",
      "244100 1111\n",
      "244200 1127\n",
      "244300 1143\n",
      "244400 1162\n",
      "244500 1179\n",
      "244600 1196\n",
      "244700 1215\n",
      "244800 1234\n",
      "244900 1251\n",
      "245000 1274\n",
      "245100 1290\n",
      "245200 1309\n",
      "245300 1332\n",
      "245400 1352\n",
      "245500 1374\n",
      "245600 1400\n",
      "245700 1429\n",
      "245800 1453\n",
      "245900 1476\n",
      "246000 1503\n",
      "246100 1532\n",
      "246200 1558\n",
      "246300 1587\n",
      "246400 1612\n",
      "246500 1643\n",
      "246600 1673\n",
      "246700 1709\n",
      "246800 1740\n",
      "246900 1774\n",
      "247000 1810\n",
      "247100 1843\n",
      "247200 1875\n",
      "247300 1918\n",
      "247400 1956\n",
      "247500 1998\n",
      "247600 2043\n",
      "247700 2087\n",
      "247800 2140\n",
      "247900 2181\n",
      "248000 2227\n",
      "248100 2280\n",
      "248200 2337\n",
      "248300 2394\n",
      "248400 2460\n",
      "248500 2509\n",
      "248600 2572\n",
      "248700 2632\n",
      "248800 2700\n",
      "248900 2757\n",
      "249000 2821\n",
      "249100 2884\n",
      "249200 2971\n",
      "249300 3054\n",
      "249400 3133\n",
      "249500 3223\n",
      "249600 3295\n",
      "249700 3390\n",
      "249800 3496\n",
      "249900 3612\n",
      "250000 3728\n",
      "250100 3836\n",
      "250200 3982\n",
      "250300 4127\n",
      "250400 4244\n",
      "250500 4387\n",
      "250600 4554\n",
      "250700 4744\n",
      "250800 4923\n",
      "250900 5096\n",
      "251000 5303\n",
      "251100 5489\n",
      "251200 5765\n",
      "251300 5972\n",
      "251400 6247\n",
      "251500 6524\n",
      "251600 6884\n",
      "251700 7200\n",
      "251800 7525\n",
      "251900 7888\n",
      "252000 8341\n",
      "252100 8760\n",
      "252200 9278\n",
      "252300 9800\n",
      "252400 10471\n",
      "252500 11207\n",
      "252600 12119\n",
      "252700 13207\n",
      "252800 14409\n",
      "252900 15161\n",
      "253000 15798\n",
      "253100 16613\n",
      "253200 17740\n",
      "253300 19038\n",
      "253400 20695\n",
      "253500 22756\n",
      "253600 26074\n",
      "253700 32583\n",
      "253800 55888\n"
     ]
    }
   ],
   "source": [
    "l= []\n",
    "for i in range(0,253854,100):\n",
    "    print(i,len_lists[i])\n",
    "    l.append([i,len_lists[i]])\n",
    "l.append([243853,len_lists[253853]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1074\n"
     ]
    }
   ],
   "source": [
    "print(len_lists[243852])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmwAAAHBCAYAAADU/+eIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3XmUZHV9///nC3RAAUcQNLI56KARNVEyKn5jdAwGWTJxSyIkMWLQcQkx5pdEMXFBRZRoFo0aRUXUqAQ3ZBIMmiAQN2QwRFlER0QZQbbBEVFB4P37496GoujuqZ7p7rp9+/k4p05X3fVd99atevXnbqkqJEmS1F1bjbsASZIkTc/AJkmS1HEGNkmSpI4zsEmSJHWcgU2SJKnjDGySJEkdZ2DTZklyYpJjxjTvJHl/kuuTfHWWp/0bSS6ZzWlq/JIsS1JJ7jZP85u37SPJyiTrp+lfSZbPRy2zJcnhSb4wxvm/KMlVSX6S5D6zPO2fJHngbE5zIZvvbXMhM7D1RJLL2i+Y7Qa6PS/JmWMsa648HvgtYPeqesxsTriq/qeqHjKb01xIZvOH0i9iLURJ7g78A3BAVW1fVdfN5vTbaV46m9PU4mBg65e7AX8+7iJmKsnWMxzlAcBlVXXjXNQzlXEGj81YRovWfK6n2Z6X4Xb2bcYyvR+wLXDhHJQzrXFt5/PY8uznewsY2PrlzcBfJbn3cI/JWjuSnJnkee3zw5N8Mck/JvlRkkuT/L+2++VJrk7ynKHJ7pzkc0luSHJWkgcMTPuX234bklyS5PcH+p2Y5F+SnJbkRuBJk9S7a5JT2/HXJXl+2/0I4L3A49pdC6+dZNyJ9/LPSTYm+WaS/Qf6PzfJxW3dlyZ5wUC/O+1ealsuX57k68CNSe7Wvv5BO/4lg9MequPEJO+aw2W0U7tr+Ip29/ApA/2e3y63De1y3HWgXyV5YZJvt+O9I42HAu8aWLY/aoffJslbkny/bcV9V5J7tP1enuQrE5+rNLuSLkyyLXB2O8sftdN73FD92yb5WZKd29evTHJLknu1r49J8k/t86VJPpjkmiTfa4fdamh9/2OSDcDRSbZua742yaXAIZOto6kk+Z32ffwozXby0IF+k30mHpXka+16/jeaH/zB6f12kvPb6X0pya9sYnq7JvlE+36/m+QlA8Pfo/18XJ/kIuDRI7ylg9vP+rVJ3pxkq3a9bkjyiIFp37ddJ7tMskwOT/KFdrle39Z10ND7ePLA66OT/Gv7fOL757lpvk+ubz+Dj07y9Xa5vP2us5xyG16a5H1JrkyzLR6TNuxM9nmY5L1sk+Sf0mw7V7TPt0nyYGDikIgfJTljknEn3svqdtwrk/zlQP/HJPly+56uTPL2JEsG+t++izqTbOdJDk5yUftZ+kGSv5pshWbT33ObvYzS4W1zUasqHz14AJcBTwY+CRzTdnsecGb7fBlQwN0GxjkTeF77/HDgFuC5wNbAMcD3gXcA2wAHADcA27fDn9i+fkLb/63AF9p+2wGXt9O6G7AvcC3wsIFxNwK/TvNPw7aTvJ+zgHfS/PA9ErgG2H+g1i9Msywm3stfAHcHntXOb6e2/yHAg4AATwR+Cuzb9lsJrB9arucDewD3AB7SvrddB5brg6aoY66X0X8A/wbs2L7PJ7bdf7Od1r7tfP8ZOHtgvAL+Hbg3sGe7bA+catkC/wScCuwE7ACsAd7Y9tuKJpgdDewNXA88aqrP3CTv4Wzgme3zzwLfAQ4a6Pf09vkHgU+3818GfAs4Ymh9/1m7LO8BvBD4ZrvedgI+v6laBmp6MHAjzW73uwMvA9YBS6b4TCwBvscdn7ffBX7BHdvhvsDVwGNptq3ntNPYZorpbQWcB7y6nfYDgUuBp7TDvwn4n/Z97QFcwMBndpL3U+3736ld39/iju3+ncBxA8P+ObBmmu3qF8Dz2/fxIuAKIIPfQQPDHw3869Bn4V002/QBwM+BU4D7Aru1y+iJQ+t0qm34FODdNNvRfYGvAi+Y6vMwyXt5HfCVdtxdgC8Brx/lczvQ/6Pt/B9Bsw09ue3/a8B+7byXARcDLx1aH8un2s6BK4HfaPvvSPvdtBnfc1u6jDq3bS72x9gL8DFLK/KOwPbwdqPdhZkHtm8P9HtEO/z9BrpdBzyyfX4icNJAv+2BW9uN8FnA/wzV927gNQPjfnCa97JHO60dBrq9EThxoNZNBbbbf0jabl8Fnj3F8KcAf94+X8ldA9ufDLxeTvPD8mTg7ptYJ3O5jO4P3AbsOEm/9wF/NzTfXwDL2tcFPH6g/8nAUZMtW5pQeyMDoRR4HPDdgdfLgA00P0yvGOq+qcD2euBtNF/mP6QJDG+i+eH6GbAzTTi4CdhnYLwXcMdn+3Dg+0PTPQN44cDrAzZVy8CwrwJOHni9FfADYOUUn4knTPJ5+xJ3BLZ/oQ0DA/0v4Y5wMjy9x07yfl4BvL99filtwG5fr2bTgW1w+BcD/z0wr8uBrdrXa4Hfn2a7Wjfw+p7ttH9p4H1sKrDtNtD/OuBZA68/QRtsmGYbptlleRMDIQM4DPj8VJ+HSd7Ld4CDB14/heYwi8FaNxXYfnmg298B75ti+JcCnxpaH4OB7YNDw3+f5vN9r028h7leRp3bNhf7w12iPVNVF9C0nhy1GaNfNfD8Z+30hrttP/D68oH5/oTmR3tXmmPMHtvuEvhRml1rfwj80mTjTmJXYENV3TDQ7Xs0/4WP6gfVfhsMjL8rQJKD0uzG29DWdjDNl89UBt/nOpov4KOBq5OclIHdjZsYdzaX0R40y+j6SfrtSvN+B+d7HXdefj8ceP5T7rxeB+1C88N83kCd/9l2n5j+ZTT/JS+jaZGdibNoQvK+wDeAz9G0eu5HEw6upVk3E61YE4Y/D8PLatehbt9jdMPL77Z2WlPNb1cm/7xNeADwl0Preo92vMmm9wBg16Hh/4bmR3hz39vw8Lu27+0cmkD+xCS/TPMPyanTTOf2z01V/bR9OtVnZzLD3yfTfb9MtQ0/gKZF6cqB5fNumlakCdNtOzC0jgemPROTLtMkD07y70l+mOTHwLGM+P3SeibNd9L30hxG8bhJxpkwl8uoi9vmomZg66fX0Oy2GNxoJg7Qv+dAt8FwsDn2mHiSZHua5u0raDbGs6rq3gOP7avqRQPjFlO7AtgpyQ4D3fakaeUY1W5JMjT+FUm2oflP/i00rYf3Bk6jaUmayp1qraqPVNXjab4UCzhumnHnahldTrOM7nK8Yjv9BwzMdzvgPoy2/IbneS3ND+nDBupcWlW3/7AmOZim1e2/aY6jHKX+CV+i2c38dJrlcRHNujqE5gdjooZfDL4n7vp5GJ7XlQws+3b4UQ0vv7TTmmp+VzL5523C5cAbhtb1Pavqo1NM73KaFszB4XeoqoO34L0ND3/FwOsPAH9E0zLz8ar6+QjTm8yNzO73y6TbMM3yuQnYeWD53KuqHjYw7KY+e3dax9x1mYxiqmX6LzS7/PauqnvRhO2ZfL+cW1VPpQlXp9C0gE9lLpdRF7fNRc3A1kNtK9C/AS8Z6HYNzUb0R+1Bn39CcxzXljg4yePbA2pfD5xTVZfTtPA9OMmzk9y9fTw6Awdub6L+y2m+LN7YHvz6K8ARwIdnUNt9gZe08/494KE0wWwJzXFd1wC3pDlo+oBRJ5rkIUl+sw1+P6cJM7dOM8pcLaMrgc8A70yyYzv+E9reHwGem+SRbZ3HtvO9bIRJXwXs3tY70br0HuAfk9y3XQa7JXlK+3xnml2wz6M5NmtVG+CgWca30RyDNdX7+CnN8Vp/yh0/Al+i2a1yVjvMrTQ/Wm9IskOaEzf+P+Bfp3kfJ9Os/92T7MhQi3OaA+LPnGbcQ5Lsn+YSD39J8+P3pSmG/zLNcTovSXPCwDOAwcvNvAd4YZLHprFdkkOG/iEZ9FXgx2lORLhHu70+PMnEyQUnA69o1/vuNMcHbcpft8PvQbNr698G+n2I5kf5j2iOR9pc5wOHtp/FFTTH8m2JSbfh9rP/WeDvk9wrzQkUD0ryxBlM+6PAK5Ps0n6GX830n6fJvCrJPZM8jOZY1IllugPwY+Anbavli6aawLAkS5L8YZKlVfWLdjrTfb/M2TIa17apqRnY+ut1NAebDno+8Nc0u8cextQ/QKP6CE1r3gaaA23/EKDdlXkAcCjNf3s/pGmF2mYG0z6MZhfbFcCnaI7t+twMxj+H5iD4a4E3AL9bVde1tb2E5kvjeuAPmH4X0LBtaI7juJbmfd2X5j/oqczlMno2zX+336Q5ru6l7bT/m+Y4rE/Q/Df7oHY+oziD5nIGP0xybdvt5TQH3X+l3cXzXzT/eQMcD3y6qk6r5npVRwDvTXKf9gv/DcAX290y+00xz7Nodt98deD1Dtxxlik0oeRGmuO3vkCzXE+Y5n28Bzgd+D/gazQn4wzaA/jiZCNW1SU04eWfadbzKmBVVd08xfA3A8+gOV7neprjEz850H8tzbb39rb/unbYSbU/gqtoTrb5blvDe4Gl7SCvpdmN9F2aH+UPTTWtAZ+m+fE9n+ZklfcNzG89zTIqmpMZNteraD5r17c1fmQLpgVTbMNtvz+m+efronZ+H6c5rnNUx9Acr/d1mt19X2u7zcRZNOvyv4G3VNVn2+5/RfO9cgPN5/DfJh99Ss8GLmu3tRfSfBanMpfLCMazbWoKE2f3SL2R5HCakykeP+Y6TqQ5GPyV46xDd5XkfJqzjmf1oqgLVZITgCv8rG5akmU0YfnuVXXLGOs4nA58z2n+eBE7SYtOVT1y3DV0RRtAngE8aryVSJqOu0QlaZFK8nqa67i9uaq+O+56JE3NXaKSJEkdZwubJElSx/XuGLadd965li1bNu4yJEmSNum88867tqrucv/eYb0LbMuWLWPt2rXjLkOSJGmTkox0t4fe7BJNsirJ8Rs3bhx3KZIkSbOqN4GtqtZU1eqlS5duemBJkqQFpDeBTZIkqa8MbJIkSR1nYJMkSeq43gQ2TzqQJEl91ZvA5kkHkiSpr3oT2CRJkvrKwCZJktRxBjZJkqSOM7BJkiR1nIFNkiSp43oT2LyshyRJ6qveBDYv6yFJkvqqN4FNkiSprwxskiRJHWdgkyRJ6jgDmyRJUscZ2CRJkjrOwCZJktRxBjZJkqSO601g88K5kiSpr3oT2LxwriRJ6qveBDZJkqS+MrBJkiR1nIFNkiSp4wxskiRJHWdgkyRJ6jgDmyRJUscZ2CRJkjrOwCZJktRxBjZJkqSOM7BJkiR1nIFNkiSp43oT2Lz5uyRJ6qveBDZv/i5JkvqqN4FNkiSprwxskiRJHWdgkyRJ6jgDmyRJUscZ2CRJkjrOwCZJktRxBjZJkqSOM7BJkiR1nIFNkiSp4wxskiRJHWdgkyRJ6jgDmyRJUscZ2CRJkjrOwCZJktRxBjZJkqSOM7BJkiR1XKcDW5KVSf4nybuSrBx3PZIkSeMw74EtyQlJrk5ywVD3A5NckmRdkqPazgX8BNgWWD/ftUqSJHXBOFrYTgQOHOyQZGvgHcBBwD7AYUn2Af6nqg4CXg68dp7rlCRJ6oR5D2xVdTawYajzY4B1VXVpVd0MnAQ8tapua/tfD2wz1TSTrE6yNsnaa665Zk7qliRJGpeuHMO2G3D5wOv1wG5JnpHk3cCHgLdPNXJVHV9VK6pqxS677DLHpUqSJM2vu427gFYm6VZV9Ungk/NdjCRJUpd0pYVtPbDHwOvdgStmMoEkq5Icv3HjxlktTJIkady6EtjOBfZOsleSJcChwKkzmUBVramq1UuXLp2TAiVJksZlHJf1+CjwZeAhSdYnOaKqbgGOBE4HLgZOrqoL57s2SZKkLpr3Y9iq6rApup8GnDbP5UiSJHVeV3aJbjGPYZMkSX3Vm8DmMWySJKmvehPYJEmS+srAJkmS1HG9CWwewyZJkvqqN4HNY9gkSVJf9SawSZIk9ZWBTZIkqeMMbJIkSR3Xm8DmSQeSJKmvehPYPOlAkiT1VW8CmyRJUl8Z2CRJkjrOwCZJktRxBjZJkqSO601g8yxRSZLUV70JbJ4lKkmS+qo3gU2SJKmvDGySJEkdZ2CTJEnqOAObJElSxxnYJEmSOq43gc3LekiSpL7qTWDzsh6SJKmvehPYJEmS+srAJkmS1HEGNkmSpI4zsEmSJHWcgU2SJKnjDGySJEkd15vA5nXYJElSX/UmsHkdNkmS1Fe9CWySJEl9ZWCTJEnqOAObJElSxxnYJEmSOs7AJkmS1HEGNkmSpI4zsEmSJHWcgU2SJKnjDGySJEkdZ2CTJEnqOAObJElSx/UmsHnzd0mS1Fe9CWze/F2SJPVVbwKbJElSXxnYJEmSOs7AJkmS1HEGNkmSpI4zsEmSJHWcgU2SJKnjDGySJEkdZ2CTJEnqOAObJElSxxnYJEmSOs7AJkmS1HEGNkmSpI4zsEmSJHWcgU2SJKnjDGySJEkdZ2CTJEnquM4HtiTbJTkvyW+PuxZJkqRxmPfAluSEJFcnuWCo+4FJLkmyLslRA71eDpw8v1VKkiR1xzha2E4EDhzskGRr4B3AQcA+wGFJ9knyZOAi4Kr5LlKSJKkr7jbfM6yqs5MsG+r8GGBdVV0KkOQk4KnA9sB2NCHuZ0lOq6rbhqeZZDWwGmDPPfecu+IlSZLGYKTAlmQrYKuqumWg21OAhwNnVNX/bmEduwGXD7xeDzy2qo5s53U4cO1kYQ2gqo4HjgdYsWJFbWEtkiRJnTJqC9tHgZuAPwZI8kLgnW2/XyQ5pKr+awvqyCTdbg9eVXXiFkxbkiRpQRv1GLb9gNMGXv818F5gKfBJ4G+3sI71wB4Dr3cHrtjCaUqSJPXCqIHtvsAPAJIsB/YC3l5VNwDvBx6xhXWcC+ydZK8kS4BDgVNnMoEkq5Icv3Hjxi0sRZIkqVtGDWw/Bu7TPl9JczzZ19vXtwLbjjrDJB8Fvgw8JMn6JEe0x8YdCZwOXAycXFUXjjpNgKpaU1Wrly5dOpPRJEmSOm/UY9i+BByV5Bbgpdx59+hyml2aI6mqw6boftrQdCVJksToLWwvB3ai2U25LXD0QL9n0bSYjZW7RCVJUl+lavSrYCS5T1VdN9TtEcAPq+qa2S5uc6xYsaLWrl077jIkSZI2Kcl5VbViU8NtsoUtyZIkG5L8znBYA6iqb3QlrEmSJPXRJgNbVd0M3AL8fO7LkSRJ0rBRj2E7BfjduSxkS3kMmyRJ6quRjmFL8nTgbcA5NOHtSgbuRABQVWfMRYEz5TFskiRpoRj1GLZRL+vxifbvM9rHhKK5rVQBW8+oQkmSJI1k1MD2pDmtQpIkSVMaKbBV1VlzXYgkSZImN+pJB53nSQeSJKmvpmxhS3IG8OKq+mb7fDpVVfvPbmkzU1VrgDUrVqx4/jjrkCRJmm3T7RLNwPOtGDordJphJUmSNIumDGxV9aSB5yvnpRpJkiTdRW+OYZMkSeqrUS/rAUCSHYG9gW2H+1XV2bNVlCRJku4wUmBLsi1wAvD7TH282lgvnJtkFbBq+fLl4yxDkiRp1o26S/RVwErgOTSB7UjgecAXgO8Avz0Xxc1EVa2pqtVLly4ddymSJEmzatTA9kzgdcBJ7etzqur9VfVE4P+AA+eiOEmSJI0e2PYELqyqW4FfANsN9DsBeNZsFyZJkqTGqIHtOmD79vnlwK8O9NsZuMdsFiVJkqQ7jHqW6FeARwGfAT4BvD7JDsAtwF/SHMsmSZKkOTBqYDuOZrcowDHAcppj2ramCXMvmv3SJEmSBCMGtqpaC6xtn98APDPJNsA2VfXjOaxvZF7WQ5Ik9dVm3+mgqm7qSlgDL+shSZL6a+TAlmTvJB9I8q0kN7Z/T0xik5YkSdIcGvVOByuB04CfAf8BXAXcD1gFPCvJgVV11lwVKUmStJiNetLB3wP/Czylqn4y0bE9U/Szbf8Vs1+eJEmSRt0lug9w3GBYg9tPQDgOeNhsFyZJkqTGqIFtPbBkin5LgB/MTjmSJEkaNmpgOw54bZLdBju2r18DHDvbhUmSJKkx6jFsTwR2AL6T5CvccdLBfu3zle2JCQBVVc+Z7UIlSZIWq1ED2+OBW4ErgQe0D9rXAL8xMGzNTmkz44VzJUlSX6VqLPlqzqxYsaLWrl077jIkSZI2Kcl5VbXJK21s9p0OJEmSND8MbJIkSR1nYJMkSeo4A5skSVLHGdgkSZI6bsrAluRrSR7WPn91kl3nryxJkiRNmK6F7RHA9u3z1wC7z305kiRJGjbdhXOvAJ6W5CogwC8l2XOqgavq+7NdnCRJkqYPbO8GjgFeRnP3gk9tYlpbz1ZRkiRJusOUga2qjk3yOWAf4P3AG4FL56swSZIkNaa9l2hVnQucm+Rw4ENV9c15qWozeC9RSZLUVyNd1qOqntTlsAZQVWuqavXSpUvHXYokSdKsGvk6bEkekeTjSa5JckuSq5OcnOQRc1mgJEnSYjftLtEJSR4NnAX8DDgV+CHwS8Aq4JAkT6iq8+asSkmSpEVspMBGc8LBBcD+VXXDRMckOwD/1fY/YPbLkyRJ0qi7RPcD3jgY1gDa18cBj5vtwiRJkrbUsqP+Y9wlzIpRA1ttYX9JkiRtplED2znA37S7QG+XZDvg5cBXZrswSZKkLdGX1jUY/Ri2vwHOBL6X5N+BK2lOOjgEuAewci6KkyRJ0oiBraq+mmQ/4NXAU4CdgA3AGcDrq+obc1eiJEnS4jZqCxtV9XXgd+ewFkmSpFnRp92hMIML50qSJGk8DGySJEkdZ2CTJEm90rfdoWBgkyRJ6jwDmyRJ6o0+tq7BCIEtyZIkG5L8znwUJEmSpDvbZGCrqpuBW4Cfz305kiRJGjbqLtFTGMM12JI8NMm7knw8yYvme/6SJGnh6OvuUBj9wrmfAd6W5OM04e1Khm74XlVnjDKhJCcAvw1cXVUPH+h+IPBWYGvgvVX1pqq6GHhhkq2A94xYqyRJUq+MGtg+0f59RvuYUEDav1uPOK0TgbcDH5zokGRr4B3AbwHrgXOTnFpVF7XHzh3VjiNJknQXfW5dg9ED25Nma4ZVdXaSZUOdHwOsq6pLAZKcBDwVuKiqTgVOTfIfwEdmqw5JkqSFYtSbv581x3XsBlw+8Ho98NgkK2la9LYBTptq5CSrgdUAe+6559xVKUmSOqfvrWswg5u/AyTZGdgPuA+wpqo2JNkWuLmqbtuCOjJJt6qqM4EzNzVyVR0PHA+wYsWK2sTgkiRJC8pIZ4mm8Waalq9TgROAZW3vTwN/u4V1rAf2GHi9O3DFFk5TkiT13GJoXYPRL+vxCuBI4HXAY7lzi9gamrM+t8S5wN5J9kqyBDiUJhiOLMmqJMdv3LhxC0uRJEnqllED2/OA11XVscDXhvqtAx406gyTfBT4MvCQJOuTHFFVt9AEwtOBi4GTq+rCUacJUFVrqmr10qVLZzKaJElaoBZL6xqMfgzbbsBXpuh3M7DdqDOsqsOm6H4a05xYIEmStFiN2sL2A+DhU/T7VeC7s1OOJEnSpi2m1jUYPbB9DHh1kl8f6FZJHgz8JXDSrFc2Qx7DJkmS+mrUwHY08E3gbODbbbePAd9oX79p1iubIY9hkyRpcVhsrWsw+oVzf9ZexPYPgKfQnGhwHfB64MPtSQOSJEmaAyNfOLeqbgU+1D4kSZLm3WJsXYOZ3+lgOc19P3ejvUl7Va2bi8JmKskqYNXy5cvHXYokSZoDizWsweh3Otg2yQk010j7V+A44MPAxUnem2SbOaxxJB7DJkmS+mrUkw7eAvwh8BpgObBD+/do4NnAm+eiOEmSJFjcrWsw+i7RQ4HXtnc6mHAp8IYkAH8BvGSWa5MkSRKjt7BtA3x1in7nAEtmp5zN53XYJEnqp8XeugajB7b/Ag6Yot8BwBmzU87m8xg2SZL6x7DWmHKXaJIHDrz8B+BDSbajuWDuVcD9gN8HDgb+aC6LlCRJWsymO4ZtHVADrwO8CHjhUDeAs4CtZ7c0SZK0mNm6dofpAttz560KSZKkAYa1O5sysFXVB+azEEmSJE1u1JMOOs+zRCVJ6gdb1+5q5FtTJTkQ+D1gD2Dbod5VVU+czcJmqqrWAGtWrFjx/HHWIUmSNp9hbXKj3prqZcBpwG8D2wG3Dj1um6sCJUmSFrtRW9iOBN4NHFlVt85hPZIkaZGydW1qox7Ddi/gY4Y1SZI0Fwxr0xs1sJ0O7DeXhUiSpMXJsLZpM9kl+qkkBXwWuH54gKq6dDYLkyRJUmPUwFbADcAbgGOmGGasdzpIsgpYtXz58nGWIUmSZsDWtdGMGthOBP4f8I/AN4Gb56qgzeVlPSRJWlgMa6MbNbCtpDlD9MS5K0WSJC0WhrWZGfWkg2uBq+ayEEmSJE1u1MD2NuDFSXpzKytJkjQetq7N3Ki7RHcEHg5clORz3PUs0aqq18xqZZIkqXcMa5tn1MD2twPPHzxJ/wIMbJIkaUqGtc03UmCrKneFSpIkjYlBTJIkzTlb17ZMbwJbklVJjt+4ceO4S5EkSQMMa1tupMCW5LYkt073mOtCN6Wq1lTV6qVLl467FEmS1DKszY5RTzp4Hc2JBYPuAxwAbENzJwRJkqTbGdZmz6gnHRw9WfckWwNrAPdDSpKk2xnWZtcWHcNWVbcC7wReOjvlSJKkhc6wNvtm46SDbYCdZmE6kiRpgTOszY2Rdokm2XOSzkto7n7wJmDtbBYlSZIWHsPa3Bn1pIPLuOtJBwABvgP86WwVJEmSFh7D2twaNbD9CXcNbD8Hvgec2x7LJkmSFiHD2twb9SzRE+e4DkmStAAZ1uZHb+50IEmS5pdhbf6MukuUJM8BDgP2BLYd6l1V9aDZLEySJHWXYW1+jXqW6KuA1wIXAOcDN81lUZsjySpg1fLly8ddiiRJvWZYm3+jtrAdAby1qv5iLovZElW1BlizYsWK54+7FkmS+sqwNh6jHsN2H5pbUEmSpEXKsDY+owa2s4BfnctCJElSdxnWxmvUXaIvBT6Z5DrgNGDD8ABVddtsFiZJkrrBsDZ+owa2b7V/3z9F/5rBtCRJ0gJhWOuGUUPW65j81lSSJKmnDGvdMeqdDo6e4zokSVJHGNS6xzsdSJKk2xnWusnAJkk3evKlAAAR6ElEQVSSAMNalxnYJEmSYa3jDGySJC1yhrXu81IckiQtUga1hcMWNkmSFiHD2sJiYJMkaZExrC087hKVJGmRMKgtXLawSZK0CBjWFjYDmyRJPWdYW/jcJSpJUk8Z1Pqj8y1sSZ6W5D1JPp3kgHHXI0nSQmBY65exBLYkJyS5OskFQ90PTHJJknVJjgKoqlOq6vnA4cCzxlCuJEkLimGtf8a1S/RE4O3AByc6JNkaeAfwW8B64Nwkp1bVRe0gr2z7S5KkSRjU+mssLWxVdTawYajzY4B1VXVpVd0MnAQ8NY3jgM9U1dcmm16S1UnWJll7zTXXzG3xkiR1kGGt37p00sFuwOUDr9cDjwX+DHgysDTJ8qp61/CIVXU8cDzAihUrah5qlSSpEwxqi0OXAlsm6VZV9TbgbfNdjCRJXWdYWzy6FNjWA3sMvN4duGLUkZOsAlYtX758tuuSJKlTDGqLT5cu63EusHeSvZIsAQ4FTh115KpaU1Wrly5dOmcFSpI0boa1xWksLWxJPgqsBHZOsh54TVW9L8mRwOnA1sAJVXXhOOqTJKlrDGqL21gCW1UdNkX304DT5rkcSZI6y6Am6NYu0S2SZFWS4zdu3DjuUiRJmhWGNU3o0kkHW6Sq1gBrVqxY8fxx1yJJ0pYwqGlYbwKbJEkLnUFNUzGwSZI0ZgY1bUpvApvXYZMkLTQGNY2qNycdeB02SdJCYljTTPSmhU2SpIXAoKbNYWCTJGkeGNS0JQxskiTNIYOaZkNvApsnHUiSusSgptnUm8DmhXMlSV1gUNNc6E1gkyRpXAxpmmsGNkmSNpNBTfOlN9dhkyRpPhnWNJ9608LmSQeSpLlmSNO49CawedKBJGmuGNQ0br0JbJIkzTaDmrrCwCZJ0hCDmrrGwCZJUsugpq7yLFFJkqSOM7BJkiR1XG8CW5JVSY7fuHHjuEuRJEmaVb0JbFW1pqpWL126dNylSJIkzareBDZJkqS+MrBJkiR1nIFNkiSp4wxskiRJHWdgkyRJ6jgDmyRJUscZ2CRJkjquN/cSTbIKWLV8+fJxlyJJmoHJ7t952ZsOGUMlUnf1JrBV1RpgzYoVK54/7lokSdPzJuvSzPQmsEmSusuAJm0ZA5skadYZ0KTZ5UkHkiRJHWcLmyRpi9iaJs09A5skaWSGM2k8DGySpGkZ0qTxM7BJku7CkCZ1iycdSJIkdZwtbJKk29myJnWTgU2SZFCTOs5dopIkSR3XmxY2b/4uabGxVUxaPHoT2Lz5u6Q+MpRJAneJSpIkdV5vWtgkaaGx9UzSqGxhkyRJ6jhb2CRpjtiCJmm22MImSZLUcbawSdJmsPVM0nyyhU2SJKnjbGGTpAG2nEnqIlvYJEmSOs4WNkmLmi1qkhYCW9gkSZI6zhY2SYuOrWqSFhpb2CRJkjrOFjZJi4Yta5IWKlvYJEmSOs7AJkmS1HGdDmxJHpjkfUk+Pu5aJC1s7g6VtJDNe2BLckKSq5NcMNT9wCSXJFmX5CiAqrq0qo6Y7xolSZK6ZBwtbCcCBw52SLI18A7gIGAf4LAk+8x/aZIkSd0z72eJVtXZSZYNdX4MsK6qLgVIchLwVOCiUaaZZDWwGmDPPfectVq1+LjbbMtc9qZD5n2erjNJi0FXjmHbDbh84PV6YLck90nyLuBRSV4x1chVdXxVraiqFbvssstc1ypJkjSvunIdtkzSrarqOuCF812MJElSl3QlsK0H9hh4vTtwxUwmkGQVsGr58uWzWZc6xt1fkqTFqCu7RM8F9k6yV5IlwKHAqTOZQFWtqarVS5cunZMCJUmSxmUcl/X4KPBl4CFJ1ic5oqpuAY4ETgcuBk6uqgvnuzZJkqQuGsdZoodN0f004LR5LkeSJKnzunIM2xbzGLaFxWPRJEkaXVeOYdtiHsMmSZL6qjeBTZIkqa8MbJIkSR3nMWyL0ODxY+O4lZAkSZqZ3rSweQybJEnqq94ENkmSpL4ysEmSJHWcgU2SJKnjPOmgg7yorCRJGtSbFjZPOpAkSX3Vm8AmSZLUVwY2SZKkjjOwSZIkdZyBTZIkqeM8S3QzeBanJEmaT71pYfMsUUmS1Fe9CWySJEl9ZWCTJEnqOAObJElSxxnYJEmSOq43gS3JqiTHb9y4cdylSJIkzareBDbPEpUkSX3Vm8AmSZLUVwY2SZKkjjOwSZIkdZyBTZIkqeMMbJIkSR1nYJMkSeo4A5skSVLH9SaweeFcSZLUV70JbF44V5Ik9VWqatw1zKok1wDfm+PZ7AxcO8fz0OhcH93i+ugW10e3uD66pQvr4wFVtcumBupdYJsPSdZW1Ypx16GG66NbXB/d4vroFtdHtyyk9dGbXaKSJEl9ZWCTJEnqOAPb5jl+3AXoTlwf3eL66BbXR7e4PrplwawPj2GTJEnqOFvYJEmSOs7AJkmS1HEGthlKcmCSS5KsS3LUuOtZLJJcluQbSc5PsrbttlOSzyX5dvt3x7Z7krytXUdfT7LveKtf+JKckOTqJBcMdJvx8k/ynHb4byd5zjjeSx9MsT6OTvKDdhs5P8nBA/1e0a6PS5I8ZaC732dbKMkeST6f5OIkFyb587a728cYTLM+Fv72UVU+RnwAWwPfAR4ILAH+D9hn3HUthgdwGbDzULe/A45qnx8FHNc+Pxj4DBBgP+Cccde/0B/AE4B9gQs2d/kDOwGXtn93bJ/vOO73thAfU6yPo4G/mmTYfdrvqm2AvdrvsK39Ppu1dXF/YN/2+Q7At9pl7vbRrfWx4LcPW9hm5jHAuqq6tKpuBk4CnjrmmhazpwIfaJ9/AHjaQPcPVuMrwL2T3H8cBfZFVZ0NbBjqPNPl/xTgc1W1oaquBz4HHDj31ffPFOtjKk8FTqqqm6rqu8A6mu8yv89mQVVdWVVfa5/fAFwM7Ibbx1hMsz6msmC2DwPbzOwGXD7wej3TfxA0ewr4bJLzkqxuu92vqq6EZiMF7tt2dz3Nj5kuf9fL3Duy3c12wsQuOFwf8ybJMuBRwDm4fYzd0PqABb59GNhmJpN087oo8+PXq2pf4CDgT5M8YZphXU/jNdXyd73MrX8BHgQ8ErgS+Pu2u+tjHiTZHvgE8NKq+vF0g07SzfUxyyZZHwt++zCwzcx6YI+B17sDV4yplkWlqq5o/14NfIqmufqqiV2d7d+r28FdT/Njpsvf9TKHquqqqrq1qm4D3kOzjYDrY84luTtNOPhwVX2y7ez2MSaTrY8+bB8Gtpk5F9g7yV5JlgCHAqeOuabeS7Jdkh0mngMHABfQLPuJM6meA3y6fX4q8Mft2Vj7ARsndk1oVs10+Z8OHJBkx3Z3xAFtN82CoeM0n06zjUCzPg5Nsk2SvYC9ga/i99msSBLgfcDFVfUPA73cPsZgqvXRh+3jbuOc+UJTVbckOZJmI9oaOKGqLhxzWYvB/YBPNdshdwM+UlX/meRc4OQkRwDfB36vHf40mjOx1gE/BZ47/yX3S5KPAiuBnZOsB14DvIkZLP+q2pDk9TRfhACvq6pRD5zXgCnWx8okj6TZbXMZ8AKAqrowycnARcAtwJ9W1a3tdPw+23K/Djwb+EaS89tuf4Pbx7hMtT4OW+jbh7emkiRJ6jh3iUqSJHWcgU2SJKnjDGySJEkdZ2CTJEnqOAObJElSxxnYJGmRSXJZkjPHXYek0RnYJC0YSe6d5OgkK+dxno9s57lsvuYpScMMbJIWknvTXiR2Huf5yHaey+ZxnpJ0JwY2SeqRidu4SeoXA5ukGUmyJMnLkpyf5KdJNiZZ297GZXC4ZUk+lOSqJDcl+U6SY5Pcc2i4o5NUkoe0/de3w/9fkoMHhlsJfLd9+Zp2nEpy2dD0npXkC0luaOs7J8nvDg3z4nbcVw113zXJNUkuTnLPJEcD7297f35gnidOs3wOb4dZOdDt7kl+0nZ/5ED3HZL8Isk7h6bxtCRfbMf5Sfv8qZPM67IkZyZ5VJLTk2wEvj7Qf48kJ7fr6MdJ1iR50BR1H5LkrCTXJvlZku8n+WSSB0/1XiXNH+8lKmlk7U2QT6fZJflZ4F+BnwOPAJ4BvL0d7gE0N1BeCvwL8K12nFcAv55k/6q6ZWjyHwB+AbwFWAK8FDglyYOr6jLgYuAvgH8EPgV8sh3vJwP1HQP8LfCfwKuA22hu9PyxJEdW1TsAquqdSfanCX6fr6ovJNmqfT87AE+uqp8m+SRwf2A1cGxbA8B3pllM/93+3R84s33+WGC7tp79gYl7HD6B5nv4jIH38GLgHcA3gWNo7n14eLssXlBVxw/Nb892/I8BnwC2b6dzb+BsYA/gXTT3Snwi8HngHoMTSPJEmhtbfwN4I/AjYFfgycBymvUnaZyqyocPHz5GegAvowkQx07Sb6uB5x9uhzt4aJg3t92PGOh2dNvt32nvb9x2f3Tb/Y0D3Za13Y6eZP77TlPbKcCPgR0Guu1IcxPo77fPX9WOf+TQuIe33VfOYDmtA7448PrVwDXAZ4DTBrr/PU2I23mgpp+0499rYLh70YTEG4B7D3S/rK3teZPUcGzb77lD3f+p7X7mQLd/aLvdd9yfMR8+fEz+cJeopJn4Q+B64HXDParqNoC2pep3gP+tqtOGBnsjd7R6DXtrVdXA9M6lCSh7z6C2Aj6QZOfBB03r0Q7A4wamfz3wBzQtaJ+hObHg1Kp6+4jzm84ZwKOTbN++/k2alq3/An4jyd3b7k8Cvl5V17avf4umJe5tVfXjgVp/DPwzTevZk4fmtYE7dtsOehpwFfDBoe7HTTLsxvbvM5O450XqIAObpJnYG/hmVf18mmF2oQkWFw73qKoNwJXAAycZ79JJum0A7jNibQ8FQrMr8Zqhx/vaYe43VM+XaALMY9vh/mTEeW3KGcDdacLZPYD92m5n0CybxyTZEfhVBnaHAnu1f++y7IAL2r/Dy+47VXXrJMM/EPj2cL+qupJml+egtwP/C7wT2JDktCQvSbLLNO9R0jzyPylJM1Wb6J/NnO5koWMm0wtNbQdNM607BaH2mLyntC93ojke7LoR5zediRD2mzTH5W3Tdvt2O/39acLjVtw5sG3OsvvpNP2mWld3mk9VXZfk0cBv0LTyPYHmWMHXJjm4qr68GXVJmkUGNkkz8S3goUm2qaqbphjmappdmQ8b7tG2Kt2fOw66n6npwuK3gQOB71fVxdMMN+iNwAqaY/NeBpyUZN+qunHEeU5eZNXVSS6kCWa3AOur6lsA7R0G9qdpibyV5sSACRMnMzyMO05emLBP+3eylsjJXAo8OMnWg61sSe5PczLIcM230pwkcWY73K8A5wGvBA4ZcZ6S5oi7RCXNxIdpDox/5XCPJIHbj2VbAzwqyYFDgx1F873zqc2c/8QZoTtN0u9D7d9jk2w9SX33HXp9EM1Zpx+oqjfTnFzwYNozXUec53TOoNnl+XTu3Ip2Bs0u0oOAtYPHqgGfA24E/mzwemrt8z9ra/nciPP/NE0r3h8PdX/58IDtcX7Dvgn8jJm/b0lzwBY2STPxVmAV8Mp2F9pnaS7r8TDgIdxxQPzf0OxaO6W9xtg6mt1sz6JpUfrA5sy83XW3Djg0yXdoDqq/sarWVNW5SV4DvBY4P8nHgCtoWvR+DTiY5nIhE61MH6BplTuynfZ/JHkr8OdJTq+qk9rZnktzosTfti2ENwLfrapzNlHuGTQh6yE0LXmD3ZcADwJOHnp/P0ryMprLepwzcL23w2kur/GCqtrIaP6O5qSK9yT5NZrdwStpTry4dmjY9yTZnWZ9fo/msh/PojlRY/ikBUnjMO7TVH348LGwHsC2NNc6u5AmrP2IJtS8eGi4vWhava4GbqbZRXcscM+h4Y6m2e24bJJ5XcbA5Sfabo8BvkgTnAq4bKj/ITTXitsA3ARcTnMW6Iva/lvRnK35c+BRQ+MuAb5Gc9bkXgPdn0NzHbOb23meOMJyujfN7tAC9hjqt77t/uQpxn068KX2Pd7YPn/aKMtnqP+ewMdpLmlyA03L54OGx6O5ht6pbV030ZyAcRbwzHF/3nz48NE8UjXjwzMkSZI0jzyGTZIkqeMMbJIkSR1nYJMkSeo4A5skSVLHGdgkSZI6zsAmSZLUcQY2SZKkjjOwSZIkdZyBTZIkqeP+f+YMPP5+rWxEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = [10,7]\n",
    "plt.title('Number of pairs per context word, ordered by number of pairs per word')\n",
    "plt.bar(range(len(l)), [val[1] for val in l], align='center')\n",
    "#plt.xticks(range(len(l)), [val[0] for val in l])\n",
    "plt.xlabel('context words', fontsize=18)\n",
    "plt.ylabel('number of pairs', fontsize=16)\n",
    "#plt.xticks(rotation=70)\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = [12,7]\n",
    "plt.title('Number of pairs per context word for the 244452/253854 first words ')\n",
    "plt.bar(range(len(l)), [val[1] for val in l], align='center')\n",
    "plt.xticks(range(len(l)), [val[0] for val in l])\n",
    "plt.xlabel('context words', fontsize=18)\n",
    "plt.ylabel('number of pairs', fontsize=16)\n",
    "plt.xticks(rotation=70)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean = 292.75764021839325\n",
      "median = 15.0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'statistics' has no attribute 'min'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-93ef5e02e02d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"mean = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatistics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen_lists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"median = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatistics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen_lists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"minimum = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatistics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen_lists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'statistics' has no attribute 'min'"
     ]
    }
   ],
   "source": [
    "print( \"mean = \" + str(statistics.mean(len_lists)))\n",
    "print( \"median = \" + str(statistics.median(len_lists)))\n",
    "print( \"minimum = \" + str(statistics.min(len_lists)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "starting training\n",
      "batch_size = 1241 || processed_batches = 12270/363429\r"
     ]
    }
   ],
   "source": [
    "#Median\n",
    "w2v = W2V(ds, neg_samples=10, alpha=0.0075,shuffle=True)\n",
    "w2v.train_with_loader()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating vocab\n"
     ]
    }
   ],
   "source": [
    "# Creating whole datasety\n",
    "enwik9_wDataset = wDataSet((enwik9),ctx_window=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "starting training\n",
      "0%==========100%, Time:  02:57:43.88, cum_loss = 542836.375\n",
      "1 epoch of 20\n",
      " 244696 244697 batches, pairs 489393510, cum loss: 542851.43750\n",
      "Current score on wordsim Task: 0.6580580246735275\n",
      "0%==========100%, Time:  02:57:25.32, cum_loss = 524791.9375\n",
      "2 epoch of 20\n",
      " 244696 244697 batches, pairs 489393510, cum loss: 524807.06250\n",
      "Current score on wordsim Task: 0.6651399366885339\n",
      "0%==========100%, Time:  02:42:56.22, cum_loss = 523478.125\n",
      "3 epoch of 20\n",
      " 244696 244697 batches, pairs 489393510, cum loss: 523493.21875\n",
      "Current score on wordsim Task: 0.6644381396072672\n",
      "0%==========100%, Time:  02:58:48.60, cum_loss = 523088.78125\n",
      "4 epoch of 20\n",
      " 244696 244697 batches, pairs 489393510, cum loss: 523103.78125\n",
      "Current score on wordsim Task: 0.6716186405794663\n",
      "0%==========100%, Time:  03:02:41.59, cum_loss = 523442.575\n",
      "5 epoch of 20\n",
      " 244696 244697 batches, pairs 489393510, cum loss: 523457.53125\n",
      "Current score on wordsim Task: 0.676185051156628\n",
      "0%==========100%, Time:  02:55:46.43, cum_loss = 524288.4375\n",
      "6 epoch of 20\n",
      " 244696 244697 batches, pairs 489393510, cum loss: 524303.50000\n",
      "Current score on wordsim Task: 0.6749061536829675\n",
      "0%==========100%, Time:  02:58:48.30, cum_loss = 525010.755\n",
      "7 epoch of 20\n",
      " 244696 244697 batches, pairs 489393510, cum loss: 525025.81250\n",
      "Current score on wordsim Task: 0.6749605183035327\n",
      "0%==========100%, Time:  03:02:33.69, cum_loss = 525540.625\n",
      "8 epoch of 20\n",
      " 244696 244697 batches, pairs 489393510, cum loss: 525555.68750\n",
      "Current score on wordsim Task: 0.6744560926496601\n",
      "0%==========100%, Time:  03:16:09.07, cum_loss = 525977.255\n",
      "9 epoch of 20\n",
      " 244696 244697 batches, pairs 489393510, cum loss: 525992.62500\n",
      "Current score on wordsim Task: 0.669108620088296\n",
      "0%==========100%, Time:  03:13:37.84, cum_loss = 526406.255\n",
      "10 epoch of 20\n",
      " 244696 244697 batches, pairs 489393510, cum loss: 526421.43750\n",
      "Current score on wordsim Task: 0.6618866383489417\n",
      "0%==========100%, Time:  03:02:09.50, cum_loss = 526817.625\n",
      "11 epoch of 20\n",
      " 244696 244697 batches, pairs 489393510, cum loss: 526832.68750\n",
      "Current score on wordsim Task: 0.66952426347481\n",
      "0%==========100%, Time:  03:02:32.89, cum_loss = 527191.125\n",
      "12 epoch of 20\n",
      " 244696 244697 batches, pairs 489393510, cum loss: 527206.06250\n",
      "Current score on wordsim Task: 0.6612676590218918\n",
      "0%==========100%, Time:  03:02:40.53, cum_loss = 527456.375\n",
      "13 epoch of 20\n",
      " 244696 244697 batches, pairs 489393510, cum loss: 527471.50000\n",
      "Current score on wordsim Task: 0.6600279888343876\n",
      "0%==========100%, Time:  02:56:10.99, cum_loss = 527606.9375\n",
      "14 epoch of 20\n",
      " 244696 244697 batches, pairs 489393510, cum loss: 527622.00000\n",
      "Current score on wordsim Task: 0.6555544091799008\n",
      "0%==========100%, Time:  02:55:51.07, cum_loss = 527677.255\n",
      "15 epoch of 20\n",
      " 244696 244697 batches, pairs 489393510, cum loss: 527692.31250\n",
      "Current score on wordsim Task: 0.6619050234018661\n",
      "0%==========100%, Time:  02:55:00.13, cum_loss = 527748.4375\n",
      "16 epoch of 20\n",
      " 244696 244697 batches, pairs 489393510, cum loss: 527763.68750\n",
      "Current score on wordsim Task: 0.661681115757567\n",
      "0%==========100%, Time:  02:55:10.22, cum_loss = 527875.875\n",
      "17 epoch of 20\n",
      " 244696 244697 batches, pairs 489393510, cum loss: 527891.06250\n",
      "Current score on wordsim Task: 0.6659673790640246\n",
      "0%==========100%, Time:  02:57:43.95, cum_loss = 528124.625\n",
      "18 epoch of 20\n",
      " 244696 244697 batches, pairs 489393510, cum loss: 528139.75000\n",
      "Current score on wordsim Task: 0.6651928876623854\n",
      "0%==========100%, Time:  02:57:42.57, cum_loss = 528456.755\n",
      "19 epoch of 20\n",
      " 244696 244697 batches, pairs 489393510, cum loss: 528471.87500\n",
      "Current score on wordsim Task: 0.666018600597232\n",
      "0%==========100%, Time:  02:56:30.92, cum_loss = 528885.875\n",
      "20 epoch of 20\n",
      " 244696 244697 batches, pairs 489393510, cum loss: 528901.00000\n",
      "Current score on wordsim Task: 0.6652057563122343\n",
      "ntm\n",
      "Saving embedding: dict_emb_OptimAdam_momentum0_nesterovFalse_step_size1_gamma1_shuffleTrue_batch_size2000_alpha0.001_dim100_workers2_ctxw5_neg_samples5_use_cudaTrue_iterations20.pkl to disk with ws_score: [0.6580580246735275, 0.6651399366885339, 0.6644381396072672, 0.6716186405794663, 0.676185051156628, 0.6749061536829675, 0.6749605183035327, 0.6744560926496601, 0.669108620088296, 0.6618866383489417, 0.66952426347481, 0.6612676590218918, 0.6600279888343876, 0.6555544091799008, 0.6619050234018661, 0.661681115757567, 0.6659673790640246, 0.6651928876623854, 0.666018600597232, 0.6652057563122343] \n"
     ]
    }
   ],
   "source": [
    "w2v = W2V(enwik9_wDataset, neg_samples=5, alpha=0.001,shuffle=True)\n",
    "w2v.train_with_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ntm\n",
      "Saving embedding: dict_emb_OptimAdam_momentum0_nesterovFalse_step_size1_gamma1_shuffleTrue_batch_size2000_alpha0.001_dim100_workers1_ctxw5_neg_samples5_use_cudaTrue_iterations20.pkl to disk with ws_score: [0.6651699513300704, 0.6644982110172235] \n"
     ]
    }
   ],
   "source": [
    "w2v.save_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = -1*(wordsim_task(w2v.get_embedding())[0][1])\n",
    "w2v.ws_list.append(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "starting training\n",
      "0%======60%, Time:  94:02:32.95, cum_loss = 29342714.0\r"
     ]
    }
   ],
   "source": [
    "ws_lists=[]\n",
    "for i in range(10):\n",
    "    w2v = W2V(enwik9_wDataset, neg_samples=5, alpha=0.001,batch_size=30,iterations=2)\n",
    "    w2v.train_with_loader()\n",
    "    ws_lists.append(np.array(w2v.ws_list))\n",
    "mean_list = [np.mean(x) for x in zip(* ws_lists)]\n",
    "with open(\"mean_list_adam_10runs_enwik9\", 'wb') as output:\n",
    "    pickle.dump(mean_list, output, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"mean_list_adam_10runs_enwik9\", 'wb') as output:\n",
    "    pickle.dump(ws_lists, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6257743894841544,\n",
       " 0.6705295692422975,\n",
       " 0.6804812375824623,\n",
       " 0.6810218187331774,\n",
       " 0.6789483524873088,\n",
       " 0.676725395051269,\n",
       " 0.6769424838360802,\n",
       " 0.6753655497078557,\n",
       " 0.6728324299609623,\n",
       " 0.672059632651494]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "with open(\"mean_list_adam_iter10\", 'rb') as output:\n",
    "        mean_list = pickle.load(output)\n",
    "mean_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.538406581419507,\n",
       " 0.6228384775172953,\n",
       " 0.6515852681869152,\n",
       " 0.6629197884943001,\n",
       " 0.6663014320112144,\n",
       " 0.6652439726413314]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "with open(\"ws_lists_gensim\", 'rb') as output:\n",
    "        ws_lists = pickle.load(output)\n",
    "mean_list = [np.mean(x) for x in zip(* ws_lists)]\n",
    "mean_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-e901cb14a9bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dict_emb_w2vbs7000_neg7_dim100_epochs20_ctxw10_alpha0-075decayhalf.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mdict_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "with open(\"dict_emb_w2vbs7000_neg7_dim100_epochs20_ctxw10_alpha0-075decayhalf.pkl\", 'rb') as output:\n",
    "        dict_emb = pickle.load(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30364346504211426\n",
      "0.45958149433135986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5577877461910248"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import spatial\n",
    "\n",
    "x = spatial.distance.cosine(gensim_emb['love'], gensim_emb['music'])\n",
    "y = spatial.distance.cosine(gensim_emb['anarchism'],gensim_emb['music'])\n",
    "z = spatial.distance.cosine(gensim_emb['revolution'],gensim_emb['creatine'])\n",
    "\n",
    "l = ['music','anarchism','revolution','philosophy','creatine']\n",
    "print(x)\n",
    "print(y)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(5.5450, requires_grad=True),\n",
       " tensor(5.5439, requires_grad=True),\n",
       " tensor(5.5429, requires_grad=True),\n",
       " tensor(5.5426, requires_grad=True),\n",
       " tensor(5.5412, requires_grad=True),\n",
       " tensor(5.5425, requires_grad=True),\n",
       " tensor(5.5414, requires_grad=True),\n",
       " tensor(5.5402, requires_grad=True),\n",
       " tensor(5.5409, requires_grad=True),\n",
       " tensor(5.5391, requires_grad=True),\n",
       " tensor(5.5376, requires_grad=True),\n",
       " tensor(5.5360, requires_grad=True),\n",
       " tensor(5.5368, requires_grad=True),\n",
       " tensor(5.5365, requires_grad=True),\n",
       " tensor(5.5357, requires_grad=True),\n",
       " tensor(5.5351, requires_grad=True),\n",
       " tensor(5.5354, requires_grad=True),\n",
       " tensor(5.5333, requires_grad=True),\n",
       " tensor(5.5336, requires_grad=True)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_emb.pop('loss_list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim_emb = dict()\n",
    "for sentences in text8_dataset:\n",
    "    for word in sentences:\n",
    "        gensim_emb[word] = model.wv[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text8_ds1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-e0e07fdce0fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCallbackAny2Vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext8_ds1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mgensim_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'text8_ds1' is not defined"
     ]
    }
   ],
   "source": [
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "from gensim.models import Word2Vec\n",
    "vocab = set(text8_ds1)\n",
    "gensim_emb = dict()\n",
    "\n",
    "    \n",
    "class EpochLogger(CallbackAny2Vec):\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "        self.cum_loss = 0\n",
    "        self.loss_list = []\n",
    "        self.ws_list = []\n",
    "        self.prev_score = -1\n",
    "        self.no_improvement =0\n",
    "\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        for word in vocab:\n",
    "            gensim_emb[word] = model.wv[word]\n",
    "            \n",
    "        score = -1*wordsim_task(gensim_emb)[0][1]\n",
    "        self.ws_list.append(score)\n",
    "        \n",
    "        if(score - self.prev_score < 0.0009):\n",
    "            self.no_improvement +=1\n",
    "            \n",
    "        print(\"Epoch #{} end: cum_loss={}, ws_score={}\".format(self.epoch,self.cum_loss,score))\n",
    "        \n",
    "        \n",
    "        if(self.no_improvement == 2):\n",
    "            print(\"No improvement in word similarity early stoppage\")\n",
    "            \n",
    "            \n",
    "            \n",
    "        self.epoch += 1\n",
    "        self.prev_score = score\n",
    "    \n",
    "    def on_batch_end(self, model):\n",
    "        \"\"\"Method called at the end of each batch.\n",
    "        Parameters\n",
    "        ----------\n",
    "        model : :class:`~gensim.models.base_any2vec.BaseWordEmbeddingsModel`\n",
    "            Current model.\n",
    "        \"\"\"\n",
    "        self.cum_loss += model.get_latest_training_loss()\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distances(word):\n",
    "    for x in dict_emb.keys():\n",
    "        yield(x, spatial.distance.cosine(dict_emb[word],dict_emb[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Variable that requires grad. Use var.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-0927695588b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mn_dict_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mn_dict_emb_gensim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgensim_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-54-0927695588b9>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mn_dict_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mn_dict_emb_gensim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgensim_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m   2449\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2450\u001b[0m                 \u001b[0msqnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2451\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqnorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2452\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2453\u001b[0m                 \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Variable that requires grad. Use var.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "n_dict_emb = {(word): (x / np.linalg.norm(x)) for (word, x) in (dict_emb.items())}\n",
    "n_dict_emb_gensim = {(word): (x / np.linalg.norm(x)) for (word, x) in (gensim_emb.items())}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANALOGY TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"./data/questions-words.txt\")\n",
    "questions = file.readlines()\n",
    "qeustions_vocab = set()\n",
    "for i,x in enumerate(questions): \n",
    "    questions[i] = x.rstrip(\"\\n\").split()\n",
    "    if x[0]==':':\n",
    "        del questions[i]\n",
    "    else: \n",
    "        for word in x:\n",
    "            questions_vocab.add(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_chunks(file_object, chunk_size=1024):\n",
    "    \"\"\"Lazy function (generator) to read a file piece by piece.\n",
    "    Default chunk size: 1k.\"\"\"\n",
    "    while True:\n",
    "        data = file_object.read(chunk_size)\n",
    "        if not data:\n",
    "            break\n",
    "        yield data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"./data/enwik9\")\n",
    "enwik9 = read_in_chunks(file)\n",
    "l = []\n",
    "for x in enwik9:\n",
    "    l.append(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anarchism',\n",
       " 'originated',\n",
       " 'as',\n",
       " 'a',\n",
       " 'term',\n",
       " 'of',\n",
       " 'abuse',\n",
       " 'first',\n",
       " 'used',\n",
       " 'against',\n",
       " 'early',\n",
       " 'working',\n",
       " 'class',\n",
       " 'radicals',\n",
       " 'including',\n",
       " 'the',\n",
       " 'diggers',\n",
       " 'of',\n",
       " 'the',\n",
       " 'english']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'social relations based upon voluntary association of autonomous individuals mutual aid and self governance while anarchism is most easily defined by what it is against anarchists also offer positive visions of what they believe to be a truly free society however ideas about how an anarchist society might work vary considerably especially with respect to economics there is also disagreement about how a free society might be brought about origins and predecessors kropotkin and others argue that before recorded history human society was organized on anarchist principles most anthropologists follow kropotkin and engels in believing that hunter gatherer bands were egalitarian and lacked division of labour accumulated wealth or decreed law and had equal access to resources william godwin anarchists including the the anarchy organisation and rothbard find anarchist attitudes in taoism from ancient china kropotkin found similar ideas in stoic zeno of citium according to kropotkin zeno repudiated the omnipotence of th'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open(\"./data/questions-words.txt\")\n",
    "questions = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EpochLogger' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-8804cada497e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#TODO: logging, save loss, batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mepoch_logger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEpochLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnegative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch_logger\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EpochLogger' is not defined"
     ]
    }
   ],
   "source": [
    "#TODO: logging, save loss, batch_size\n",
    "epoch_logger = EpochLogger()\n",
    "model = Word2Vec(l, size=100,window=5,negative=10, alpha=0.01, min_count=5, workers=4,sg=1, callbacks=[epoch_logger],compute_loss=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analogy_task(questions,dict_emb):\n",
    "    score = []\n",
    "    if all(word in dict_emb for word in questions):\n",
    "        y = dict_emb[questions[0]] -  dict_emb[questions[1]] +  dict_emb[questions[2]]\n",
    "        x = get_closest_with_score(dict_emb,y)\n",
    "        if x == questions[3]:\n",
    "            score.append(1)\n",
    "        else: \n",
    "            score.append(0)\n",
    "    return score\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# TODO: calculate closest only for a given set of words to get faster computation for analogy task\n",
    "def calculate_sim(dict_emb): \n",
    "    # Create dictionnary with id for every word, this is needed because sometimes we only have access to the dict_emb\n",
    "    # and not the whole model \n",
    "    idx2word = {idx: w for (idx, w) in enumerate(dict_emb.keys())}\n",
    "    word2idx = {w: idx for (idx, w) in enumerate(dict_emb.keys())}\n",
    "    \n",
    "    emb_size = len(next(iter(dict_emb.values())))\n",
    "    \n",
    "    # Create an embedding dictionnary with normalized vectors\n",
    "    normalized_dict_emb = {(word): (x / np.linalg.norm(x)) for (word, x) in (dict_emb.items())}\n",
    "    \n",
    "    # Create an vocab_size*emb_size Matrix that holds the normalized embeding of each word in it's row called matrix_row\n",
    "    # Create an emb_size*vocab_size Matrix that holds the normalized embeding of each word in it's colomn  matrix_colomn\n",
    "    for i in range(0,len(dict_emb.keys())):\n",
    "        y = normalized_dict_emb[idx2word[i]]\n",
    "        if i ==0:\n",
    "            matrix_colomn = torch.tensor(y).view(emb_size,1)\n",
    "            matrix_row = torch.tensor(y)\n",
    "        else:\n",
    "            matrix_colomn = torch.cat([matrix_colomn,torch.tensor(y).view(emb_size,1)],1)\n",
    "            matrix_row = torch.cat([matrix_row,torch.tensor(y)])\n",
    "    \n",
    "    matrix_row = matrix_row.view(-1,emb_size)\n",
    "    \n",
    "    matrix_row = matrix_row.to(device)\n",
    "    matrix_colomn = matrix_colomn.to(device)\n",
    "    \n",
    "    return 1-(torch.matmul(matrix_row,matrix_colomn)),word2idx\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def get_closest(score_dict, word):\n",
    "    closest = ()\n",
    "    distance = 3\n",
    "    for (x,y),score in score_dict.items():\n",
    "        #print(x,y,score)\n",
    "        if((x != y) and ((x==word)or(y==word))):\n",
    "            if (distance > score):\n",
    "                closest = (x,y)\n",
    "                distance = score\n",
    "    return closest\n",
    "\n",
    "def get_closest_with_score(dict_emb,y):\n",
    "    distance = 100\n",
    "    for x,emb in dict_emb.items():\n",
    "        if(spatial.distance.cosine(dict_emb[x], dict_emb[y])<distance):\n",
    "            closest = x\n",
    "    return x\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "list_of_files = []\n",
    "for file in os.listdir(\"/home/c3dric/model/todo\"):\n",
    "        list_of_files.append(file)\n",
    "list_of_files.remove('.ipynb_checkpoints')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list_of_files.remove('shuffle_false')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_emb = []\n",
    "for i,file in enumerate(list_of_files):\n",
    "    with open(\"/home/c3dric/model/todo/\" + file, 'rb') as output:\n",
    "        dict_emb = pickle.load(output)\n",
    "        file_emb.append((file, [float(x) for x in dict_emb['ws_list']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_of_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the saved data into a csv file\n",
    "import re\n",
    "import csv\n",
    "with_0 = r'(\\w*)alpha(\\d.\\d*)_\\w*'\n",
    "without_0 = r'(\\w*)alpha(\\d)_\\w*'\n",
    "sgd_reg = r'(\\w*)momentum0_.*'\n",
    "models_sgd = []\n",
    "models_adam = []\n",
    "models_adagrad = []\n",
    "models_mom = []\n",
    "models_nag = []\n",
    "for model in file_emb:\n",
    "    filename = model[0] \n",
    "    if \"OptimAdagrad\" in filename: \n",
    "        models_adagrad.append(model)\n",
    "    if \"OptimAdam\" in filename: \n",
    "        models_adam.append(model)\n",
    "    if \"OptimSGD\" in filename:\n",
    "        if(re.search(sgd_reg,filename)):\n",
    "            models_sgd.append(model)\n",
    "        elif(\"nesterovFalse\" in filename):\n",
    "            models_mom.append(model)\n",
    "        else:\n",
    "            models_nag.append(model)\n",
    "        \n",
    "assert(len(file_emb) == len(models_sgd + models_adam + models_adagrad + models_mom + models_nag))\n",
    "\n",
    "def create_csv(models,csv_file_name):\n",
    "    lr = []\n",
    "    lr_scores = []\n",
    "    epochs = [[] for x in range(20)]\n",
    "    for model in models:\n",
    "        filename = model[0]\n",
    "        if(re.search (without_0,filename)):\n",
    "            alpha =  int(re.search(without_0,filename).group(2))\n",
    "            lr_scores.append((alpha,model[1]))\n",
    "        if(re.search (with_0,filename)):\n",
    "            alpha =  float(re.search(with_0,filename).group(2))\n",
    "            lr_scores.append((alpha,model[1]))\n",
    "    lr_scores = sorted(lr_scores)\n",
    "    lr = [x[0] for x in lr_scores]\n",
    "    scores = [x[1] for  x in lr_scores]\n",
    "    \n",
    "    for x in lr_scores: \n",
    "        ws_scores = x[1]\n",
    "        for i,score in enumerate(ws_scores):\n",
    "            epochs[i].append(score)\n",
    "        for j in range(i+1,20):\n",
    "            epochs[j].append(\"\")\n",
    "            \n",
    "    \n",
    "    output = [lr] + epochs \n",
    "    \n",
    "    with open(csv_file_name, 'w') as csvFile:\n",
    "        writer = csv.writer(csvFile)\n",
    "        writer.writerows(output)\n",
    "        csvFile.close()\n",
    "\n",
    "\n",
    "create_csv(models_adam,\"adam.csv\")\n",
    "create_csv(models_adagrad,\"adagrad.csv\")\n",
    "create_csv(models_sgd,\"sgd.csv\")\n",
    "create_csv(models_mom,\"mom.csv\")\n",
    "create_csv(models_nag,\"nag.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Taken from https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/word2vec.ipynb##\n",
    "import logging\n",
    "from sklearn.decomposition import IncrementalPCA    # inital reduction\n",
    "from sklearn.manifold import TSNE                   # final reduction\n",
    "import numpy as np                                  # array handling\n",
    "\n",
    "from plotly.offline import init_notebook_mode, iplot, plot\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "def reduce_dimensions(model,vocab, vocab_plot, plot_in_notebook = True):\n",
    "\n",
    "    num_dimensions = 2  # final num dimensions (2D, 3D, etc)\n",
    "\n",
    "    vectors = []        # positions in vector space\n",
    "    labels = []         # keep track of words to label our data again later\n",
    "    for word in vocab:\n",
    "        vectors.append(model[word])\n",
    "        labels.append(word)\n",
    "        \n",
    "    \n",
    "    # convert both lists into numpy vectors for reduction\n",
    "    vectors = np.asarray(vectors)\n",
    "    labels = np.asarray(labels)\n",
    "    \n",
    "    # reduce using t-SNE\n",
    "    vectors = np.asarray(vectors)\n",
    "    logging.info('starting tSNE dimensionality reduction. This may take some time.')\n",
    "    tsne = TSNE(n_components=num_dimensions, random_state=0)\n",
    "    vectors = tsne.fit_transform(vectors)\n",
    "\n",
    "    \n",
    "    x_vals = [v[0] for i,v in enumerate(vectors) if labels[i] in vocab_plot]\n",
    "    y_vals = [v[1] for i,v in enumerate(vectors) if labels[i] in vocab_plot]\n",
    "        \n",
    "    # Create a trace\n",
    "    trace = go.Scatter(\n",
    "        x=x_vals,\n",
    "        y=y_vals,\n",
    "        mode='text',\n",
    "        text=labels\n",
    "        )\n",
    "    \n",
    "    data = [trace]\n",
    "    \n",
    "    logging.info('All done. Plotting.')\n",
    "    \n",
    "    if plot_in_notebook:\n",
    "        init_notebook_mode(connected=True)\n",
    "        iplot(data, filename='word-embedding-plot')\n",
    "    else:\n",
    "        plot(data, filename='word-embedding-plot.html')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['popcorn', 'fruit', 'eat', 'grocery', 'potato', 'seafood', 'butter', 'cabbage', 'drink', 'wine', 'brandy', 'vodka', 'oil', 'grocery', 'cucumber', 'wine']\n",
      "['card', 'luxury', 'gem', 'investor', 'rading', 'earning', 'insuracnce,', 'dividend', 'profit', 'wealth', 'market', 'stock', 'payment', 'money']\n"
     ]
    }
   ],
   "source": [
    "money_vocab = 'card luxury gem investor rading earning insuracnce, dividend profit wealth market stock payment money'.split(\" \")\n",
    "foods_vocab = \"popcorn fruit eat grocery potato seafood butter cabbage drink wine brandy vodka oil grocery cucumber wine \".split()\n",
    "print(foods_vocab)\n",
    "print(money_vocab)\n",
    "dict_emb.pop(\"time\")\n",
    "dict_emb.pop(\"loss_list\")\n",
    "    \n",
    "reduce_dimensions(dict_emb, dict_emb.keys(),money_vocab + foods_vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "hoverinfo": "name",
         "line": {
          "color": "rgb(20,125,190)",
          "shape": "linear"
         },
         "mode": "lines+markers",
         "name": "sgd",
         "type": "scatter",
         "uid": "9fae3d89-8bab-4d46-bf10-01979cd719e8",
         "x": [
          2,
          3,
          4,
          5,
          7,
          8,
          9,
          10,
          11,
          12
         ],
         "y": [
          20,
          20,
          20,
          20,
          20,
          16,
          11,
          20,
          20,
          20
         ]
        },
        {
         "hoverinfo": "text+name",
         "line": {
          "color": "rgb(245,145,30)",
          "shape": "linear"
         },
         "mode": "lines+markers",
         "name": "adam",
         "type": "scatter",
         "uid": "cdcca733-aace-4bd5-b374-739e22d8a2b4",
         "x": [
          1,
          3,
          5,
          8,
          12
         ],
         "y": [
          20,
          14,
          5,
          3,
          20
         ]
        },
        {
         "hoverinfo": "text+name",
         "line": {
          "color": "rgb(25,160,75)",
          "shape": "linear"
         },
         "mode": "lines+markers",
         "name": "adagrad",
         "type": "scatter",
         "uid": "443297e2-65a6-47dc-b2d3-227375149c16",
         "x": [
          4,
          5,
          12,
          13,
          14,
          15,
          16,
          17,
          23
         ],
         "y": [
          20,
          20,
          16,
          13,
          4,
          6,
          11,
          20,
          20
         ]
        },
        {
         "hoverinfo": "text+name",
         "line": {
          "color": "rgb(200,30,135)",
          "shape": "linear"
         },
         "mode": "lines+markers",
         "name": "momentum",
         "type": "scatter",
         "uid": "b5cd40d4-f502-47f0-84df-752074a06502",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8
         ],
         "y": [
          20,
          20,
          13,
          11,
          9,
          20,
          20,
          20
         ]
        },
        {
         "hoverinfo": "text+name",
         "line": {
          "color": "rgb(0,0,0)",
          "shape": "linear"
         },
         "mode": "lines+markers",
         "name": "nag",
         "type": "scatter",
         "uid": "a043cd0e-3182-4585-ab1a-7257feaadbbb",
         "x": [
          2,
          3,
          4,
          5,
          7,
          8
         ],
         "y": [
          20,
          15,
          12,
          12,
          20,
          20
         ]
        }
       ],
       "layout": {
        "height": 500,
        "title": {
         "text": "Time to train vs. learning rate, by optimizer"
        },
        "width": 800,
        "xaxis": {
         "ticktext": [
          5e-05,
          0.0001,
          0.00025,
          0.0005,
          0.00075,
          0.001,
          0.002,
          0.0025,
          0.005,
          0.0075,
          0.01,
          0.025,
          0.05,
          0.075,
          0.1,
          0.25,
          0.5,
          1,
          1.5,
          2,
          2.5,
          3,
          4,
          5,
          7.5,
          10,
          15,
          17.5,
          20,
          22.5,
          25,
          30,
          32.5,
          35,
          40,
          45,
          50
         ],
         "tickvals": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36
         ],
         "title": {
          "text": "Learning rate"
         }
        },
        "yaxis": {
         "autorange": true,
         "tickvals": [
          1,
          2,
          3,
          4,
          5,
          9,
          11,
          12,
          20
         ],
         "title": {
          "text": "Training time in number of Epochs"
         },
         "type": "linear"
        }
       }
      },
      "text/html": [
       "<div id=\"a61591d3-14ab-4feb-b54b-3a43a2eac4f0\" style=\"height: 500px; width: 800px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"a61591d3-14ab-4feb-b54b-3a43a2eac4f0\")) {\n",
       "    Plotly.newPlot(\"a61591d3-14ab-4feb-b54b-3a43a2eac4f0\", [{\"hoverinfo\": \"name\", \"line\": {\"color\": \"rgb(20,125,190)\", \"shape\": \"linear\"}, \"mode\": \"lines+markers\", \"name\": \"sgd\", \"x\": [2, 3, 4, 5, 7, 8, 9, 10, 11, 12], \"y\": [20, 20, 20, 20, 20, 16, 11, 20, 20, 20], \"type\": \"scatter\", \"uid\": \"cf93e276-7ea4-49b2-8073-806c2e526f5b\"}, {\"hoverinfo\": \"text+name\", \"line\": {\"color\": \"rgb(245,145,30)\", \"shape\": \"linear\"}, \"mode\": \"lines+markers\", \"name\": \"adam\", \"x\": [1, 3, 5, 8, 12], \"y\": [20, 14, 5, 3, 20], \"type\": \"scatter\", \"uid\": \"14d124e7-53f0-40f6-a323-226357dc8b2d\"}, {\"hoverinfo\": \"text+name\", \"line\": {\"color\": \"rgb(25,160,75)\", \"shape\": \"linear\"}, \"mode\": \"lines+markers\", \"name\": \"adagrad\", \"x\": [4, 5, 12, 13, 14, 15, 16, 17, 23], \"y\": [20, 20, 16, 13, 4, 6, 11, 20, 20], \"type\": \"scatter\", \"uid\": \"52984550-727b-40b3-a8a0-98c9c20b9ca5\"}, {\"hoverinfo\": \"text+name\", \"line\": {\"color\": \"rgb(200,30,135)\", \"shape\": \"linear\"}, \"mode\": \"lines+markers\", \"name\": \"momentum\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8], \"y\": [20, 20, 13, 11, 9, 20, 20, 20], \"type\": \"scatter\", \"uid\": \"6e998eda-a4bf-4cc7-9f04-9141b89bc371\"}, {\"hoverinfo\": \"text+name\", \"line\": {\"color\": \"rgb(0,0,0)\", \"shape\": \"linear\"}, \"mode\": \"lines+markers\", \"name\": \"nag\", \"x\": [2, 3, 4, 5, 7, 8], \"y\": [20, 15, 12, 12, 20, 20], \"type\": \"scatter\", \"uid\": \"7ed5f19b-9ca8-4a26-a9d6-4bc2d05243c2\"}], {\"height\": 500, \"title\": {\"text\": \"Time to train vs. learning rate, by optimizer\"}, \"width\": 800, \"xaxis\": {\"ticktext\": [5e-05, 0.0001, 0.00025, 0.0005, 0.00075, 0.001, 0.002, 0.0025, 0.005, 0.0075, 0.01, 0.025, 0.05, 0.075, 0.1, 0.25, 0.5, 1, 1.5, 2, 2.5, 3, 4, 5, 7.5, 10, 15, 17.5, 20, 22.5, 25, 30, 32.5, 35, 40, 45, 50], \"tickvals\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36], \"title\": {\"text\": \"Learning rate\"}}, \"yaxis\": {\"autorange\": true, \"tickvals\": [1, 2, 3, 4, 5, 9, 11, 12, 20], \"title\": {\"text\": \"Training time in number of Epochs\"}, \"type\": \"linear\"}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"a61591d3-14ab-4feb-b54b-3a43a2eac4f0\" style=\"height: 500px; width: 800px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"a61591d3-14ab-4feb-b54b-3a43a2eac4f0\")) {\n",
       "    Plotly.newPlot(\"a61591d3-14ab-4feb-b54b-3a43a2eac4f0\", [{\"hoverinfo\": \"name\", \"line\": {\"color\": \"rgb(20,125,190)\", \"shape\": \"linear\"}, \"mode\": \"lines+markers\", \"name\": \"sgd\", \"x\": [2, 3, 4, 5, 7, 8, 9, 10, 11, 12], \"y\": [20, 20, 20, 20, 20, 16, 11, 20, 20, 20], \"type\": \"scatter\", \"uid\": \"cf93e276-7ea4-49b2-8073-806c2e526f5b\"}, {\"hoverinfo\": \"text+name\", \"line\": {\"color\": \"rgb(245,145,30)\", \"shape\": \"linear\"}, \"mode\": \"lines+markers\", \"name\": \"adam\", \"x\": [1, 3, 5, 8, 12], \"y\": [20, 14, 5, 3, 20], \"type\": \"scatter\", \"uid\": \"14d124e7-53f0-40f6-a323-226357dc8b2d\"}, {\"hoverinfo\": \"text+name\", \"line\": {\"color\": \"rgb(25,160,75)\", \"shape\": \"linear\"}, \"mode\": \"lines+markers\", \"name\": \"adagrad\", \"x\": [4, 5, 12, 13, 14, 15, 16, 17, 23], \"y\": [20, 20, 16, 13, 4, 6, 11, 20, 20], \"type\": \"scatter\", \"uid\": \"52984550-727b-40b3-a8a0-98c9c20b9ca5\"}, {\"hoverinfo\": \"text+name\", \"line\": {\"color\": \"rgb(200,30,135)\", \"shape\": \"linear\"}, \"mode\": \"lines+markers\", \"name\": \"momentum\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8], \"y\": [20, 20, 13, 11, 9, 20, 20, 20], \"type\": \"scatter\", \"uid\": \"6e998eda-a4bf-4cc7-9f04-9141b89bc371\"}, {\"hoverinfo\": \"text+name\", \"line\": {\"color\": \"rgb(0,0,0)\", \"shape\": \"linear\"}, \"mode\": \"lines+markers\", \"name\": \"nag\", \"x\": [2, 3, 4, 5, 7, 8], \"y\": [20, 15, 12, 12, 20, 20], \"type\": \"scatter\", \"uid\": \"7ed5f19b-9ca8-4a26-a9d6-4bc2d05243c2\"}], {\"height\": 500, \"title\": {\"text\": \"Time to train vs. learning rate, by optimizer\"}, \"width\": 800, \"xaxis\": {\"ticktext\": [5e-05, 0.0001, 0.00025, 0.0005, 0.00075, 0.001, 0.002, 0.0025, 0.005, 0.0075, 0.01, 0.025, 0.05, 0.075, 0.1, 0.25, 0.5, 1, 1.5, 2, 2.5, 3, 4, 5, 7.5, 10, 15, 17.5, 20, 22.5, 25, 30, 32.5, 35, 40, 45, 50], \"tickvals\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36], \"title\": {\"text\": \"Learning rate\"}}, \"yaxis\": {\"autorange\": true, \"tickvals\": [1, 2, 3, 4, 5, 9, 11, 12, 20], \"title\": {\"text\": \"Training time in number of Epochs\"}, \"type\": \"linear\"}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from plotly.offline import init_notebook_mode, iplot, plot\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "\n",
    "learning_rates = [5e-05, 0.0001,0.00025,0.0005,.00075,.001,0.002,.0025,0.005,0.0075,.01,.025,.05,0.075,0.1,0.25,0.5] + [1,1.5,2,2.5,3,4,5,7.5,10,15,17.5,20,22.5,25,30,32.5,35,40,45,50]\n",
    "lr_dict = {x: i for i,x in enumerate(learning_rates)}\n",
    "# SGD\n",
    "lr_sgd      = [0.00025,0.0005,0.00075,0.001,0.0025,0.005,0.0075,0.01,0.025,0.05]\n",
    "tr_time_sgd = [20,20,20,20,20,16,11,20,20,20]\n",
    "lr_sgd_dict = [lr_dict[x] for x in lr_sgd]\n",
    "assert(len(lr_sgd)== len(tr_time_sgd))\n",
    "# ADAM\n",
    "lr_adam = [0.0001,0.0005,0.001,0.005,0.05]\n",
    "lr_adam_dict = [lr_dict[x] for x in lr_adam]\n",
    "tr_time_adam = [20,14,5,3,20]\n",
    "# adagrad\n",
    "lr_adagrad = [0.00075,0.001,0.05,0.075,0.1,0.25,0.5,1,5]\n",
    "lr_adagrad_dict = [lr_dict[x] for x in lr_adagrad]\n",
    "tr_time_adagrad = [20,20,16,13,4,6,11,20,20]\n",
    "# momentum\n",
    "lr_mom = [0.0001,0.00025,0.0005,0.00075,0.001,0.002,0.0025,0.005] \n",
    "lr_mom_dict = [lr_dict[x] for x in lr_mom]\n",
    "tr_time_mom = [20,20,13,11,9,20,20,20]\n",
    "# NAG\n",
    "lr_nag = [0.00025,0.0005,0.00075,0.001,0.0025,0.005]\n",
    "lr_nag_dict = [lr_dict[x] for x in lr_nag]\n",
    "tr_time_nag = [20,15,12,12,20,20]\n",
    "\n",
    "trace1 = go.Scatter(\n",
    "    x=lr_sgd_dict,\n",
    "    y=tr_time_sgd,\n",
    "    mode='lines+markers',\n",
    "    name=\"sgd\",\n",
    "    hoverinfo='name',\n",
    "    line=dict(\n",
    "        shape='linear',color='rgb(20,125,190)'\n",
    "    )\n",
    ")\n",
    "trace2 = go.Scatter(\n",
    "    x= lr_adam_dict,\n",
    "    y=tr_time_adam,\n",
    "    mode='lines+markers',\n",
    "    name=\"adam\",\n",
    "    hoverinfo='text+name',\n",
    "    line=dict(\n",
    "        shape='linear',color='rgb(245,145,30)'\n",
    "        \n",
    "    )\n",
    ")\n",
    "trace3 = go.Scatter(\n",
    "    x= lr_adagrad_dict,\n",
    "    y=tr_time_adagrad,\n",
    "    mode='lines+markers',\n",
    "    name=\"adagrad\",\n",
    "    hoverinfo='text+name',\n",
    "    line=dict(\n",
    "        shape='linear',color='rgb(25,160,75)'\n",
    "    )\n",
    ")\n",
    "trace4 = go.Scatter(\n",
    "    x= lr_mom_dict,\n",
    "    y=tr_time_mom,\n",
    "    mode='lines+markers',\n",
    "    name=\"momentum\",\n",
    "    hoverinfo='text+name',\n",
    "    line=dict(\n",
    "        shape='linear',color='rgb(200,30,135)'\n",
    "    )\n",
    ")\n",
    "trace5 = go.Scatter(\n",
    "    x= lr_nag_dict,\n",
    "    y=tr_time_nag,\n",
    "    mode='lines+markers',\n",
    "    name=\"nag\",\n",
    "    hoverinfo='text+name',\n",
    "    line=dict(\n",
    "        shape='linear',color='rgb(0,0,0)'\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "data = [trace1,trace2,trace3,trace4,trace5]\n",
    "layout = dict(title = 'Time to train vs. learning rate, by optimizer',\n",
    "                 width = 800,\n",
    "    height = 500,\n",
    "    xaxis = dict(\n",
    "        tickvals = list(lr_dict.values()),\n",
    "        ticktext = list(lr_dict.keys()),\n",
    "      title = \"Learning rate\"\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        type='linear',\n",
    "        title = 'Training time in number of Epochs',\n",
    "        tickvals= [1,2,3,4,5,9,11,12,20],\n",
    "        autorange=True\n",
    "    )\n",
    "              )\n",
    "\n",
    "print(layout[\"xaxis\"][\"tickvals\"])\n",
    "fig = dict(data=data, layout=layout)\n",
    "init_notebook_mode(connected=True)\n",
    "iplot(fig, filename='word-embedding-plot.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "hoverinfo": "name",
         "line": {
          "color": "rgb(20,125,190)",
          "dash": "dot",
          "shape": "linear"
         },
         "mode": "lines+markers",
         "name": "sgd_shuffle",
         "type": "scatter",
         "uid": "bfc8e278-cf89-47aa-8d3b-0b451a5988cf",
         "x": [
          2,
          3,
          4,
          5,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14
         ],
         "y": [
          20,
          20,
          20,
          20,
          20,
          19,
          11,
          11,
          11,
          7,
          20,
          20
         ]
        },
        {
         "hoverinfo": "text+name",
         "line": {
          "color": "rgb(245,145,30)",
          "dash": "dot",
          "shape": "linear"
         },
         "mode": "lines+markers",
         "name": "adam_shuffle",
         "type": "scatter",
         "uid": "949ddd68-8805-45e1-82d7-ba4394681be1",
         "x": [
          3,
          5,
          8,
          12,
          14,
          16,
          17,
          18
         ],
         "y": [
          20,
          2,
          2,
          7,
          8,
          15,
          20,
          20
         ]
        },
        {
         "hoverinfo": "text+name",
         "line": {
          "color": "rgb(25,160,75)",
          "dash": "dot",
          "shape": "linear"
         },
         "mode": "lines+markers",
         "name": "adagrad_shuffle",
         "type": "scatter",
         "uid": "0f4cf6fe-387d-4978-a46f-c2d65227848d",
         "x": [
          4,
          5,
          12,
          13,
          14,
          15,
          16,
          17,
          19,
          23
         ],
         "y": [
          20,
          20,
          4,
          3,
          3,
          8,
          20,
          20,
          20,
          20
         ]
        },
        {
         "hoverinfo": "text+name",
         "line": {
          "color": "rgb(200,30,135)",
          "dash": "dot",
          "shape": "linear"
         },
         "mode": "lines+markers",
         "name": "momentum_suffle",
         "type": "scatter",
         "uid": "96b90d0a-107f-43db-a693-8102b03566b2",
         "x": [
          3,
          4,
          6,
          7,
          12
         ],
         "y": [
          17,
          12,
          8,
          9,
          20
         ]
        },
        {
         "hoverinfo": "text+name",
         "line": {
          "color": "rgb(0,0,0)",
          "dash": "dot",
          "shape": "linear"
         },
         "mode": "lines+markers",
         "name": "nag_shuffle",
         "type": "scatter",
         "uid": "3e216455-26f9-4268-988f-87274816c68f",
         "x": [
          2,
          3,
          4,
          5,
          7,
          8,
          9,
          12
         ],
         "y": [
          20,
          19,
          9,
          9,
          7,
          3,
          20,
          20
         ]
        }
       ],
       "layout": {
        "height": 500,
        "title": {
         "text": "Time to train vs. learning rate, by optimizer"
        },
        "width": 800,
        "xaxis": {
         "ticktext": [
          5e-05,
          0.0001,
          0.00025,
          0.0005,
          0.00075,
          0.001,
          0.002,
          0.0025,
          0.005,
          0.0075,
          0.01,
          0.025,
          0.05,
          0.075,
          0.1,
          0.25,
          0.5,
          1,
          1.5,
          2,
          2.5,
          3,
          4,
          5,
          7.5,
          10,
          15,
          17.5,
          20,
          22.5,
          25,
          30,
          32.5,
          35,
          40,
          45,
          50
         ],
         "tickvals": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36
         ],
         "title": {
          "text": "Learning rate"
         }
        },
        "yaxis": {
         "autorange": true,
         "tickvals": [
          1,
          2,
          3,
          7,
          8,
          15,
          20
         ],
         "title": {
          "text": "Training time in number of Epochs"
         },
         "type": "linear"
        }
       }
      },
      "text/html": [
       "<div id=\"5701084d-2a85-463c-8c20-da4444421b78\" style=\"height: 500px; width: 800px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"5701084d-2a85-463c-8c20-da4444421b78\")) {\n",
       "    Plotly.newPlot(\"5701084d-2a85-463c-8c20-da4444421b78\", [{\"hoverinfo\": \"name\", \"line\": {\"color\": \"rgb(20,125,190)\", \"dash\": \"dot\", \"shape\": \"linear\"}, \"mode\": \"lines+markers\", \"name\": \"sgd_shuffle\", \"x\": [2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14], \"y\": [20, 20, 20, 20, 20, 19, 11, 11, 11, 7, 20, 20], \"type\": \"scatter\", \"uid\": \"e8e4cc85-be3c-4010-a3d7-79d8a28308e8\"}, {\"hoverinfo\": \"text+name\", \"line\": {\"color\": \"rgb(245,145,30)\", \"dash\": \"dot\", \"shape\": \"linear\"}, \"mode\": \"lines+markers\", \"name\": \"adam_shuffle\", \"x\": [3, 5, 8, 12, 14, 16, 17, 18], \"y\": [20, 2, 2, 7, 8, 15, 20, 20], \"type\": \"scatter\", \"uid\": \"de151cc9-4f9f-403f-922c-3aee35fc2ee7\"}, {\"hoverinfo\": \"text+name\", \"line\": {\"color\": \"rgb(25,160,75)\", \"dash\": \"dot\", \"shape\": \"linear\"}, \"mode\": \"lines+markers\", \"name\": \"adagrad_shuffle\", \"x\": [4, 5, 12, 13, 14, 15, 16, 17, 19, 23], \"y\": [20, 20, 4, 3, 3, 8, 20, 20, 20, 20], \"type\": \"scatter\", \"uid\": \"db04b724-b21a-4622-8947-2263a735577f\"}, {\"hoverinfo\": \"text+name\", \"line\": {\"color\": \"rgb(200,30,135)\", \"dash\": \"dot\", \"shape\": \"linear\"}, \"mode\": \"lines+markers\", \"name\": \"momentum_suffle\", \"x\": [3, 4, 6, 7, 12], \"y\": [17, 12, 8, 9, 20], \"type\": \"scatter\", \"uid\": \"731c3555-9d5f-43c1-bddf-0265564d2eba\"}, {\"hoverinfo\": \"text+name\", \"line\": {\"color\": \"rgb(0,0,0)\", \"dash\": \"dot\", \"shape\": \"linear\"}, \"mode\": \"lines+markers\", \"name\": \"nag_shuffle\", \"x\": [2, 3, 4, 5, 7, 8, 9, 12], \"y\": [20, 19, 9, 9, 7, 3, 20, 20], \"type\": \"scatter\", \"uid\": \"fb5d9975-619f-4125-a456-40de22d944e7\"}], {\"height\": 500, \"title\": {\"text\": \"Time to train vs. learning rate, by optimizer\"}, \"width\": 800, \"xaxis\": {\"ticktext\": [5e-05, 0.0001, 0.00025, 0.0005, 0.00075, 0.001, 0.002, 0.0025, 0.005, 0.0075, 0.01, 0.025, 0.05, 0.075, 0.1, 0.25, 0.5, 1, 1.5, 2, 2.5, 3, 4, 5, 7.5, 10, 15, 17.5, 20, 22.5, 25, 30, 32.5, 35, 40, 45, 50], \"tickvals\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36], \"title\": {\"text\": \"Learning rate\"}}, \"yaxis\": {\"autorange\": true, \"tickvals\": [1, 2, 3, 7, 8, 15, 20], \"title\": {\"text\": \"Training time in number of Epochs\"}, \"type\": \"linear\"}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"5701084d-2a85-463c-8c20-da4444421b78\" style=\"height: 500px; width: 800px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"5701084d-2a85-463c-8c20-da4444421b78\")) {\n",
       "    Plotly.newPlot(\"5701084d-2a85-463c-8c20-da4444421b78\", [{\"hoverinfo\": \"name\", \"line\": {\"color\": \"rgb(20,125,190)\", \"dash\": \"dot\", \"shape\": \"linear\"}, \"mode\": \"lines+markers\", \"name\": \"sgd_shuffle\", \"x\": [2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14], \"y\": [20, 20, 20, 20, 20, 19, 11, 11, 11, 7, 20, 20], \"type\": \"scatter\", \"uid\": \"e8e4cc85-be3c-4010-a3d7-79d8a28308e8\"}, {\"hoverinfo\": \"text+name\", \"line\": {\"color\": \"rgb(245,145,30)\", \"dash\": \"dot\", \"shape\": \"linear\"}, \"mode\": \"lines+markers\", \"name\": \"adam_shuffle\", \"x\": [3, 5, 8, 12, 14, 16, 17, 18], \"y\": [20, 2, 2, 7, 8, 15, 20, 20], \"type\": \"scatter\", \"uid\": \"de151cc9-4f9f-403f-922c-3aee35fc2ee7\"}, {\"hoverinfo\": \"text+name\", \"line\": {\"color\": \"rgb(25,160,75)\", \"dash\": \"dot\", \"shape\": \"linear\"}, \"mode\": \"lines+markers\", \"name\": \"adagrad_shuffle\", \"x\": [4, 5, 12, 13, 14, 15, 16, 17, 19, 23], \"y\": [20, 20, 4, 3, 3, 8, 20, 20, 20, 20], \"type\": \"scatter\", \"uid\": \"db04b724-b21a-4622-8947-2263a735577f\"}, {\"hoverinfo\": \"text+name\", \"line\": {\"color\": \"rgb(200,30,135)\", \"dash\": \"dot\", \"shape\": \"linear\"}, \"mode\": \"lines+markers\", \"name\": \"momentum_suffle\", \"x\": [3, 4, 6, 7, 12], \"y\": [17, 12, 8, 9, 20], \"type\": \"scatter\", \"uid\": \"731c3555-9d5f-43c1-bddf-0265564d2eba\"}, {\"hoverinfo\": \"text+name\", \"line\": {\"color\": \"rgb(0,0,0)\", \"dash\": \"dot\", \"shape\": \"linear\"}, \"mode\": \"lines+markers\", \"name\": \"nag_shuffle\", \"x\": [2, 3, 4, 5, 7, 8, 9, 12], \"y\": [20, 19, 9, 9, 7, 3, 20, 20], \"type\": \"scatter\", \"uid\": \"fb5d9975-619f-4125-a456-40de22d944e7\"}], {\"height\": 500, \"title\": {\"text\": \"Time to train vs. learning rate, by optimizer\"}, \"width\": 800, \"xaxis\": {\"ticktext\": [5e-05, 0.0001, 0.00025, 0.0005, 0.00075, 0.001, 0.002, 0.0025, 0.005, 0.0075, 0.01, 0.025, 0.05, 0.075, 0.1, 0.25, 0.5, 1, 1.5, 2, 2.5, 3, 4, 5, 7.5, 10, 15, 17.5, 20, 22.5, 25, 30, 32.5, 35, 40, 45, 50], \"tickvals\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36], \"title\": {\"text\": \"Learning rate\"}}, \"yaxis\": {\"autorange\": true, \"tickvals\": [1, 2, 3, 7, 8, 15, 20], \"title\": {\"text\": \"Training time in number of Epochs\"}, \"type\": \"linear\"}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from plotly.offline import init_notebook_mode, iplot, plot\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "#learning_rates = [0.00025,0.0005,.00075,.001,0.1,0.25,0.5] + [2.5,5,7.5,10,15,20,22.5]\n",
    "#lr_dict = {x: i for i,x in enumerate(learning_rates)}\n",
    "# sgd_shuffle\n",
    "lr_sgd_shuffle    = [0.00025,0.0005,0.00075,0.001,0.0025,0.005,0.0075,0.01,0.025,0.05,0.075,0.1]\n",
    "tr_time_sgd_shuffle = [20,20,20,20,20,19,11,11,11,7,20,20]\n",
    "lr_sgd_shuffle_dict = [lr_dict[x] for x in lr_sgd_shuffle]\n",
    "assert len(lr_sgd_shuffle) == len(tr_time_sgd_shuffle)\n",
    "\n",
    "# adam_shuffle\n",
    "lr_adam_shuffle = [0.0001,0.0005,0.001,0.005,0.05,0.1]\n",
    "lr_adam_shuffle_dict = [lr_dict[x] for x in lr_adam_shuffle]\n",
    "tr_time_adam_shuffle = [20,4,2,157,8,15,20,20]\n",
    "assert len(lr_adam_shuffle) == len(tr_time_adam_shuffle), (str(len(lr_adam_shuffle))+ \" \"+ str(len(tr_time_adam_shuffle)))\n",
    "\n",
    "# adagrad_shuffle\n",
    "lr_adagrad_shuffle = [0.00075,0.001,0.05,0.075,0.1,0.25,0.5,1,2,5]\n",
    "lr_adagrad_shuffle_dict = [lr_dict[x] for x in lr_adagrad_shuffle]\n",
    "tr_time_adagrad_shuffle = [20,20,4,3,3,8,20,20,20,20]\n",
    "assert len(lr_adagrad_shuffle) == len(tr_time_adagrad_shuffle), (str(len(lr_adagrad_shuffle))+ \" \"+ str(len(tr_time_adagrad_shuffle)))\n",
    "\n",
    "\n",
    "# mom_suffleentum\n",
    "lr_mom_suffle = [0.0005,0.00075,0.002,0.0025,0.05] \n",
    "lr_mom_suffle_dict = [lr_dict[x] for x in lr_mom_suffle]\n",
    "tr_time_mom_suffle = [17,12,8,9,20]\n",
    "assert len(lr_mom_suffle) == len(tr_time_mom_suffle), (str(len(lr_mom_suffle))+ \" \"+ str(len(tr_time_mom_suffle)))\n",
    "\n",
    "\n",
    "# nag_shuffle\n",
    "lr_nag_shuffle = [0.00025,0.0005,0.00075,0.001,0.0025,0.005,0.0075,0.05]\n",
    "lr_nag_shuffle_dict = [lr_dict[x] for x in lr_nag_shuffle]\n",
    "tr_time_nag_shuffle = [20,19,9,9,7,3,20,20]\n",
    "assert len(lr_nag_shuffle) == len(tr_time_nag_shuffle),(str(len(lr_nag_shuffle))+ \" \"+ str(len(tr_time_nag_shuffle)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "trace1a = go.Scatter(\n",
    "    x=lr_sgd_shuffle_dict,\n",
    "    y=tr_time_sgd_shuffle,\n",
    "    mode='lines+markers',\n",
    "    name=\"sgd_shuffle\",\n",
    "    hoverinfo='name',\n",
    "    line=dict(\n",
    "        shape='linear',dash='dot',color='rgb(20,125,190)'\n",
    "    )\n",
    ")\n",
    "trace2a = go.Scatter(\n",
    "    x= lr_adam_shuffle_dict,\n",
    "    y=tr_time_adam_shuffle,\n",
    "    mode='lines+markers',\n",
    "    name=\"adam_shuffle\",\n",
    "    hoverinfo='text+name',\n",
    "    line=dict(\n",
    "        shape='linear',dash='dot',color='rgb(245,145,30)'\n",
    "        \n",
    "    )\n",
    ")\n",
    "trace3a = go.Scatter(\n",
    "    x= lr_adagrad_shuffle_dict,\n",
    "    y=tr_time_adagrad_shuffle,\n",
    "    mode='lines+markers',\n",
    "    name=\"adagrad_shuffle\",\n",
    "    hoverinfo='text+name',\n",
    "    line=dict(\n",
    "        shape='linear',dash='dot',color='rgb(25,160,75)'\n",
    "    )\n",
    ")\n",
    "trace4a = go.Scatter(\n",
    "    x= lr_mom_suffle_dict,\n",
    "    y=tr_time_mom_suffle,\n",
    "    mode='lines+markers',\n",
    "    name=\"momentum_suffle\",\n",
    "    hoverinfo='text+name',\n",
    "    line=dict(\n",
    "        shape='linear',dash='dot',color='rgb(200,30,135)'\n",
    "    )\n",
    ")\n",
    "trace5a = go.Scatter(\n",
    "    x= lr_nag_shuffle_dict,\n",
    "    y=tr_time_nag_shuffle,\n",
    "    mode='lines+markers',\n",
    "    name=\"nag_shuffle\",\n",
    "    hoverinfo='text+name',\n",
    "    line=dict(\n",
    "        shape='linear',dash='dot',color='rgb(0,0,0)'\n",
    "    )\n",
    ")\n",
    "data_a = [trace1a,trace2a,trace3a,trace4a,trace5a] \n",
    "data = data + data_a\n",
    "layout = dict(title = 'Time to train vs. learning rate, by optimizer',\n",
    "                 width = 800,\n",
    "    height = 500,\n",
    "    xaxis = dict(\n",
    "        tickvals = list(lr_dict.values()),\n",
    "        ticktext = list(lr_dict.keys()),\n",
    "      title = \"Learning rate\"\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        type='linear',\n",
    "        title = 'Training time in number of Epochs',\n",
    "        tickvals=[1,2,3,7,8,15,20],\n",
    "        autorange=True\n",
    "    )\n",
    "              )\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "fig1 = dict(data=data_a, layout=layout)\n",
    "init_notebook_mode(connected=True)\n",
    "#iplot(fig, filename='word-embedding-plot')\n",
    "iplot(fig1, filename='word-embedding-plot')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "hoverinfo": "name",
         "line": {
          "color": "rgb(139,0,0)",
          "shape": "linear"
         },
         "mode": "lines+markers",
         "name": "gensim",
         "type": "scatter",
         "uid": "5c8b7ec2-d4af-4f24-ad23-fbafe04424d2",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
         ],
         "y": [
          0,
          0.47,
          0.59,
          0.63,
          0.637,
          0.649,
          0.64991,
          0.653,
          0.664,
          0.6655,
          0.6615,
          0.6629,
          0.663
         ]
        },
        {
         "hoverinfo": "text+name",
         "line": {
          "color": "rgb(20,125,190)",
          "dash": "dot",
          "shape": "linear"
         },
         "mode": "lines+markers",
         "name": "SGD_shuffle",
         "type": "scatter",
         "uid": "d373b57d-2b1b-4a60-8122-c9e7d2fb38c0",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
         ],
         "y": [
          0,
          0.3979027932,
          0.5345590809,
          0.5957749206,
          0.6150409906,
          0.6343477449,
          0.6408864911,
          0.6569273384,
          0.6638613219,
          0.664644281,
          0.6684268463,
          0.6676506492
         ]
        },
        {
         "hoverinfo": "name",
         "line": {
          "color": "rgb(20,125,190)",
          "shape": "linear"
         },
         "mode": "lines+markers",
         "name": "gensim",
         "type": "scatter",
         "uid": "c85364dd-6a81-4a03-94d0-e6d011ab9a02",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
         ],
         "y": [
          0,
          0.2656567075,
          0.409453666,
          0.4961671944,
          0.5470711378,
          0.58201276,
          0.608320445,
          0.6224159501,
          0.6369093127,
          0.6457120334,
          0.653658488,
          0.6585042924,
          0.6608316399
         ]
        },
        {
         "hoverinfo": "text+name",
         "line": {
          "color": "rgb(245,145,30)",
          "dash": "dot",
          "shape": "linear"
         },
         "mode": "lines+markers",
         "name": "adam_shuffle",
         "type": "scatter",
         "uid": "3176425e-2746-428e-a14f-7993511e3afd",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
         ],
         "y": [
          0,
          0.6209724591,
          0.6648207026,
          0.6608316399,
          0.6653500479,
          0.6667224712
         ]
        },
        {
         "hoverinfo": "text+name",
         "line": {
          "color": "rgb(245,145,30)",
          "shape": "linear"
         },
         "mode": "lines+markers",
         "name": "adam_shuffle",
         "type": "scatter",
         "uid": "f14efa63-6541-490e-bcb1-34c138500202",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
         ],
         "y": [
          0,
          0.5274663249,
          0.6317800941,
          0.6661224712,
          0.6663352711,
          0.6692290085,
          0.6709985856,
          0.6687059277,
          0.6676404941
         ]
        }
       ],
       "layout": {
        "height": 500,
        "title": {
         "text": "Convergence time comparison"
        },
        "width": 800,
        "xaxis": {
         "title": {
          "text": "Training time in number of Epochs"
         }
        },
        "yaxis": {
         "autorange": true,
         "title": {
          "text": "Word similarity"
         },
         "type": "linear"
        }
       }
      },
      "text/html": [
       "<div id=\"8a35eeec-8a18-4e42-8684-4690508dcf04\" style=\"height: 500px; width: 800px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"8a35eeec-8a18-4e42-8684-4690508dcf04\")) {\n",
       "    Plotly.newPlot(\"8a35eeec-8a18-4e42-8684-4690508dcf04\", [{\"hoverinfo\": \"name\", \"line\": {\"color\": \"rgb(139,0,0)\", \"shape\": \"linear\"}, \"mode\": \"lines+markers\", \"name\": \"gensim\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], \"y\": [0, 0.47, 0.59, 0.63, 0.637, 0.649, 0.64991, 0.653, 0.664, 0.6655, 0.6615, 0.6629, 0.663], \"type\": \"scatter\", \"uid\": \"be9e8749-976d-4609-b607-ff7766bfcb9d\"}, {\"hoverinfo\": \"text+name\", \"line\": {\"color\": \"rgb(20,125,190)\", \"dash\": \"dot\", \"shape\": \"linear\"}, \"mode\": \"lines+markers\", \"name\": \"SGD_shuffle\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], \"y\": [0, 0.3979027932, 0.5345590809, 0.5957749206, 0.6150409906, 0.6343477449, 0.6408864911, 0.6569273384, 0.6638613219, 0.664644281, 0.6684268463, 0.6676506492], \"type\": \"scatter\", \"uid\": \"8ac49cd4-cd26-49f7-b337-3901cabe544d\"}, {\"hoverinfo\": \"name\", \"line\": {\"color\": \"rgb(20,125,190)\", \"shape\": \"linear\"}, \"mode\": \"lines+markers\", \"name\": \"gensim\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], \"y\": [0, 0.2656567075, 0.409453666, 0.4961671944, 0.5470711378, 0.58201276, 0.608320445, 0.6224159501, 0.6369093127, 0.6457120334, 0.653658488, 0.6585042924, 0.6608316399], \"type\": \"scatter\", \"uid\": \"e066aafc-c475-48a1-88bd-30ccb8fc7b30\"}, {\"hoverinfo\": \"text+name\", \"line\": {\"color\": \"rgb(245,145,30)\", \"dash\": \"dot\", \"shape\": \"linear\"}, \"mode\": \"lines+markers\", \"name\": \"adam_shuffle\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], \"y\": [0, 0.6209724591, 0.6648207026, 0.6608316399, 0.6653500479, 0.6667224712], \"type\": \"scatter\", \"uid\": \"e6ed0982-e110-43f0-aa8a-8db539a2bb01\"}, {\"hoverinfo\": \"text+name\", \"line\": {\"color\": \"rgb(245,145,30)\", \"shape\": \"linear\"}, \"mode\": \"lines+markers\", \"name\": \"adam_shuffle\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], \"y\": [0, 0.5274663249, 0.6317800941, 0.6661224712, 0.6663352711, 0.6692290085, 0.6709985856, 0.6687059277, 0.6676404941], \"type\": \"scatter\", \"uid\": \"74fa9a02-3fd8-4475-ad4f-7cc792ed7e8e\"}], {\"height\": 500, \"title\": {\"text\": \"Convergence time comparison\"}, \"width\": 800, \"xaxis\": {\"title\": {\"text\": \"Training time in number of Epochs\"}}, \"yaxis\": {\"autorange\": true, \"title\": {\"text\": \"Word similarity\"}, \"type\": \"linear\"}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"8a35eeec-8a18-4e42-8684-4690508dcf04\" style=\"height: 500px; width: 800px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"8a35eeec-8a18-4e42-8684-4690508dcf04\")) {\n",
       "    Plotly.newPlot(\"8a35eeec-8a18-4e42-8684-4690508dcf04\", [{\"hoverinfo\": \"name\", \"line\": {\"color\": \"rgb(139,0,0)\", \"shape\": \"linear\"}, \"mode\": \"lines+markers\", \"name\": \"gensim\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], \"y\": [0, 0.47, 0.59, 0.63, 0.637, 0.649, 0.64991, 0.653, 0.664, 0.6655, 0.6615, 0.6629, 0.663], \"type\": \"scatter\", \"uid\": \"be9e8749-976d-4609-b607-ff7766bfcb9d\"}, {\"hoverinfo\": \"text+name\", \"line\": {\"color\": \"rgb(20,125,190)\", \"dash\": \"dot\", \"shape\": \"linear\"}, \"mode\": \"lines+markers\", \"name\": \"SGD_shuffle\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], \"y\": [0, 0.3979027932, 0.5345590809, 0.5957749206, 0.6150409906, 0.6343477449, 0.6408864911, 0.6569273384, 0.6638613219, 0.664644281, 0.6684268463, 0.6676506492], \"type\": \"scatter\", \"uid\": \"8ac49cd4-cd26-49f7-b337-3901cabe544d\"}, {\"hoverinfo\": \"name\", \"line\": {\"color\": \"rgb(20,125,190)\", \"shape\": \"linear\"}, \"mode\": \"lines+markers\", \"name\": \"gensim\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], \"y\": [0, 0.2656567075, 0.409453666, 0.4961671944, 0.5470711378, 0.58201276, 0.608320445, 0.6224159501, 0.6369093127, 0.6457120334, 0.653658488, 0.6585042924, 0.6608316399], \"type\": \"scatter\", \"uid\": \"e066aafc-c475-48a1-88bd-30ccb8fc7b30\"}, {\"hoverinfo\": \"text+name\", \"line\": {\"color\": \"rgb(245,145,30)\", \"dash\": \"dot\", \"shape\": \"linear\"}, \"mode\": \"lines+markers\", \"name\": \"adam_shuffle\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], \"y\": [0, 0.6209724591, 0.6648207026, 0.6608316399, 0.6653500479, 0.6667224712], \"type\": \"scatter\", \"uid\": \"e6ed0982-e110-43f0-aa8a-8db539a2bb01\"}, {\"hoverinfo\": \"text+name\", \"line\": {\"color\": \"rgb(245,145,30)\", \"shape\": \"linear\"}, \"mode\": \"lines+markers\", \"name\": \"adam_shuffle\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], \"y\": [0, 0.5274663249, 0.6317800941, 0.6661224712, 0.6663352711, 0.6692290085, 0.6709985856, 0.6687059277, 0.6676404941], \"type\": \"scatter\", \"uid\": \"74fa9a02-3fd8-4475-ad4f-7cc792ed7e8e\"}], {\"height\": 500, \"title\": {\"text\": \"Convergence time comparison\"}, \"width\": 800, \"xaxis\": {\"title\": {\"text\": \"Training time in number of Epochs\"}}, \"yaxis\": {\"autorange\": true, \"title\": {\"text\": \"Word similarity\"}, \"type\": \"linear\"}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from plotly.offline import init_notebook_mode, iplot, plot\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "gensim_conv = [0,0.47 ,0.59,0.63,0.637,0.649, 0.64991,0.653,0.664,0.6655,0.6615,0.6629,0.663] \n",
    "adam_conv = [0,0.5274663249,0.6317800941,0.6661224712,0.6663352711,0.6692290085, 0.6709985856, 0.6687059277, 0.6676404941]\n",
    "adam_shuffle_conv = [0,0.6209724591, 0.6648207026,0.6608316399,0.6653500479,0.6667224712]\n",
    "sgd_conv = [0,0.2656567075,0.409453666,0.4961671944,0.5470711378,0.58201276,0.608320445,0.6224159501,0.6369093127,0.6457120334,0.653658488,0.6585042924,0.6608316399]\n",
    "sgd_shuffle_conv = [0,0.3979027932,0.5345590809,0.5957749206,0.6150409906,0.6343477449,0.6408864911,0.6569273384,0.6638613219,0.664644281,0.6684268463,0.6676506492]\n",
    "\n",
    "epoches = list(range(20))\n",
    "trace1 = go.Scatter(\n",
    "    x=epoches,\n",
    "    y=gensim_conv,\n",
    "    mode='lines+markers',\n",
    "    name=\"gensim\",\n",
    "    hoverinfo='name',\n",
    "    line=dict(\n",
    "        shape='linear',color='rgb(139,0,0)'\n",
    "    )\n",
    ")\n",
    "trace2 = go.Scatter(\n",
    "    x= epoches,\n",
    "    y=sgd_shuffle_conv,\n",
    "    mode='lines+markers',\n",
    "    name=\"SGD_shuffle\",\n",
    "    hoverinfo='text+name',\n",
    "    line=dict(\n",
    "        shape='linear',dash='dot',color='rgb(20,125,190)'\n",
    "        \n",
    "    )\n",
    ")\n",
    "trace3 = go.Scatter(\n",
    "    x=epoches,\n",
    "    y=sgd_conv,\n",
    "    mode='lines+markers',\n",
    "    name=\"gensim\",\n",
    "    hoverinfo='name',\n",
    "    line=dict(\n",
    "        shape='linear',color='rgb(20,125,190)'\n",
    "    )\n",
    ")\n",
    "trace4 = go.Scatter(\n",
    "    x= epoches,\n",
    "    y=adam_shuffle_conv,\n",
    "    mode='lines+markers',\n",
    "    name=\"adam_shuffle\",\n",
    "    hoverinfo='text+name',\n",
    "    line=dict(\n",
    "        shape='linear',dash='dot',color='rgb(245,145,30)'\n",
    "        \n",
    "    )\n",
    ")\n",
    "trace5 = go.Scatter(\n",
    "    x= epoches,\n",
    "    y=adam_conv,\n",
    "    mode='lines+markers',\n",
    "    name=\"adam_shuffle\",\n",
    "    hoverinfo='text+name',\n",
    "    line=dict(\n",
    "        shape='linear',color='rgb(245,145,30)'\n",
    "        \n",
    "    )\n",
    ")\n",
    "\n",
    "data = [trace1,trace2,trace3,trace4,trace5]\n",
    "layout = dict(title = 'Convergence time comparison',\n",
    "                 width = 800,\n",
    "    height = 500,\n",
    "    xaxis = dict(\n",
    "      title = 'Training time in number of Epochs'\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        type='linear',\n",
    "        title = \"Word similarity\",\n",
    "             autorange=True\n",
    "    )\n",
    "              )\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "init_notebook_mode(connected=True)\n",
    "iplot(fig, filename='word-embedding-plot.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
