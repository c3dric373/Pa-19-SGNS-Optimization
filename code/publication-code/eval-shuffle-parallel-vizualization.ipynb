{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# text8 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Invalid alias: The name clear can't be aliased because it is another magic command.\n",
      "ERROR:root:Invalid alias: The name more can't be aliased because it is another magic command.\n",
      "ERROR:root:Invalid alias: The name less can't be aliased because it is another magic command.\n",
      "ERROR:root:Invalid alias: The name man can't be aliased because it is another magic command.\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "import gensim.downloader as api\n",
    "\n",
    "\"Transforms a list of words to a list of sentences with length=len_sen\"\n",
    "def words_to_sentences(words,len_sen=20):\n",
    "    new_ds = []\n",
    "    for i in range(0, len(words), len_sen):\n",
    "        y = [words[i:i + len_sen]]\n",
    "        new_ds.extend(y)\n",
    "    return new_ds\n",
    "\n",
    "# Get dataset online\n",
    "dataset = api.load('text8')\n",
    "\n",
    "# Convert to list of words\n",
    "text8_ds = []\n",
    "for x in dataset: \n",
    "    for y in x:\n",
    "        text8_ds.append(y)\n",
    "\n",
    "# New dataset with sentences of length=20\n",
    "text8_dataset = words_to_sentences(text8_ds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wordsim Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats, spatial \n",
    "import csv, numpy as np\n",
    "from scipy.stats.stats import pearsonr\n",
    "from scipy import spatial \n",
    "#IMPORT DATA\n",
    "def get_wordsim_data():\n",
    "    wordsim_data = [] \n",
    "    with open('./data/wordsim/set1.csv', newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=' ',quotechar='|')\n",
    "        for row in reader: \n",
    "            wordsim_data.append(row[0].split(',')[0:3])\n",
    "    del wordsim_data[0]\n",
    "    with open('./data/wordsim/set2.csv', newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=' ',quotechar='|')\n",
    "        for i,row in enumerate(reader):\n",
    "            if i!=0:\n",
    "                wordsim_data.append(row[0].split(',')[0:3])\n",
    "\n",
    "    return wordsim_data\n",
    "\n",
    "#len(wordsim_vocab.intersection(text8_dataset_first_sentence.vocab))\n",
    "def wordsim_task(dict_emb):\n",
    "    wordsim_data = get_wordsim_data()\n",
    "    scores = []\n",
    "    distances = []\n",
    "    found = 0\n",
    "    missed = 0\n",
    "    for task in wordsim_data: \n",
    "        if (task[0] in dict_emb.keys() ) and (task[1] in dict_emb.keys()):\n",
    "            found += 1\n",
    "            scores.append(float(task[2]))\n",
    "            distances.append(spatial.distance.cosine(dict_emb[task[0]], dict_emb[task[1]]))\n",
    "        else:\n",
    "            missed += 1\n",
    "            \n",
    "    print('found:',found,'missed:',missed)            \n",
    "            \n",
    "    #return stats.zscore(np.array([x[1] for x in out],dtype=float))\n",
    "    return np.corrcoef(scores,distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class SkipGramModel(nn.Module):\n",
    "\n",
    "    def __init__(self, emb_size_u, emb_size_v,emb_dimension):\n",
    "        super(SkipGramModel, self).__init__()\n",
    "        self.emb_dimension = emb_dimension\n",
    "        self.u_embeddings = nn.Embedding(emb_size_u, emb_dimension, sparse=False)\n",
    "        self.v_embeddings = nn.Embedding(emb_size_v, emb_dimension, sparse=False)\n",
    "        self.init_emb()\n",
    "        \n",
    "\n",
    "    def init_emb(self):\n",
    "        initrange = 0.5 / self.emb_dimension\n",
    "        self.u_embeddings.weight.data.uniform_(-initrange, initrange)\n",
    "        self.v_embeddings.weight.data.uniform_(-0, 0)\n",
    "        \n",
    "    def forward(self, pos_u, pos_v,neg_v):\n",
    "        emb_u = self.u_embeddings(pos_u)\n",
    "        neg_v = neg_v.view(len(pos_u),-1)\n",
    "        samples = torch.cat([pos_v,Variable(neg_v)],1)\n",
    "        emb_v = self.v_embeddings(samples)\n",
    "        score = torch.bmm(emb_v, emb_u.unsqueeze(2)).squeeze()\n",
    "        score[:,1:]=score[:,1:].neg()\n",
    "        score = F.logsigmoid(score)\n",
    "        return -1 * (torch.sum(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from collections import defaultdict\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import random\n",
    "import multiprocessing\n",
    "import time\n",
    "import numbers\n",
    "import itertools\n",
    "import pdb\n",
    "\n",
    "\n",
    "class W2VDataset(Dataset):\n",
    "    def __init__(self, sentences,power=0.75, neg_samples=5, min_count=5, window=5, sample=1e-4, sample_buffer=1000):\n",
    "        self.sentences = sentences\n",
    "        self.neg_samples=neg_samples\n",
    "        self.min_count = min_count\n",
    "        self.window_size = window\n",
    "        self.vocab_id = defaultdict(int)\n",
    "        self.vocab_ctx = defaultdict(int)\n",
    "        self.index2id = dict()\n",
    "        self.id2index = dict()\n",
    "        self.index2ctx = dict()\n",
    "        self.ctx2index = dict()\n",
    "        self.build_vocab(sentences)\n",
    "        self.ctx_weights = self.make_cum_table(power)\n",
    "        self.downsample_probs = np.zeros_like(self.ctx_weights)\n",
    "        if sample > 0:\n",
    "            self.downsample_probs = 1 - np.sqrt(sample/self.ctx_weights).clip(0,1)\n",
    "        self.pairs = []\n",
    "        ### If you do not want to shuffle the pairs please selec generat_pairs, else you can generate the pairs \n",
    "        ### in parallel with generate_pairs_parallel()\n",
    "        self.generate_pairs()\n",
    "        #self.generate_pairs_parallel()\n",
    "        self.ctx_weights = torch.FloatTensor(self.ctx_weights)\n",
    "        self.samples = None\n",
    "        self.sample_idx = -1\n",
    "        self.sample_size = 0\n",
    "        self.sample_buffer = sample_buffer\n",
    "        \n",
    "    def dataset_into_chunks(self,dataset,n_chunks=15):\n",
    "        chunks = []\n",
    "        #print(type(n_chunks))\n",
    "        split = int((len(dataset)/(n_chunks-1)))\n",
    "        for i in range(0, len(dataset), split):\n",
    "                    y = [dataset[i:i + split]]\n",
    "                    chunks.extend(y)\n",
    "        return chunks\n",
    "    def chunks_to_ds(chunks): \n",
    "        out = [x for z in l for x in chunks]\n",
    "        return out\n",
    "        \n",
    "    def sliding_window(self, words):\n",
    "        for pos, word in enumerate(words):\n",
    "            # sliding window (randomly reduced to give more weight to closeby words)\n",
    "            reduction = np.random.randint(self.window_size)\n",
    "            start = max(0, pos - self.window_size + reduction)\n",
    "            for pos2, word2 in enumerate(words[start:(pos + self.window_size + 1 - reduction)], start):\n",
    "                if pos2 != pos:\n",
    "                    yield (self.id2index[word],self.id2index[word2])\n",
    "                    \n",
    "    def generate_pairs_inner(self,sent):\n",
    "        pairs = []\n",
    "        words = [w for w in sent if w in self.vocab_id and self.downsample_probs[self.id2index[w]] < random.random()]\n",
    "        for pair in self.sliding_window(words):\n",
    "            pairs.append(pair)\n",
    "        return pairs\n",
    "        \n",
    "    def generate_pairs(self):  \n",
    "        print('generating pairs')\n",
    "        start = time.time()\n",
    "        p = [self.generate_pairs_inner(s) for s in self.sentences]\n",
    "        self.pairs = list(itertools.chain(*p))\n",
    "        end = time.time()\n",
    "        hours, rem = divmod(end-start, 3600)\n",
    "        minutes, seconds = divmod(rem, 60)\n",
    "        time_since_start = \"Time:  {:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds)\n",
    "        print('pairs generated in ',time_since_start)\n",
    "\n",
    "    def generate_pairs_parallel(self): \n",
    "        print('generating pairs parallel')\n",
    "        start = time.time()\n",
    "        chunks = self.dataset_into_chunks(self.sentences)\n",
    "        manager = multiprocessing.Manager()\n",
    "        return_dict = manager.list()\n",
    "        threads = []\n",
    "        pairs = []\n",
    "        for index,chunk in enumerate(chunks):\n",
    "            thread = multiprocessing.Process(target=self.generate_pairs_single_thread, args=(chunk,index,return_dict))\n",
    "            thread.start()\n",
    "            threads.append(thread)\n",
    "        for thread in threads:\n",
    "            thread.join()\n",
    "        \n",
    "    \n",
    "        self.pairs = list(itertools.chain(*return_dict))\n",
    "        \n",
    "        end = time.time()\n",
    "        hours, rem = divmod(end-start, 3600)\n",
    "        minutes, seconds = divmod(rem, 60)\n",
    "        time_since_start = \"Time:  {:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds)\n",
    "        print('pairs generated parallel  in ',time_since_start)\n",
    "        \n",
    "    def generate_pairs_single_thread(self,chunk,index,return_dict):\n",
    "        pairs = []\n",
    "        for sent in chunk:\n",
    "            words = [w for w in sent if w in self.vocab_id and self.downsample_probs[self.id2index[w]] < random.random()]\n",
    "            for pair in self.sliding_window(words):\n",
    "                pairs.append(pair)\n",
    "        #p = [self.generate_pairs_inner(s) for s in chunk]\n",
    "        #out = list(itertools.chain(*p))\n",
    "        print('thread' + str(index) + ' created' + str(len(pairs)) + \" pairs\")\n",
    "        return_dict.extend(pairs)\n",
    "        #return_dict[index] = pairs\n",
    "      \n",
    "        \n",
    "    def build_vocab(self,sentences):\n",
    "        print('building vocab')\n",
    "        raw_vocab = defaultdict(int)\n",
    "        for sent in sentences:\n",
    "            for word in sent:\n",
    "                raw_vocab[word] += 1\n",
    "        self.vocab_id = {k:v for k,v in raw_vocab.items() if v >= self.min_count}\n",
    "        self.vocab_ctx = self.vocab_id \n",
    "        del raw_vocab\n",
    "                \n",
    "        # ctx - index\n",
    "        for word in self.vocab_ctx:\n",
    "            self.ctx2index[word] = len(self.ctx2index)\n",
    "        self.index2ctx = dict(zip(self.ctx2index.values(), self.ctx2index.keys()))\n",
    "        # id - index\n",
    "        self.id2index = self.ctx2index\n",
    "        self.index2id = self.index2ctx\n",
    "        print('vocab build')\n",
    "        \n",
    "        \n",
    "    def make_cum_table(self, power):\n",
    "        pow_frequency = np.array([self.vocab_ctx[self.index2ctx[i]] for i in range(len(self.vocab_ctx))])**power\n",
    "        return pow_frequency / pow_frequency.sum()\n",
    "    \n",
    "    \n",
    "    def sample_neg(self, count):\n",
    "        if self.sample_idx == -1:\n",
    "            self.sample_size = count*self.sample_buffer\n",
    "            self.samples = np.random.choice(list(self.index2ctx.keys()),size=self.sample_size,replace=True,p=self.ctx_weights)\n",
    "            self.sample_idx = 0\n",
    "        while self.sample_idx + count > len(self.samples):\n",
    "            self.samples = np.random.choice(list(self.index2ctx.keys()),size=self.sample_size,replace=True,p=self.ctx_weights)\n",
    "            self.sample_idx = 0\n",
    "        out = self.samples[self.sample_idx:self.sample_idx+count]\n",
    "        self.sample_idx += count\n",
    "        return out\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        pos_u = self.pairs[idx][0]\n",
    "        pos_v = self.pairs[idx][1]\n",
    "        samples = self.sample_neg(self.neg_samples)\n",
    "        while pos_v in samples:\n",
    "            samples = self.sample_neg(self.neg_samples)\n",
    "        return (pos_u,pos_v,samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W2V Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "from torch.utils.data import DataLoader\n",
    "import copy\n",
    "import time\n",
    "import numbers\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "cpu = torch.device('cpu')\n",
    "gpu = torch.device(\"cuda:0\")\n",
    "\n",
    "class W2V():\n",
    "    def __init__(self, data,dim=100, neg_samples=10, alpha=0.4, iterations=20, batch_size=2000, \n",
    "                 shuffle=True,use_cuda=True,workers=2,momentum=0,nesterov=False,step_size=1,gamma=1,optim='Adam'):\n",
    "        self.momentum = momentum\n",
    "        self.nesterov = nesterov\n",
    "        self.step_size = step_size\n",
    "        self.gamma = gamma\n",
    "        self.shuffle = shuffle        \n",
    "        self.batch_size = batch_size\n",
    "        self.alpha = alpha\n",
    "        self.dim = dim\n",
    "        self.data = data\n",
    "        self.workers = workers\n",
    "        self.neg_samples = neg_samples\n",
    "        self.use_cuda = use_cuda\n",
    "        self.ws_list = []\n",
    "        self.loss_list = []\n",
    "        self.model = SkipGramModel(len(self.data.vocab_id),len(self.data.vocab_id), self.dim)\n",
    "        self.model.to(device)\n",
    "        # Choose wanted optimizer\n",
    "        if (optim=='Adam'):\n",
    "            print(\"choosen optimizer is Adam\")\n",
    "            self.optimizer = torch.optim.Adam(self.model.parameters(),lr=alpha)\n",
    "        else:\n",
    "            print(\"choosen optimizer is SGD\")\n",
    "            self.optimizer = torch.optim.SGD(self.model.parameters(), lr=alpha, momentum=momentum,nesterov=nesterov)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        self.iterations = iterations\n",
    " \n",
    "    def train_with_loader(self,save_embedding=False):\n",
    "        print('starting training')\n",
    "\n",
    "        self.time=0\n",
    "        for epoch in range(self.iterations):\n",
    "            loader = DataLoader(self.data, self.batch_size, self.shuffle, num_workers=self.workers,pin_memory=True)\n",
    "            tenth = int(len(loader)/10)\n",
    "\n",
    "            percent = 0\n",
    "            start = time.time()\n",
    "            processed_batches = 0 \n",
    "            pairs = 0\n",
    "            cum_loss = 0 \n",
    "            avg_loss =0\n",
    "            best_loss = 10 \n",
    "            \n",
    "            for i,(pos_u,pos_v,neg_v) in enumerate(loader):\n",
    "                if(i%tenth == 0 ):\n",
    "                    end = time.time()\n",
    "                    hours, rem = divmod(end-start, 3600)\n",
    "                    minutes, seconds = divmod(rem, 60)\n",
    "                    time_since_start = \"Time:  {:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds)\n",
    "                    if(processed_batches!=0):\n",
    "                        avg_loss = cum_loss / processed_batches\n",
    "                    print(\"0%\" + \"=\" *(int(percent/10))+ str(percent) +\"%, \" + time_since_start + \", cum_loss = {}\".format(cum_loss),end=\"\\r\" )\n",
    "                    percent+=10   \n",
    "                    \n",
    "                pos_v = pos_v.view(len(pos_u),-1)\n",
    "                neg_v = neg_v.view(len(pos_u),-1)\n",
    "                pos_u = pos_u.to(device)\n",
    "                pos_v = pos_v.to(device)\n",
    "                neg_v = neg_v.to(device)\n",
    "                self.optimizer.zero_grad()\n",
    "                loss = self.model.forward(pos_u,pos_v,neg_v)\n",
    "                cum_loss += loss\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                pairs += len(pos_u)\n",
    "                processed_batches += 1\n",
    "                \n",
    "            print(\"\\n{0:d} epoch of {1:d}\".format(epoch+1, self.iterations))\n",
    "            avg_loss = cum_loss / processed_batches\n",
    "            print(\" {0:d} {1:d} batches, pairs {2:d}, cum loss: {3:.5f}\".format(i,processed_batches, pairs,cum_loss))\n",
    "            self.loss_list.append(cum_loss)\n",
    "            self.time = time_since_start\n",
    "            self.model = self.model.to(cpu)\n",
    "            score = -1*(wordsim_task(self.get_embedding())[0][1])\n",
    "            print(\"Current score on wordsim Task: {}\".format(score))\n",
    "            self.ws_list.append(score)\n",
    "            self.model = self.model.to(gpu)\n",
    "            self.data.generate_pairs()\n",
    "        \n",
    "        if(save_embedding):\n",
    "            self.save_embedding()\n",
    "            \n",
    "\n",
    "    def get_embedding(self):\n",
    "        embedding_dict = dict()\n",
    "        embedding = self.model.u_embeddings.weight.data.numpy()\n",
    "        for i in range(len(self.data.index2id)):\n",
    "            embedding_dict[self.data.index2id[i]]= embedding[i]\n",
    "        return embedding_dict\n",
    "    \n",
    "    def save_embedding(self, with_loss=True):\n",
    "        print('ntm')\n",
    "        # Creating filename\n",
    "        optim = \"Optim\" + str(self.optimizer).split(\" \")[0] + \"_\"\n",
    "        filename = \"dict_emb_\" +  optim + \"_\".join([x + str(y) for x,y in vars(self).items() if isinstance(y, numbers.Number)]) + \".pkl\"\n",
    "        \n",
    "        # Getting Embedding\n",
    "        self.model.to(torch.device('cpu'))\n",
    "        dict_emb = w2v.get_embedding()\n",
    "        \n",
    "        # Adding loss history to embedding\n",
    "        dict_emb['loss_list'] = [x.to(torch.device('cpu')) for x in self.loss_list]\n",
    "        \n",
    "        # Adding score list to embedding \n",
    "        dict_emb['ws_list'] = self.ws_list\n",
    "        \n",
    "                \n",
    "        # Saving time spent to calculate 1 epoch\n",
    "        dict_emb['time'] = self.time\n",
    "        \n",
    "        # Logging\n",
    "        print(\"Saving embedding: {} to disk with ws_score: {} \".format(filename,dict_emb['ws_list']))\n",
    "    \n",
    "        # Writing embedding dictionnary to disk\n",
    "        with open(filename, 'wb') as output:\n",
    "            pickle.dump(dict_emb, output, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "        self.model.to(device)\n",
    "        self.loss_list = [x.to(device) for x in self.loss_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building vocab\n",
      "vocab build\n",
      "generating pairs\n",
      "pairs generated in  Time:  00:00:48.24\n"
     ]
    }
   ],
   "source": [
    "neg_samples = 10\n",
    "w2v_dataset = W2VDataset(text8_dataset,sample_buffer=500000,neg_samples=neg_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training without shuffling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choosen optimizer is Adam\n",
      "starting training\n",
      "0%==========100%, Time:  00:03:52.85, cum_loss = 143246800.0\n",
      "1 epoch of 2\n",
      " 20938 20939 batches, pairs 41876538, cum loss: 143298960.00000\n",
      "found: 333 missed: 20\n",
      "Current score on wordsim Task: 0.48772968977799863\n",
      "generating pairs\n",
      "pairs generated in  Time:  00:00:54.60\n",
      "0%==========100%, Time:  00:04:43.54, cum_loss = 131173304.0\n",
      "2 epoch of 2\n",
      " 20945 20946 batches, pairs 41890574, cum loss: 131205992.00000\n",
      "found: 333 missed: 20\n",
      "Current score on wordsim Task: 0.5917808204040622\n",
      "generating pairs\n",
      "pairs generated in  Time:  00:00:58.65\n",
      "choosen optimizer is Adam\n",
      "starting training\n",
      "0%==========100%, Time:  00:05:14.15, cum_loss = 143281600.0\n",
      "1 epoch of 2\n",
      " 20937 20938 batches, pairs 41874679, cum loss: 143327856.00000\n",
      "found: 333 missed: 20\n",
      "Current score on wordsim Task: 0.4776594700117363\n",
      "generating pairs\n",
      "pairs generated in  Time:  00:01:00.94\n",
      "0%==========100%, Time:  00:05:26.52, cum_loss = 131143008.0\n",
      "2 epoch of 2\n",
      " 20934 20935 batches, pairs 41868264, cum loss: 131169184.00000\n",
      "found: 333 missed: 20\n",
      "Current score on wordsim Task: 0.5746030578686163\n",
      "generating pairs\n",
      "pairs generated in  Time:  00:01:02.52\n",
      "choosen optimizer is Adam\n",
      "starting training\n",
      "0%0%, Time:  00:00:06.84, cum_loss = 0\r"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "ws_lists_adam_shuffle = []\n",
    "ws_lists_sgd_shuffle = []\n",
    "ADAM_LR = 0.005\n",
    "SGD_LR = 0.075\n",
    "NUMBER_OF_EVAL = 10\n",
    "NUMBER_OF_ITER = 10 \n",
    "for x in range(NUMBER_OF_EVAL):\n",
    "    w2v = W2V(w2v_dataset, neg_samples=neg_samples, alpha=ADAM_LR,shuffle=False,workers=4,iterations=NUMBER_OF_ITER,batch_size=2000,optim='Adam')\n",
    "    w2v.train_with_loader()\n",
    "    ws_lists_adam_shuffle.append(w2v.ws_list)\n",
    "    \n",
    "mean_list_adam = np.mean(ws_lists_adam_shuffle, axis=0)\n",
    "with open('mean_list_adam.pkl', 'wb') as fp:\n",
    "    pickle.dump(mean_list_adam, fp)\n",
    "    \n",
    "for x in range(NUMBER_OF_EVAL):\n",
    "    w2v = W2V(w2v_dataset, neg_samples=neg_samples, alpha=SGD_LR,shuffle=False,workers=4,iterations=NUMBER_OF_ITER,batch_size=2000,optim='Sgd')\n",
    "    w2v.train_with_loader()\n",
    "    ws_lists_sgd_shuffle.append(w2v.ws_list)\n",
    "    \n",
    "mean_list_sgd = np.mean(ws_lists_sgd_shuffle, axis=0)\n",
    "with open('mean_list_sgd.pkl', 'wb') as fp:\n",
    "    pickle.dump(mean_list_sgd, fp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'W2V' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-b5a4862cb3d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mNUMBER_OF_ITER\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUMBER_OF_ITER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mw2v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mW2V\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2v_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mneg_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mADAM_LR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mw2v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_with_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mws_lists_adam_shuffle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mws_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'W2V' is not defined"
     ]
    }
   ],
   "source": [
    "ws_lists_adam_shuffle = []\n",
    "ws_lists_sgd_shuffle = []\n",
    "ADAM_LR = 0.001\n",
    "SGD_LR = 0.05\n",
    "NUMBER_OF_EVAL = 10\n",
    "NUMBER_OF_ITER = 10\n",
    "for x in range(NUMBER_OF_EVAL):\n",
    "    w2v = W2V(w2v_dataset, neg_samples=neg_samples, alpha=ADAM_LR,shuffle=True,workers=4,iterations=NUMBER_OF_ITER,batch_size=2000,optim='Adam')\n",
    "    w2v.train_with_loader()\n",
    "    ws_lists_adam_shuffle.append(w2v.ws_list)\n",
    "    \n",
    "mean_list_adam_shuffle = np.mean(ws_lists_adam_shuffle, axis=0)\n",
    "with open('mean_list_adam_shuffle.pkl', 'wb') as fp:\n",
    "    pickle.dump(mean_list_adam_shuffle, fp)\n",
    "\n",
    "for x in range(NUMBER_OF_EVAL):\n",
    "    w2v = W2V(w2v_dataset, neg_samples=neg_samples, alpha=SGD_LR,shuffle=True,workers=4,iterations=NUMBER_OF_ITER,batch_size=2000,optim='Sgd')\n",
    "    w2v.train_with_loader()\n",
    "    ws_lists_sgd_shuffle.append(w2v.ws_list)\n",
    "    \n",
    "mean_list_sgd_shuffle = np.mean(ws_lists_sgd_shuffle, axis=0)\n",
    "with open('mean_list_sgd_shuffle.pkl', 'wb') as fp:\n",
    "    pickle.dump(mean_list_sgd_shuffle, fp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Gensim\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "from gensim.models import Word2Vec\n",
    "gensim_emb = dict()\n",
    "    \n",
    "class EpochLogger(CallbackAny2Vec):\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "        self.cum_loss = 0\n",
    "        self.loss_list = []\n",
    "        self.ws_list = []\n",
    "        self.prev_score = -1\n",
    "        self.no_improvement =0\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        score = model.wv.evaluate_word_pairs(\"./data/wordsim/combined.tab\")\n",
    "        self.ws_list.append(score[1][0])\n",
    "        print(\"Epoch #{}, ws_score={}\".format(self.epoch,score[1][0]))\n",
    "        self.epoch += 1 \n",
    "            \n",
    "    def on_batch_end(self, model):\n",
    "        \"\"\"Method called at the end of each batch.\n",
    "        Parameters\n",
    "        ----------\n",
    "        model : :class:`~gensim.models.base_any2vec.BaseWordEmbeddingsModel`\n",
    "            Current model.\n",
    "        \"\"\"\n",
    "        self.cum_loss += model.get_latest_training_loss()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #0, ws_score=0.5423840286648558\n",
      "Epoch #1, ws_score=0.6301018249878083\n",
      "Epoch #2, ws_score=0.6588657706574313\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-ebb25224abb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUMBER_OF_EVAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mepoch_logger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEpochLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext8_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnegative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch_logger\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mws_lists_gensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mws_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmean_list_gensim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mws_lists_gensim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sentences, corpus_file, size, alpha, window, min_count, max_vocab_size, sample, seed, workers, min_alpha, sg, hs, negative, ns_exponent, cbow_mean, hashfxn, iter, null_word, trim_rule, sorted_vocab, batch_words, compute_loss, callbacks, max_final_vocab)\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m             \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnegative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbow_mean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcbow_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m             fast_version=FAST_VERSION)\n\u001b[0m\u001b[1;32m    784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m     def _do_train_epoch(self, corpus_file, thread_id, offset, cython_vocab, thread_private_mem, cur_epoch,\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sentences, corpus_file, workers, vector_size, epochs, callbacks, batch_words, trim_rule, sg, alpha, window, seed, hs, negative, ns_exponent, cbow_mean, min_alpha, compute_loss, fast_version, **kwargs)\u001b[0m\n\u001b[1;32m    761\u001b[0m                 \u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m                 \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_total_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m                 end_alpha=self.min_alpha, compute_loss=compute_loss)\n\u001b[0m\u001b[1;32m    764\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtrim_rule\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sentences, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks)\u001b[0m\n\u001b[1;32m    908\u001b[0m             \u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m             queue_factor=queue_factor, report_delay=report_delay, compute_loss=compute_loss, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_sentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport_delay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sentences, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m             \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m             \u001b[0mqueue_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqueue_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport_delay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreport_delay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m             **kwargs)\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_job_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data_iterable, corpus_file, epochs, total_examples, total_words, queue_factor, report_delay, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    551\u001b[0m                 trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch = self._train_epoch(\n\u001b[1;32m    552\u001b[0m                     \u001b[0mdata_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m                     total_words=total_words, queue_factor=queue_factor, report_delay=report_delay)\n\u001b[0m\u001b[1;32m    554\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m                 trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch = self._train_epoch_corpusfile(\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(self, data_iterable, cur_epoch, total_examples, total_words, queue_factor, report_delay)\u001b[0m\n\u001b[1;32m    487\u001b[0m         trained_word_count, raw_word_count, job_tally = self._log_epoch_progress(\n\u001b[1;32m    488\u001b[0m             \u001b[0mprogress_queue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_queue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             report_delay=report_delay, is_corpus_file_mode=False)\n\u001b[0m\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrained_word_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_word_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_tally\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36m_log_epoch_progress\u001b[0;34m(self, progress_queue, job_queue, cur_epoch, total_examples, total_words, report_delay, is_corpus_file_mode)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0munfinished_worker_count\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m             \u001b[0mreport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprogress_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocks if workers too slow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreport\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# a thread reporting that it finished\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m                 \u001b[0munfinished_worker_count\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ws_lists_gensim  = []\n",
    "for x in range(NUMBER_OF_EVAL):\n",
    "    epoch_logger = EpochLogger()\n",
    "    model = Word2Vec(text8_dataset,size=100,window=5,negative=10,min_count=5, sample=1e-4, iter=10, workers=1,sg=1, hs=0,callbacks=[epoch_logger],compute_loss=True)\n",
    "    ws_lists_gensim.append(epoch_logger.ws_list)\n",
    "mean_list_gensim = np.mean(ws_lists_gensim, axis=0)\n",
    "with open('mean_list_gensim.pkl', 'wb') as fp:\n",
    "    pickle.dump(mean_list_gensim, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('mean_list_sgd_shuffle-once.pkl', 'rb') as fp:\n",
    "    mean_list_sgd_shuffle = pickle.load(fp)\n",
    "with open('mean_list_adam_shuffle.pkl', 'rb') as fp:\n",
    "    mean_list_adam_shuffle = pickle.load(fp)\n",
    "with open('mean_list_adam.pkl', 'rb') as fp:\n",
    "    mean_list_adam = pickle.load(fp)\n",
    "with open('mean_list_sgd-once.pkl', 'rb') as fp:\n",
    "    mean_list_sgd = pickle.load(fp)\n",
    "with open('mean_list_gensim-once.pkl', 'rb') as fp:\n",
    "    mean_list_gensim = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.60702571, 0.65638966, 0.66539662, 0.66948095, 0.66802354,\n",
       "       0.66696067, 0.66498466, 0.66498765, 0.66263203, 0.66150022])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vizualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Word similarity score')\n",
    "plt.title('Convergence Time According to the choosen Optimizer')\n",
    "# red dashes, blue squares and green triangles\n",
    "plt.plot(mean_list_sgd_shuffle, 'bo--',label='sgd_shuffle')\n",
    "plt.plot(mean_list_sgd , 'bo-',label='sgd')\n",
    "plt.plot(mean_list_adam_shuffle,'ro--',label='adam_shuffle')\n",
    "plt.plot(mean_list_adam,'ro-',label='adam')\n",
    "plt.plot(mean_list_gensim,'go-',label='Gensim')\n",
    "plt.grid(True)\n",
    "plt.legend(loc=(1.04,0.5))\n",
    "plt.savefig('comparison.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
