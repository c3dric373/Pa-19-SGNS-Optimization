{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# text8 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Invalid alias: The name clear can't be aliased because it is another magic command.\n",
      "ERROR:root:Invalid alias: The name more can't be aliased because it is another magic command.\n",
      "ERROR:root:Invalid alias: The name less can't be aliased because it is another magic command.\n",
      "ERROR:root:Invalid alias: The name man can't be aliased because it is another magic command.\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "import gensim.downloader as api\n",
    "\n",
    "\"Transforms a list of words to a list of sentences with length=len_sen\"\n",
    "def words_to_sentences(words,len_sen=20):\n",
    "    new_ds = []\n",
    "    for i in range(0, len(words), len_sen):\n",
    "        y = [words[i:i + len_sen]]\n",
    "        new_ds.extend(y)\n",
    "    return new_ds\n",
    "\n",
    "# Get dataset online\n",
    "dataset = api.load('text8')\n",
    "\n",
    "# Convert to list of words\n",
    "text8_ds = []\n",
    "for x in dataset: \n",
    "    for y in x:\n",
    "        text8_ds.append(y)\n",
    "\n",
    "# New dataset with sentences of length=20\n",
    "text8_dataset = words_to_sentences(text8_ds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wordsim Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats, spatial \n",
    "import csv, numpy as np\n",
    "from scipy.stats.stats import pearsonr\n",
    "from scipy import spatial \n",
    "#IMPORT DATA\n",
    "def get_wordsim_data():\n",
    "    wordsim_data = [] \n",
    "    with open('./data/wordsim/set1.csv', newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=' ',quotechar='|')\n",
    "        for row in reader: \n",
    "            wordsim_data.append(row[0].split(',')[0:3])\n",
    "    del wordsim_data[0]\n",
    "    with open('./data/wordsim/set2.csv', newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=' ',quotechar='|')\n",
    "        for i,row in enumerate(reader):\n",
    "            if i!=0:\n",
    "                wordsim_data.append(row[0].split(',')[0:3])\n",
    "\n",
    "    return wordsim_data\n",
    "\n",
    "#len(wordsim_vocab.intersection(text8_dataset_first_sentence.vocab))\n",
    "def wordsim_task(dict_emb):\n",
    "    wordsim_data = get_wordsim_data()\n",
    "    scores = []\n",
    "    distances = []\n",
    "    found = 0\n",
    "    missed = 0\n",
    "    for task in wordsim_data: \n",
    "        if (task[0] in dict_emb.keys() ) and (task[1] in dict_emb.keys()):\n",
    "            found += 1\n",
    "            scores.append(float(task[2]))\n",
    "            distances.append(spatial.distance.cosine(dict_emb[task[0]], dict_emb[task[1]]))\n",
    "        else:\n",
    "            missed += 1\n",
    "            \n",
    "    print('found:',found,'missed:',missed)            \n",
    "            \n",
    "    #return stats.zscore(np.array([x[1] for x in out],dtype=float))\n",
    "    return np.corrcoef(scores,distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class SkipGramModel(nn.Module):\n",
    "\n",
    "    def __init__(self, emb_size_u, emb_size_v,emb_dimension):\n",
    "        super(SkipGramModel, self).__init__()\n",
    "        self.emb_dimension = emb_dimension\n",
    "        self.u_embeddings = nn.Embedding(emb_size_u, emb_dimension, sparse=False)\n",
    "        self.v_embeddings = nn.Embedding(emb_size_v, emb_dimension, sparse=False)\n",
    "        self.init_emb()\n",
    "        \n",
    "\n",
    "    def init_emb(self):\n",
    "        initrange = 0.5 / self.emb_dimension\n",
    "        self.u_embeddings.weight.data.uniform_(-initrange, initrange)\n",
    "        self.v_embeddings.weight.data.uniform_(-0, 0)\n",
    "        \n",
    "    def forward(self, pos_u, pos_v,neg_v):\n",
    "        emb_u = self.u_embeddings(pos_u)\n",
    "        neg_v = neg_v.view(len(pos_u),-1)\n",
    "        samples = torch.cat([pos_v,Variable(neg_v)],1)\n",
    "        emb_v = self.v_embeddings(samples)\n",
    "        score = torch.bmm(emb_v, emb_u.unsqueeze(2)).squeeze()\n",
    "        score[:,1:]=score[:,1:].neg()\n",
    "        score = F.logsigmoid(score)\n",
    "        return -1 * (torch.sum(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from collections import defaultdict\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import random\n",
    "import multiprocessing\n",
    "import time\n",
    "import numbers\n",
    "import itertools\n",
    "import pdb\n",
    "\n",
    "\n",
    "class W2VDataset(Dataset):\n",
    "    def __init__(self, sentences,power=0.75, neg_samples=5, min_count=5, window=5, sample=1e-4, sample_buffer=1000):\n",
    "        self.sentences = sentences\n",
    "        self.neg_samples=neg_samples\n",
    "        self.min_count = min_count\n",
    "        self.window_size = window\n",
    "        self.vocab_id = defaultdict(int)\n",
    "        self.vocab_ctx = defaultdict(int)\n",
    "        self.index2id = dict()\n",
    "        self.id2index = dict()\n",
    "        self.index2ctx = dict()\n",
    "        self.ctx2index = dict()\n",
    "        self.build_vocab(sentences)\n",
    "        self.ctx_weights = self.make_cum_table(power)\n",
    "        self.downsample_probs = np.zeros_like(self.ctx_weights)\n",
    "        if sample > 0:\n",
    "            self.downsample_probs = 1 - np.sqrt(sample/self.ctx_weights).clip(0,1)\n",
    "        self.pairs = []\n",
    "        ### If you do not want to shuffle the pairs please selec generat_pairs, else you can generate the pairs \n",
    "        ### in parallel with generate_pairs_parallel()\n",
    "        self.generate_pairs()\n",
    "        #self.generate_pairs_parallel()\n",
    "        self.ctx_weights = torch.FloatTensor(self.ctx_weights)\n",
    "        self.samples = None\n",
    "        self.sample_idx = -1\n",
    "        self.sample_size = 0\n",
    "        self.sample_buffer = sample_buffer\n",
    "        \n",
    "    def dataset_into_chunks(self,dataset,n_chunks=15):\n",
    "        chunks = []\n",
    "        #print(type(n_chunks))\n",
    "        split = int((len(dataset)/(n_chunks-1)))\n",
    "        for i in range(0, len(dataset), split):\n",
    "                    y = [dataset[i:i + split]]\n",
    "                    chunks.extend(y)\n",
    "        return chunks\n",
    "    def chunks_to_ds(chunks): \n",
    "        out = [x for z in l for x in chunks]\n",
    "        return out\n",
    "        \n",
    "    def sliding_window(self, words):\n",
    "        for pos, word in enumerate(words):\n",
    "            # sliding window (randomly reduced to give more weight to closeby words)\n",
    "            reduction = np.random.randint(self.window_size)\n",
    "            start = max(0, pos - self.window_size + reduction)\n",
    "            for pos2, word2 in enumerate(words[start:(pos + self.window_size + 1 - reduction)], start):\n",
    "                if pos2 != pos:\n",
    "                    yield (self.id2index[word],self.id2index[word2])\n",
    "                    \n",
    "    def generate_pairs_inner(self,sent):\n",
    "        pairs = []\n",
    "        words = [w for w in sent if w in self.vocab_id and self.downsample_probs[self.id2index[w]] < random.random()]\n",
    "        for pair in self.sliding_window(words):\n",
    "            pairs.append(pair)\n",
    "        return pairs\n",
    "        \n",
    "    def generate_pairs(self):  \n",
    "        print('generating pairs')\n",
    "        start = time.time()\n",
    "        p = [self.generate_pairs_inner(s) for s in self.sentences]\n",
    "        self.pairs = list(itertools.chain(*p))\n",
    "        end = time.time()\n",
    "        hours, rem = divmod(end-start, 3600)\n",
    "        minutes, seconds = divmod(rem, 60)\n",
    "        time_since_start = \"Time:  {:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds)\n",
    "        print('pairs generated in ',time_since_start)\n",
    "\n",
    "    def generate_pairs_parallel(self): \n",
    "        print('generating pairs parallel')\n",
    "        start = time.time()\n",
    "        chunks = self.dataset_into_chunks(self.sentences)\n",
    "        manager = multiprocessing.Manager()\n",
    "        return_dict = manager.list()\n",
    "        threads = []\n",
    "        pairs = []\n",
    "        for index,chunk in enumerate(chunks):\n",
    "            thread = multiprocessing.Process(target=self.generate_pairs_single_thread, args=(chunk,index,return_dict))\n",
    "            thread.start()\n",
    "            threads.append(thread)\n",
    "        for thread in threads:\n",
    "            thread.join()\n",
    "        \n",
    "    \n",
    "        self.pairs = list(itertools.chain(*return_dict))\n",
    "        \n",
    "        end = time.time()\n",
    "        hours, rem = divmod(end-start, 3600)\n",
    "        minutes, seconds = divmod(rem, 60)\n",
    "        time_since_start = \"Time:  {:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds)\n",
    "        print('pairs generated parallel  in ',time_since_start)\n",
    "        \n",
    "    def generate_pairs_single_thread(self,chunk,index,return_dict):\n",
    "        pairs = []\n",
    "        for sent in chunk:\n",
    "            words = [w for w in sent if w in self.vocab_id and self.downsample_probs[self.id2index[w]] < random.random()]\n",
    "            for pair in self.sliding_window(words):\n",
    "                pairs.append(pair)\n",
    "        #p = [self.generate_pairs_inner(s) for s in chunk]\n",
    "        #out = list(itertools.chain(*p))\n",
    "        print('thread' + str(index) + ' created' + str(len(pairs)) + \" pairs\")\n",
    "        return_dict.extend(pairs)\n",
    "        #return_dict[index] = pairs\n",
    "      \n",
    "        \n",
    "    def build_vocab(self,sentences):\n",
    "        print('building vocab')\n",
    "        raw_vocab = defaultdict(int)\n",
    "        for sent in sentences:\n",
    "            for word in sent:\n",
    "                raw_vocab[word] += 1\n",
    "        self.vocab_id = {k:v for k,v in raw_vocab.items() if v >= self.min_count}\n",
    "        self.vocab_ctx = self.vocab_id \n",
    "        del raw_vocab\n",
    "                \n",
    "        # ctx - index\n",
    "        for word in self.vocab_ctx:\n",
    "            self.ctx2index[word] = len(self.ctx2index)\n",
    "        self.index2ctx = dict(zip(self.ctx2index.values(), self.ctx2index.keys()))\n",
    "        # id - index\n",
    "        self.id2index = self.ctx2index\n",
    "        self.index2id = self.index2ctx\n",
    "        print('vocab build')\n",
    "        \n",
    "        \n",
    "    def make_cum_table(self, power):\n",
    "        pow_frequency = np.array([self.vocab_ctx[self.index2ctx[i]] for i in range(len(self.vocab_ctx))])**power\n",
    "        return pow_frequency / pow_frequency.sum()\n",
    "    \n",
    "    \n",
    "    def sample_neg(self, count):\n",
    "        if self.sample_idx == -1:\n",
    "            self.sample_size = count*self.sample_buffer\n",
    "            self.samples = np.random.choice(list(self.index2ctx.keys()),size=self.sample_size,replace=True,p=self.ctx_weights)\n",
    "            self.sample_idx = 0\n",
    "        while self.sample_idx + count > len(self.samples):\n",
    "            self.samples = np.random.choice(list(self.index2ctx.keys()),size=self.sample_size,replace=True,p=self.ctx_weights)\n",
    "            self.sample_idx = 0\n",
    "        out = self.samples[self.sample_idx:self.sample_idx+count]\n",
    "        self.sample_idx += count\n",
    "        return out\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        pos_u = self.pairs[idx][0]\n",
    "        pos_v = self.pairs[idx][1]\n",
    "        samples = self.sample_neg(self.neg_samples)\n",
    "        while pos_v in samples:\n",
    "            samples = self.sample_neg(self.neg_samples)\n",
    "        return (pos_u,pos_v,samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W2V Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "from torch.utils.data import DataLoader\n",
    "import copy\n",
    "import time\n",
    "import numbers\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "cpu = torch.device('cpu')\n",
    "gpu = torch.device(\"cuda:0\")\n",
    "\n",
    "class W2V():\n",
    "    def __init__(self, data,dim=100, neg_samples=10, alpha=0.4, iterations=20, batch_size=2000, \n",
    "                 shuffle=True,use_cuda=True,workers=2,momentum=0,nesterov=False,step_size=1,gamma=1,optim='Adam'):\n",
    "        self.momentum = momentum\n",
    "        self.nesterov = nesterov\n",
    "        self.step_size = step_size\n",
    "        self.gamma = gamma\n",
    "        self.shuffle = shuffle        \n",
    "        self.batch_size = batch_size\n",
    "        self.alpha = alpha\n",
    "        self.dim = dim\n",
    "        self.data = data\n",
    "        self.workers = workers\n",
    "        self.neg_samples = neg_samples\n",
    "        self.use_cuda = use_cuda\n",
    "        self.ws_list = []\n",
    "        self.loss_list = []\n",
    "        self.model = SkipGramModel(len(self.data.vocab_id),len(self.data.vocab_id), self.dim)\n",
    "        self.model.to(device)\n",
    "        # Choose wanted optimizer\n",
    "        if (optim=='Adam'):\n",
    "            print(\"choosen optimizer is Adam\")\n",
    "            self.optimizer = torch.optim.Adam(self.model.parameters(),lr=alpha)\n",
    "        else:\n",
    "            print(\"choosen optimizer is SGD\")\n",
    "            self.optimizer = torch.optim.SGD(self.model.parameters(), lr=alpha, momentum=momentum,nesterov=nesterov)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        self.iterations = iterations\n",
    " \n",
    "    def train_with_loader(self,save_embedding=False):\n",
    "        print('starting training')\n",
    "\n",
    "        self.time=0\n",
    "        for epoch in range(self.iterations):\n",
    "            loader = DataLoader(self.data, self.batch_size, self.shuffle, num_workers=self.workers,pin_memory=True)\n",
    "            tenth = int(len(loader)/10)\n",
    "\n",
    "            percent = 0\n",
    "            start = time.time()\n",
    "            processed_batches = 0 \n",
    "            pairs = 0\n",
    "            cum_loss = 0 \n",
    "            avg_loss =0\n",
    "            best_loss = 10 \n",
    "            \n",
    "            for i,(pos_u,pos_v,neg_v) in enumerate(loader):\n",
    "                if(i%tenth == 0 ):\n",
    "                    end = time.time()\n",
    "                    hours, rem = divmod(end-start, 3600)\n",
    "                    minutes, seconds = divmod(rem, 60)\n",
    "                    time_since_start = \"Time:  {:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds)\n",
    "                    if(processed_batches!=0):\n",
    "                        avg_loss = cum_loss / processed_batches\n",
    "                    print(\"0%\" + \"=\" *(int(percent/10))+ str(percent) +\"%, \" + time_since_start + \", cum_loss = {}\".format(cum_loss),end=\"\\r\" )\n",
    "                    percent+=10   \n",
    "                    \n",
    "                pos_v = pos_v.view(len(pos_u),-1)\n",
    "                neg_v = neg_v.view(len(pos_u),-1)\n",
    "                pos_u = pos_u.to(device)\n",
    "                pos_v = pos_v.to(device)\n",
    "                neg_v = neg_v.to(device)\n",
    "                self.optimizer.zero_grad()\n",
    "                loss = self.model.forward(pos_u,pos_v,neg_v)\n",
    "                cum_loss += loss\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                pairs += len(pos_u)\n",
    "                processed_batches += 1\n",
    "                \n",
    "            print(\"\\n{0:d} epoch of {1:d}\".format(epoch+1, self.iterations))\n",
    "            avg_loss = cum_loss / processed_batches\n",
    "            print(\" {0:d} {1:d} batches, pairs {2:d}, cum loss: {3:.5f}\".format(i,processed_batches, pairs,cum_loss))\n",
    "            self.loss_list.append(cum_loss)\n",
    "            self.time = time_since_start\n",
    "            self.model = self.model.to(cpu)\n",
    "            score = -1*(wordsim_task(self.get_embedding())[0][1])\n",
    "            print(\"Current score on wordsim Task: {}\".format(score))\n",
    "            self.ws_list.append(score)\n",
    "            self.model = self.model.to(gpu)\n",
    "            self.data.generate_pairs()\n",
    "        \n",
    "        if(save_embedding):\n",
    "            self.save_embedding()\n",
    "            \n",
    "\n",
    "    def get_embedding(self):\n",
    "        embedding_dict = dict()\n",
    "        embedding = self.model.u_embeddings.weight.data.numpy()\n",
    "        for i in range(len(self.data.index2id)):\n",
    "            embedding_dict[self.data.index2id[i]]= embedding[i]\n",
    "        return embedding_dict\n",
    "    \n",
    "    def save_embedding(self, with_loss=True):\n",
    "        print('ntm')\n",
    "        # Creating filename\n",
    "        optim = \"Optim\" + str(self.optimizer).split(\" \")[0] + \"_\"\n",
    "        filename = \"dict_emb_\" +  optim + \"_\".join([x + str(y) for x,y in vars(self).items() if isinstance(y, numbers.Number)]) + \".pkl\"\n",
    "        \n",
    "        # Getting Embedding\n",
    "        self.model.to(torch.device('cpu'))\n",
    "        dict_emb = w2v.get_embedding()\n",
    "        \n",
    "        # Adding loss history to embedding\n",
    "        dict_emb['loss_list'] = [x.to(torch.device('cpu')) for x in self.loss_list]\n",
    "        \n",
    "        # Adding score list to embedding \n",
    "        dict_emb['ws_list'] = self.ws_list\n",
    "        \n",
    "                \n",
    "        # Saving time spent to calculate 1 epoch\n",
    "        dict_emb['time'] = self.time\n",
    "        \n",
    "        # Logging\n",
    "        print(\"Saving embedding: {} to disk with ws_score: {} \".format(filename,dict_emb['ws_list']))\n",
    "    \n",
    "        # Writing embedding dictionnary to disk\n",
    "        with open(filename, 'wb') as output:\n",
    "            pickle.dump(dict_emb, output, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "        self.model.to(device)\n",
    "        self.loss_list = [x.to(device) for x in self.loss_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building vocab\n",
      "vocab build\n",
      "generating pairs\n",
      "pairs generated in  Time:  00:00:48.24\n"
     ]
    }
   ],
   "source": [
    "neg_samples = 10\n",
    "w2v_dataset = W2VDataset(text8_dataset,sample_buffer=500000,neg_samples=neg_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training without shuffling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choosen optimizer is Adam\n",
      "starting training\n",
      "0%==========100%, Time:  00:03:52.85, cum_loss = 143246800.0\n",
      "1 epoch of 2\n",
      " 20938 20939 batches, pairs 41876538, cum loss: 143298960.00000\n",
      "found: 333 missed: 20\n",
      "Current score on wordsim Task: 0.48772968977799863\n",
      "generating pairs\n",
      "pairs generated in  Time:  00:00:54.60\n",
      "0%==========100%, Time:  00:04:43.54, cum_loss = 131173304.0\n",
      "2 epoch of 2\n",
      " 20945 20946 batches, pairs 41890574, cum loss: 131205992.00000\n",
      "found: 333 missed: 20\n",
      "Current score on wordsim Task: 0.5917808204040622\n",
      "generating pairs\n",
      "pairs generated in  Time:  00:00:58.65\n",
      "choosen optimizer is Adam\n",
      "starting training\n",
      "0%==========100%, Time:  00:05:14.15, cum_loss = 143281600.0\n",
      "1 epoch of 2\n",
      " 20937 20938 batches, pairs 41874679, cum loss: 143327856.00000\n",
      "found: 333 missed: 20\n",
      "Current score on wordsim Task: 0.4776594700117363\n",
      "generating pairs\n",
      "pairs generated in  Time:  00:01:00.94\n",
      "0%==========100%, Time:  00:05:26.52, cum_loss = 131143008.0\n",
      "2 epoch of 2\n",
      " 20934 20935 batches, pairs 41868264, cum loss: 131169184.00000\n",
      "found: 333 missed: 20\n",
      "Current score on wordsim Task: 0.5746030578686163\n",
      "generating pairs\n",
      "pairs generated in  Time:  00:01:02.52\n",
      "choosen optimizer is Adam\n",
      "starting training\n",
      "0%0%, Time:  00:00:06.84, cum_loss = 0\r"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "ws_lists_adam_shuffle = []\n",
    "ws_lists_sgd_shuffle = []\n",
    "ADAM_LR = 0.005\n",
    "SGD_LR = 0.075\n",
    "NUMBER_OF_EVAL = 10\n",
    "NUMBER_OF_ITER = 10 \n",
    "for x in range(NUMBER_OF_EVAL):\n",
    "    w2v = W2V(w2v_dataset, neg_samples=neg_samples, alpha=ADAM_LR,shuffle=False,workers=4,iterations=NUMBER_OF_ITER,batch_size=2000,optim='Adam')\n",
    "    w2v.train_with_loader()\n",
    "    ws_lists_adam_shuffle.append(w2v.ws_list)\n",
    "    \n",
    "mean_list_adam = np.mean(ws_lists_adam_shuffle, axis=0)\n",
    "with open('mean_list_adam.pkl', 'wb') as fp:\n",
    "    pickle.dump(mean_list_adam, fp)\n",
    "    \n",
    "for x in range(NUMBER_OF_EVAL):\n",
    "    w2v = W2V(w2v_dataset, neg_samples=neg_samples, alpha=SGD_LR,shuffle=False,workers=4,iterations=NUMBER_OF_ITER,batch_size=2000,optim='Sgd')\n",
    "    w2v.train_with_loader()\n",
    "    ws_lists_sgd_shuffle.append(w2v.ws_list)\n",
    "    \n",
    "mean_list_sgd = np.mean(ws_lists_sgd_shuffle, axis=0)\n",
    "with open('mean_list_sgd.pkl', 'wb') as fp:\n",
    "    pickle.dump(mean_list_sgd, fp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'W2V' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-b5a4862cb3d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mNUMBER_OF_ITER\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUMBER_OF_ITER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mw2v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mW2V\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2v_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mneg_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mADAM_LR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mw2v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_with_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mws_lists_adam_shuffle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mws_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'W2V' is not defined"
     ]
    }
   ],
   "source": [
    "ws_lists_adam_shuffle = []\n",
    "ws_lists_sgd_shuffle = []\n",
    "ADAM_LR = 0.001\n",
    "SGD_LR = 0.05\n",
    "NUMBER_OF_EVAL = 10\n",
    "NUMBER_OF_ITER = 10\n",
    "for x in range(NUMBER_OF_EVAL):\n",
    "    w2v = W2V(w2v_dataset, neg_samples=neg_samples, alpha=ADAM_LR,shuffle=True,workers=4,iterations=NUMBER_OF_ITER,batch_size=2000,optim='Adam')\n",
    "    w2v.train_with_loader()\n",
    "    ws_lists_adam_shuffle.append(w2v.ws_list)\n",
    "    \n",
    "mean_list_adam_shuffle = np.mean(ws_lists_adam_shuffle, axis=0)\n",
    "with open('mean_list_adam_shuffle.pkl', 'wb') as fp:\n",
    "    pickle.dump(mean_list_adam_shuffle, fp)\n",
    "\n",
    "for x in range(NUMBER_OF_EVAL):\n",
    "    w2v = W2V(w2v_dataset, neg_samples=neg_samples, alpha=SGD_LR,shuffle=True,workers=4,iterations=NUMBER_OF_ITER,batch_size=2000,optim='Sgd')\n",
    "    w2v.train_with_loader()\n",
    "    ws_lists_sgd_shuffle.append(w2v.ws_list)\n",
    "    \n",
    "mean_list_sgd_shuffle = np.mean(ws_lists_sgd_shuffle, axis=0)\n",
    "with open('mean_list_sgd_shuffle.pkl', 'wb') as fp:\n",
    "    pickle.dump(mean_list_sgd_shuffle, fp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Gensim\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "from gensim.models import Word2Vec\n",
    "gensim_emb = dict()\n",
    "    \n",
    "class EpochLogger(CallbackAny2Vec):\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "        self.cum_loss = 0\n",
    "        self.loss_list = []\n",
    "        self.ws_list = []\n",
    "        self.prev_score = -1\n",
    "        self.no_improvement =0\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        score = model.wv.evaluate_word_pairs(\"./data/wordsim/combined.tab\")\n",
    "        self.ws_list.append(score[1][0])\n",
    "        print(\"Epoch #{}, ws_score={}\".format(self.epoch,score[1][0]))\n",
    "        self.epoch += 1 \n",
    "            \n",
    "    def on_batch_end(self, model):\n",
    "        \"\"\"Method called at the end of each batch.\n",
    "        Parameters\n",
    "        ----------\n",
    "        model : :class:`~gensim.models.base_any2vec.BaseWordEmbeddingsModel`\n",
    "            Current model.\n",
    "        \"\"\"\n",
    "        self.cum_loss += model.get_latest_training_loss()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #0, ws_score=0.5423840286648558\n",
      "Epoch #1, ws_score=0.6301018249878083\n",
      "Epoch #2, ws_score=0.6588657706574313\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-ebb25224abb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUMBER_OF_EVAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mepoch_logger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEpochLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext8_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnegative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch_logger\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mws_lists_gensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mws_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmean_list_gensim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mws_lists_gensim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sentences, corpus_file, size, alpha, window, min_count, max_vocab_size, sample, seed, workers, min_alpha, sg, hs, negative, ns_exponent, cbow_mean, hashfxn, iter, null_word, trim_rule, sorted_vocab, batch_words, compute_loss, callbacks, max_final_vocab)\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m             \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnegative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbow_mean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcbow_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m             fast_version=FAST_VERSION)\n\u001b[0m\u001b[1;32m    784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m     def _do_train_epoch(self, corpus_file, thread_id, offset, cython_vocab, thread_private_mem, cur_epoch,\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sentences, corpus_file, workers, vector_size, epochs, callbacks, batch_words, trim_rule, sg, alpha, window, seed, hs, negative, ns_exponent, cbow_mean, min_alpha, compute_loss, fast_version, **kwargs)\u001b[0m\n\u001b[1;32m    761\u001b[0m                 \u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m                 \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_total_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m                 end_alpha=self.min_alpha, compute_loss=compute_loss)\n\u001b[0m\u001b[1;32m    764\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtrim_rule\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sentences, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks)\u001b[0m\n\u001b[1;32m    908\u001b[0m             \u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m             queue_factor=queue_factor, report_delay=report_delay, compute_loss=compute_loss, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_sentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport_delay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sentences, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m             \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m             \u001b[0mqueue_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqueue_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport_delay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreport_delay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m             **kwargs)\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_job_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data_iterable, corpus_file, epochs, total_examples, total_words, queue_factor, report_delay, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    551\u001b[0m                 trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch = self._train_epoch(\n\u001b[1;32m    552\u001b[0m                     \u001b[0mdata_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m                     total_words=total_words, queue_factor=queue_factor, report_delay=report_delay)\n\u001b[0m\u001b[1;32m    554\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m                 trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch = self._train_epoch_corpusfile(\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(self, data_iterable, cur_epoch, total_examples, total_words, queue_factor, report_delay)\u001b[0m\n\u001b[1;32m    487\u001b[0m         trained_word_count, raw_word_count, job_tally = self._log_epoch_progress(\n\u001b[1;32m    488\u001b[0m             \u001b[0mprogress_queue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_queue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             report_delay=report_delay, is_corpus_file_mode=False)\n\u001b[0m\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrained_word_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_word_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_tally\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36m_log_epoch_progress\u001b[0;34m(self, progress_queue, job_queue, cur_epoch, total_examples, total_words, report_delay, is_corpus_file_mode)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0munfinished_worker_count\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m             \u001b[0mreport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprogress_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocks if workers too slow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreport\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# a thread reporting that it finished\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m                 \u001b[0munfinished_worker_count\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ws_lists_gensim  = []\n",
    "for x in range(NUMBER_OF_EVAL):\n",
    "    epoch_logger = EpochLogger()\n",
    "    model = Word2Vec(text8_dataset,size=100,window=5,negative=10,min_count=5, sample=1e-4, iter=10, workers=1,sg=1, hs=0,callbacks=[epoch_logger],compute_loss=True)\n",
    "    ws_lists_gensim.append(epoch_logger.ws_list)\n",
    "mean_list_gensim = np.mean(ws_lists_gensim, axis=0)\n",
    "with open('mean_list_gensim.pkl', 'wb') as fp:\n",
    "    pickle.dump(mean_list_gensim, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('mean_list_sgd_shuffle.pkl', 'rb') as fp:\n",
    "    mean_list_sgd_shuffle = pickle.load(fp)\n",
    "with open('mean_list_adam_shuffle.pkl', 'rb') as fp:\n",
    "    mean_list_adam_shuffle = pickle.load(fp)\n",
    "with open('mean_list_adam.pkl', 'rb') as fp:\n",
    "    mean_list_adam = pickle.load(fp)\n",
    "with open('mean_list_sgd.pkl', 'rb') as fp:\n",
    "    mean_list_sgd = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vizualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf0AAAEWCAYAAABsT07JAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nOzdd3xUZfb48c9JKAECSAwSAoSONEEMYldAVFSEVUBZsXxFQPSHi+K6origKIoNwUWNolhRdAWVVRQsBGyoFFE6KJ1EkQAhEAgh5/fHc8cMIWUSMpmU83697itz65yZycy597lPEVXFGGOMMeVfWKgDMMYYY0zJsKRvjDHGVBCW9I0xxpgKwpK+McYYU0FY0jfGGGMqCEv6xhhjTAVhSd8UmYgMFJF5oY4jVESkq4hs85tfKSJdQxhSwEQkUUQGB/k5/k9Evg7mc5Q1InKeiKwt4r5xIpImIuHFHZepOMpt0heRa0VksfclSRKRT0Tk3FDHVZZ4SSzNm46IyEG/+ftUdbqqXlyC8YiI/CYiq0rqOQtDVdupamJxH/d4k6eIPCAibxZnTBWB9/92t4isF5F0EdkiIhNEpGohjqEi0sI3r6pfqerJRYlHVbeoaqSqHinK/sZAOU36IjISmAQ8AtQD4oDngD6hjMufiFQKdQwF8ZJYpKpGAl8Bw33zqvpICEI6HzgJaCYip5fkE5eFz8sUu2eAocANQE3gUqA78G4ogypO9n9dAalquZqA2kAa0D+fbariTgp2eNMkoKq3riuwDbgL+ANIAm7y1p0JJAPhfse6EvjZexwGjAJ+BXbhfhyivHVNAAVuBrYAC73lNwCbve3/DWwCehTieDd6x/sTGO0XVzhwn7fvPmAJ0Mhb1xr4DEgB1gJXB/C+JgKDcyz7P+Brv3kFbgPWe8/5ENAc+A5I9eKv4rd9L+AnYA/wLdChgBimAdOBWcCUHOuigFe8z3M38IHfuj7e86R670dPb3ksMNt7HzYAQ/z2eQB4D3jT228wUA141Tv+KuBuYJvfPv6f3QPe633dey9WAp39tj0NWOat+y/wDvBwLq+5DXAQOIL7v97j93/+OrDT+/+5HwjLZf+eQAZw2Nt/ud/n+RDwjRfDPCDab78zvc9kD7Ac6JrP59LI+0x24v5Pp/j/fwBPeu/ZRuBSv/3ye//z+45GAx95saXgTkjD/I4504tlI/CPHJ9pnp9JjtfU0nvPu+TyWg8B3b35V4EE3PdpH7AAaOytW4j7Tuz33vtr8H5fcvzP3A387G33Mu5C5RPveJ8DdXJ85ysBZ3nH9E0HgU1F/R2yqeJMIQ+g2F+Q+5HLBCrls804YBHuqrGu9+P2kLeuq7f/OKAycBlwwO+L9ytwkd+x/guM8h7f4R23ofej9QLwtrfO92V7HaiBSyBtvS/suUAV3I/jYbITRyDHm+odq6P3Y9TGW3838AtwMiDe+hO9594K3OT9eJyGO2FoV8D7mkhgSX82UAto58XzBdAMl6RWATd6256GO6k6A3eCciPuB7BqHs9fHZd8LwP6ejH7n0B8jEucdbzP7QJveRdgL3AR7sewAdDaW7cAVwIUAZyKSxQXeuse8D6Lv3n7VQMm4BJMFO7HfwX5J/2DXrzhwKPAIm9dFVyiHuHFehUuMR+T9HN7n71lrwMf4q5AmwDrgJvz2P8B4M1cPs9fgVbea0sEJnjrGuCSxWXea7/Im6+by7HDcScFT+P+tyKAc/3iPgwM8ba7FZfAJYD3P7/v6KO4RFvZm87D/Y+H4U5ux3jvcTPgN+CSgj6TXF7XMGBzHusWAI96j1/FJefzcd/RyRz7nWjhN981l/+ZRbhE3wD3nVgKdPKO9yUwNsd3vlKOeCp7n58vpkL9DoX6N9umkp1CHkCxvyAYCCQXsM2vwGV+85eQfZbcFUj3/2J5X8QzvccPA9O8xzVxZ+eNvfnVvh8tb76+96NXye/L1sxv/Rjfl9Gbr4778e9RiOM19Fv/AzDAe7wW6JPLa78G+CrHshd8Pyz5vGeJBJb0z/GbXwLc4zf/FDDJe/w83o+43/q1eMk6l+e/DpcUKnk/ZHuAK/3elyy8E7NcXtvTuSxvhLuSq+m37FHgVe/xA+S4CsIlkJ5+80PJP+l/7reuLZDuPT4f2I6X/LxlXxNg0sclrENAW79ltwCJeez/ALkn/fv95m8DPvUe3wO8kWP7uXgnbDmWn+X7XPKIe0OO/28FYgJ4//P7jo7DnfC0yPF8ZwBbciy7F3iloM8kl9jvJ+8TghnAVO/xq8AMv3WR3uvylaoFkvQH+s3PBJ73m78dr9SKvJP+87iTXl9pR6F+h2yqWFN5vKe/C4gu4F5VLO5Ky2ezt+yvY6hqpt/8AdyXGeAt4CqvMs9VwFJV9R2rMfC+iOwRkT24L98R3Fm8z9Yccfw1r6oHvPh9Ajlech5xNsL9cObUGDjDd0zvuANxP8TF4Xe/x+m5zPviawzclSOORhz9Ofi7EXhXVTNV9RCuOPlGb10jIEVVd+eyX17vQ6y3zz6/ZZtxV1s+W4/e5ejPi6P/h3KT87OJ8P4vY4Htqu4XOY/nyk802aUF/rE0yH3zgOPz/2z65/hszsUlj5wa4a6IM3NZd9RzeP/feM9T0Puf33f0CdztgHlexc5RfnHH5oj7PvL/vkTk8VvxJ7m/Xrzlf/rN+3+H03C3HPL6P85NoN+ZY4jILbgTiWtVNctbXNjfIVOBlMek/x2uCO9v+WyzA/fF8InzlhVIVVfhfoAuBa7FnQT4bMXdszzBb4pQ1e3+h/B7nIQrggNARKrhiuALc7y8bMXdT89t+YIcx4xU1VsDOGZx2gqMzxFHdVV9O+eGItIQV4HqOhFJFpFkoB9wmYhEe8eKEpET8nie3N6HHd4+Nf2WxeGuwH306F1IwiU5/+2LIgloICLit6xRXhvnEsefuCu3nP/Def1f5Ny/IFtxV/r+n00NVZ2Qx7ZxRagQVtD7n+d3VFX3qepdqtoMuAIYKSIXerFszBF3TVW9rJCxgStWbyQiXfwXikgjXH2HL/wWN/JbH4m7/RPQ78nxEJHzcPUy+qjqXr9Vhf0dMhVIuUv63j//GOBZEfmbiFQXkcoicqmIPO5t9jZwv4jU9ZLGGFyFrUC9BfwDV0z7X7/lCcB4EWkM4B0/vxYD7wFXiMjZIlIFeBB3b7Kox/P3EvCQiLT0mh51EJETcRWgWonI9d77UllETheRNgEet7hMBYaJyBlefDVE5PIcScDnetw965Nx935Pxd2L3gb8XVWTcBWfnhOROt5rOt/b92XgJhG5UETCRKSBiLRW1a24+8SPikiEiHTAVW6ank/M7wL3es/REFf0WhTf4a68hotIJe8z7ZLP9r8DDb3/EdQ12XoX979R0/v/GEne/8O/A01EJNDv+5u4/8tLRCTce3+6eq85px9wJzETvM8wQkTOKegJAnj/8/yOikgvEWnhnTSl4t7LI14sqSJyj4hU82JvX5SWHqq6Dvf9my4iZ3rHaocrfv9cVT/32/wyETnX+3weAr73Xh+4975ZYZ+/IN7JxzvADV6s/o7nd8OUc+Uu6QOo6kTcj+D9uPuNW4HhwAfeJg8Di3E1Zn/BVZx5uBBP8TauSO1LVfUv5puMq8g2T0T24SrTnJFPnCtxiWMG7odzH67+wKGiHC+HibjEMA/3w/gyrtLOPuBiYADuaiQZeAx3n7zEqOpiXAWvKbia3Rtw94BzcyPwnKom+0+4HzdfEf/1uKvfNbj38A7veX7AVVp8GlehbwHZV5B/x93j3AG8j6vX8Fk+YT+IK+XZiHtf3yjUi/aoagbu1tDNuLoJ1+FOxg7lscuXuJrmySLi+3+7HVef5DdcfYC3cK0bcuM7Md0lIksDiG8rrsXDfWR/f+4ml98L7wTkCqAFrjb4Nly9kUDk9/7n9x1tiavVnoY7gXpOVRP9YjkV9xn9iTv5rR1gPDkN9/Z/03uuT3F1Ifrm2O4tYCyuWD8ed7vM5wHgNa+o/eoixpGbC3G35N6T7L4zVnrrjud3w5Rzvlq0phTwigb3AC1VdWOo4zElR0S+BxJU9ZVQx2ICJyKv4irm3R/qWIwJRLm80i9LROQK7xZEDVyTvV9wNXpNOSYiF4hIjFe8fyPQAXclaYwxQWNJP/T6kN0BSUtckzsrfin/Tsa1b9+L6wiqn1c3wRhjgsaK940xxpgKwq70jTHGmAqiXA22EB0drU2aNCnSvvv376dGjRrFG1AxsLgKx+IqHIurcMpjXEuWLPlTVesWc0imlCpXSb9JkyYsXry4SPsmJibStWvX4g2oGFhchWNxFY7FVTjlMS4RKahnSVOOWPG+McYYU0FY0jfGGGMqCEv6xhhjTAVhSd8YY4ypICzpG2OMMRWEJX1jjCmjpk+HJk2ge/cLaNLEzRuTn3LVZM8YYyqK6dNh6FA4cABA2LzZzQMMHJjfnqYisyt9Y4wpY/bvh7vv9iX8bAcOwOjRoYnJlA2W9I0xppTJzISNG+GLL2D3brfsk0/gzDPhpJMgMhKS8hieacuWkovTlD2W9I0xpoSpQnIyfPed+wuwdCl07w5Nm0JEBDRrBj16wA8/uPVVqrhk/7e/wSOPQHR07seOiyuZ12DKJrunb4wxQZCa6q7W69RxiXjLFrjtNrds40ZIT3fbvfQS3HyzS+qHDsE557jE37SpS/ydOrntLrzQTT5xcf739J3q1WH8+JJ7jabssaRvjDFFkJEBmzdDpUouQe/fDzfd5BL6b79BSorbbuxYeOABl5C3b4eTT4aePbOT+mmnue3at4dvvgn8+X2V9UaPhi1blLg4Yfx4q8Rn8mdJ3xhjcpGV5e6bHzwIzZu7ZU891YqxY11S377dFdMPGgQvv+yS+urVEBsL8fEuoTdtmp3Uo6Nh2bLijXHgQDclJi4olQMBmdLHkr4xpsLavRt27YIWLdz8Aw/A99+7pL55sytu79EDPvvMrd+ypTq1akG3btlJ/dRT3ToR+OWXkLwMYwIW1KQvIj2ByUA48JKqTshlm67AJKAy8KeqXiAijYDXgRggC3hRVScHM1ZjTPmTnu6u1ps1c/PPP+8SuO+++t690Lq1u0IH+Pln+OMP6NAB+vRxSb19++zjTZ78k11RmzItaElfRMKBZ4GLgG3AjyIyW1VX+W1zAvAc0FNVt4jISd6qTOAuVV0qIjWBJSLymf++xhhz5IgrZvfVWH/vPfjgg+yknpQENWrAvn3uSnz5cpfgmzXLrjDXqlX28WbNCs3rMKakBPNKvwuwQVV/AxCRGUAfwD9xXwvMUtUtAKr6h/c3CUjyHu8TkdVAgxz7GmPKOVX480844QSoXBkSE+Gtt7KT+ubNrk17SoqrJb9iBXz9tUvm/pXlsrIgPBwSEkL9iowJLVHV4BxYpB/uCn6wN389cIaqDvfbxles3w6oCUxW1ddzHKcJsBBor6qpuTzPUGAoQL169eJnzJhRpHjT0tKIjIws0r7BZHEVjsVVOKUhrvT0MMLDlSpVlF9/rcEnn9Rn27ZK/PFHJElJ1Th4MJypU3+kRYv9zJ5dn1deaUpMzEHq1z9I/frp1K9/kO7d/6B69SNBj7U0vF+5OZ64unXrtkRVOxdzSKa0UtWgTEB/3H183/z1wH9ybDMFWATUAKKB9UArv/WRwBLgqkCeMz4+Xotq/vz5Rd43mCyuwrG4Cqck4srIUE1Pd483b1a9917VAQNUu3RRrVtXFVQ/+sit//hj1Ro1VJs23adXXKE6YoTqpEmqO3a49VlZQQ83X+XxcwQWa5DygE2lbwpm8f42oJHffENgRy7b/Kmq+4H9IrIQ6AisE5HKwExguqranTZjSilV12a9alXYswemTHG1331F8Fu3wrPPwrBhruLcE0+4e/DNmrne5Zo2hZYt3bF69nT33xcsWJxrhTmRkn1txpQ3wUz6PwItRaQpsB0YgLuH7+9DYIqIVAKqAGcAT4uIAC8Dq1V1YhBjNMYEIDPTdUKTmQnPPHN0Ut+4EUaOzO4J7t//hpgYl9TPPdcl9fh4t65dO1ejvlIevzxh1jG4MUEVtKSvqpkiMhyYi2uyN01VV4rIMG99gqquFpFPgZ9xTfNeUtUVInIu7nbALyLyk3fI+1R1TrDiNaYiy8rKTrivvOJquPsn9csvh9dfd5Xhxo512zZr5pq7XXopXHCB2/eEE1y3sNWq5f48YWGW2I0JpaC20/eS9JwcyxJyzD8BPJFj2deAFeSZsm/6dBg9mgu2bHFl2iHqJ1U1u2h89mzXM9zGjbBs2amkpLiuYT//3K1/4gn49Vdo0sRdpZ9+Opx/vlsn4prI1ayZd1F7XgnfGBN61iOfMcEyffpfI6IIuPZlQ4e6dUFM/AsXul7lfH3Ab9zomrutWOHWP/us66CmQQOIinKDuPiK38E1eTvhhLyvyGvVClroxpggs6RvTHHzXVbfc8/RQ6CBm7/nHpf09+93/cBGRbnL4wBrqS1f7hKzf1JPSoIdO1yifv111xd8VJS7Uu/Y8egOaN580yXuqlUhMfHYHuaioo7z9RtjSi1L+sYUhqrrBq5SJdcjzBtvuDFTN2/OniZNgmuvdVk4N77ln3/uqq+Dy8BRURAVxbbxr/FZSjyHvvqBRoveZdv+KH7bE8V9T0ZRu2kUH395JqMfjaRG1UzimobTtJlwzjmun/hq1eDRR2HixLyvyOvWLf63xRhTNljSN8bfkSNuWLUaNVw180mTXCL3T+z33w+jRkFaGtxxh8u0jRu7qVMn9xfYH9WQGru2HvMU+05oyMczIGVpRyLPe5GMpBSO7Eyh75kpREsKi1bVYtB9cKOs4Qaep7p6pQXenYFh36zmpttbEzNjCnL3P2FXFPwaBRe6k4a6r74KtaLdOK3Llv11MkGdOu5v8+ZWm86YCsqSvqlY0tNdsq5b1121P/BAdn+uW7bAtm3uvvuzz7qr+X//293gbtzYlZFfdJGr2QbQsCHs3AknnnhM0XxKCtyX8ShPMZQaZBfx76c6d2c+ygt/B2hC3bpDaNoUmsbDOfdDdHu4cDdsuBri4m6gcuUb3EnI7t3uoCkpRJ3WBCKALqe7WwXeclJSXDl/lSruyT780NXKy+ngQVeycO+9nPH6624sWN+JQXQ0/Oc/brtvv3VD0PnW+U4cfMc3xpQ5lvRN+aFKpdRUl8SbNnXLHn4Yfvop+yp9507o3dslRBF49VW3XVycG4GlcWM47zy3rHJlSE11A6XnJiwMoqPZvRuWLIGTTnKjs61ZA23aAAwkFXiE0cSxhS3EcR/jmZE2kJ9/diHm1nNqnTpu+ktEBNSv7yZ/55zjpryMHw933519QrB7t+s9p2pVt75NG1LbtqVa5cpu/caN7kTIZ+JEmDnz6GPGxrrq+wAjRrixZP1PCpo3hyFD3Prly9177FtXiHoLxpjgsKRvyo4jR9z98F27sgcxf/xxNwqLl9TP3b/fFbEvXerWz5/v9omLyy569+0LLtHlV9SdS8LPynIX0EuWuOm339zyW2+F555zY7M/9hg89RS8/cdA3ubomvqN4+CUU47jfQhU5cquRCOvm/g33MDquDjq5TVU7DPPwL33uhOCXbvcX//3KiICDh92jfp923TsmJ30Bw3K/hzAnWz07OmGwQO4/XZXmdH/pKFNm+xG/1u3uooJtWrZyYIxxcSSvik90tNdEfuOHdCtm1v2n/+4q83Nm13Re2amK07/80+3fsMG+P1319D84ovZkJFBi8svzz7mF1/k/5z5JPzdu13O8iX3k05y4YSFuXHZw8JcU7chQ6Bz5+xmb5Uqwb/+5ZrEeS32/lK9enbPdaVebKyb8vLYY0fP+/rj9ZkyxX2W/rcfGvn1zL1qFaxb55b73qSrr85O+h06uJKJ8PDs+gjXXut6BwLXDWDt2kefNJx8sus1SDV7aD1jzF8s6ZuSoep+3H0V4i691F35vfqqu3/uK3r38XXrlprqrvDPOcddrfsqzPmaxb344lFPsy0xkRZ5XbnmY88ed/7Q2RtrrG/fo8dWb9LE9Urns2pV3qX+Pr6m+KNHw5YtSlychKpvnpIhkn3rAOCss/Lf3v+EzFdvwd+kSdklDL7ppJPcukOHYNo015m/v3vugQkT3PI6dVx9DP9KjEOGQP/+7v/qpZeOPmGIinInJTVrFv09MKaUs6Rvioev6N2X1C+5xF2Rz5rlKsNt2eIq0PmsW+dGWQkPd9v5it4bN3bJ3dc5++jRbipmy5fDvHnuCn7xYtcDne8co1Ild07iu3qPj3ch+iso4fsMHOimxMQFuQ4gYzy+egv+brwx7+19o/tkZrq/OU8KwsJciYB/fYaUFHdyAa7U6K67jj3uCy+44pnly6FXL/fB+50URHbuDF27QnKyq+joO5nwTdWr260IU6pZ0jeB8RW9e/fOI2rUcMvnz3f3bn1F7z6ff+66ejvhhOxa776E7vsLcP31bgqSvXuzi+gXL3bF8nXquHp8Y8e6UOLj4eabj+6VbvDgoIVkilOlSq7FQXT00ctr1XItM/LSps3RJwu+yVfUU60a9OiRvdyrt1ClWTO3fvFiVxyU07x57n/9s89g3LhjSxIGDXInN77elHzLi1pvoZR082zKDkv6xhWV796dXcN9yxY4+2z3A/jLL+7H748/jtql9j33uPur9epl13r3L373/Th27+6mErB3L6Snu3v0n3/uKtZt2JC9vnFjVzesTh247TY35cwVpoIQcfUBatfObunhr1UrN/JQDimJie5B166uVYhfU0pSUtwIRD6VK7vv07Jlbt3+/a4zpvr14b334B//yN7WV29hyRL3PZo5E95//9iThv79XSlHSgq8+64rrSjhbp5N2WZJvyLIWfS+ebOrwX7ppa4SXPPm7gfJ3/jxLunHxECfPsck9T/Wr6cNQNu2rl/XEnboEHz3XfYV/JIlsH493HdfNJde6s5FTjkF/u//sovp/RO8JXtzXCIjXUuFvFx0kZv8HTqUfduqd2/3XcpZ0uBrq5mU5P7Bd+06ut6Cr3ThoYdcnYecDhxwt8Ms6Zs8WNIvD/yL3n1/W7Rw90SPHHEVk9LTj95nxAiX9KOjXeUm/6v0uLjsrFi37jGV5QB048YSeGFOaqq7WFq82JXKXnaZq/Pnq+DfqJFL7DfeCA0bunoDp5xydEU8Y0LOv5Kj77uWl+HD3QRH11vwDWHYv3/uSR/cb4AxebCkXxbs3g2bNh3dv3vduq4NNbgiRf8veliYO9O/8cbsAdB9vcrFxbnJ1ytMeDg8/XSJv6S8HDniQlJ1V+mLFrk6fz633eaSfoMGMHeuK7Dw1d0CSEw8cMwxjSnTcqu3cPbZ7vu8efOx2/vqyxiTC0v6pUFysqs+7n9PPSzMNWUDV4v422+zt/dVMvIZN85lSt/VeoMG2cWI4JoxlUL79mVfwfvawjds6O7Hi7hqBG3auHp+vlr0vgQvAhdfHNr4jQmp8ePLeEcQJhQs6ZeE7dtdw27/K/WUFPjoI7f+jjvgnXeytz/xRNcxic/o0a6pkS+pR0cfXdM3v6ZNpYQvwf/6K9x0k1vWr5+r7Awu2cfHZ/fLAvDJJyUfpzFlhl9HELplC2K1900ALOkXR5OXbdvc5ap/RbktW+DLL10x+qRJ8OSTbtuwMHcl3rix672sShW4805Xlu0rfvc1h/O57LJieaklbd48N7b7kiWwdq0rsg8Lc52u1ajhCiBGjHDJvl69UEdrTBnkdQSxIDHR+oEwAanYSX/69L+Kx/Jt8rJ9OyxYcOwQq++/75r2zJrlshdkD7MaF+c6o4mMdI2+r7jCLY+NdU15/J1xRkm82qBIS3NX8L7i+SVLYM4c14PdmjWuW/z4eNe6z1dE7zunKaGWfMYYYzxBTfoi0hOYDIQDL6nqhFy26QpMAioDf6rqBYHue9xGjz76fhi4+ZtvdmOmv/yyy0w//JB9EnDiiS6ht2qVPSJZv37Z3cTmLHoH1x/4yScXe/glLS3NNU32NcH/+GN3LuN7G2JjXVL3NRQYPvzopsjGmPJjyZIlJ1WqVOkloD2Qz6hVpgRlASsyMzMHx8fH/5HbBkFL+iISDjwLXARsA34UkdmquspvmxOA54CeqrpFRE4KdN9ikVfTlkOHXBKvVcvNd+8OK1ceXevdX0EDk5RRqamufxLfFfzq1S7BT5kC7dq5mvNjx2a3g4+JOXr//AavM8aUbZUqVXopJiamTd26dXeHhYVpwXuYYMvKypKdO3e2TU5Ofgnonds2wbzS7wJsUNXfAERkBtAH8E/c1wKzVHULgKr+UYh9j19cXO5NXho3PrrDGV/PXeXU/v3uCt6X3M84wzWNA1fHsH59l9ivvtol9zPPhBUrXNUE34BnxpgKp70l/NIlLCxM69atuzc5Obl9XtsEM+k3ALb6zW8Dct68bgVUFpFEoCYwWVVfD3BfAERkKDAUoF69eiT6uskMwEnXXcfJTz5J+KFDfy07UrUqa6+7jj8KcZxgSktLK9RrKsjBg2GkpFQhNtYNPDJ8eCdWr65FVpa7JREVdYiwsB0kJrqToVmzKlOnzuGjjrFiRfHHVVwsrsKxuArH4jpKmCX80sf7TPIsZw1m0s9t9Iic/yCVgHjgQqAa8J2ILApwX7dQ9UXgRYDOnTtroWqwdu3qGoL7NXkJHz+etgMH0jbwowRV4nHWyl22DL7+Oru72tWrXbH8kiVu/RVXuCoJvkp2sbFVgabeFLy4gsXiKhyLq3AsLlPWBTPpbwMa+c03BHbkss2fqrof2C8iC4GOAe5bPMpJk5cDB9xooEuWuB7snnnGLZ8wwY3LUa+eK6Lv2/foxgKPPhqaeI0xxpS8YFa1+hFoKSJNRaQKMACYnWObD4HzRKSSiFTHFeGvDnDfCis93XVXC/DWW66f+Vq1XM+ct9/ukvyePW79I4+4bgSSklxfQA8+WGab/RtjyrCEBKJiYzklLIz42FhOSUggKlSxNGjQ4JSkpKRCXfQWZZ+HH374pGbNmrXr3bt30/T0dDn77LNbtW7duu3UqVPrdOnS5eSFCxdWL1zkxy9oV/qqmikiw4G5uGZ301R1pYgM89YnqOpqEfkU+BnX1E8HIxoAACAASURBVOAlVV0BkNu+wYq1NMvICGPRouxKdosXu879Fi92xfQREa4+4pVXZhfRN2iQ3WqwefPQxm+MMQkJRN15J40PHnQXmklJVLnzThoDDBtGSmijC56XX3657ieffLK+devWGV988UWNw4cPy5o1a1YBTJ069aSC9g+GoLbTV9U5wJwcyxJyzD8BPBHIvuVdejr8/LNL6Oed53riXb68Nv/6l1t/0kkuqffp48bPAbjqKjcZY0wodenCMZ2RXHUVKaNGsfPBB2ngS/g+Bw8SNmoUjYYNIyUpiUp9+nDUJcoPP7A2v+dLTU0N6927d7OkpKQqWVlZ8q9//WtHrVq1skaNGtUwKioq85RTTjmwefPmqvPnz9+QnJwc3rdv32YpKSmVO3XqtF817/qHuR13yJAhuwEef/zxk+bOnVs7MzNT3nnnnd86dep0cOTIkbGRkZFHxo0b9ztAy5Yt23300UfrH3zwwZht27ZV7d27d4v+/funvPHGG9G7d++u1Lp167YzZ8781f85Z82aVWvcuHGxGRkZ0rhx40MzZszYVLt27awC3/QiqNg98oWQqrsa370b7rrLXcWvXJldbP/44y7pt22byvvvu2TfsOGx/f4YY0xp9/vvVMlt+d69Rc9Bs2bNqhUTE3M4MTFxA8CuXbvC27Vr1y4xMXFN69atM6644oq/aiOPGjUq9qyzzkp78sknk2bMmFH77bffji7McX3roqOjM1etWrV6woQJdSdMmFDvnXfeyaXNt/PWW29tWbBgQe0FCxasq1+/fuZZZ521/6mnnqo3f/78Df7bJSUlVXrkkUfqL1y4cF2tWrWyRo8eHfPQQw/Ve/LJJ5OK+t7kx5J+CTh4MPsK3ldM3707TJzo+vr54gto29bVpI+PdxXuGjZ0+9aocYQyXL/QGFNB5HdlHhNDRlLSsYm/fn0yvL+ZBV3Z53Taaaeljx49utGtt97aoE+fPntr1ap1pFGjRodat26dATBgwICUl156qS7AokWLas6aNWuDt3zvLbfcciTQ4/bs2TPNt+7aa6/dDdClS5cDs2fPrlOYePOSmJhY49dff43o0qVLa4DDhw9LfHx8WkH7FZUl/WLmS/C7d8Mll7hlbdrApk3ucXS0S+xt2rj5ypVz7x/IGGPKizFj2O5/Tx8gIoKsMWPYXtRjdujQ4dDSpUtXzZw5s/bo0aMbdO3aNTW/7cMC7CI053E///zzVN9Vd0REhAJUqlRJMzMzxfc4Kyu7JP7QoUOFKo9VVc4999zU//3vfxsLs19RWUepxWDWLDemTqdOULPm0T3agRvuftYsl9z/+AM+/RSGDAldvMYYU5KGDSPl6afZXL8+GSLuCv/pp9l8PJX4Nm3aVLlmzZpZt912W8odd9zx+/fffx+5devWqmvXrq0C8M477/zVOuDMM8/cN23atBMB3n333VqpqanhgR73p59+yreGfZMmTQ799NNPNQC+/vrr6tu3b69amNfRtWvX/YsXL45csWJFVYB9+/aF/fzzz4U6RmHYlX6ADh1yV/D+Nei//tr1Lz93LnzwgbuCv/vu7L7ofa6/PnRxG2NMaTBsGCnFWVN/yZIl1e69996GYWFhVKpUSZ977rnN27Ztq9yzZ8+WUVFRmZ06ddrv23bChAk7+vbt26xt27ZtzjrrrLT69etnFOa4+cVxww037J4+ffqJrVu3bnvqqafub9y48cHCvI7Y2NjMF154YdOAAQOaZWRkCMDYsWO3d+jQ4VBB+xZFQElfRM4FWqrqKyJSF4hU1RIpigi26dPdYHtbtlxAXByMH+96qPv5ZzeoTPXq8Nxzrg/6w15vtFFRLqnv3u0G3Zs0CRISrJKdMcaUlL59+6b27dv3qPFY9u7dG3bttdeuzMrK4oYbboiLj4/fDxATE3Pkm2++We+36VbykNtxAbZv3/6L7/H5559/4IcfflgLEBkZqTmOnes+vXr12terV699vnnf/gC9e/fe17t379X5vuBiUmDxvoiMBe4B7vUWVQbezHuPsmP6dBg61BW7qwqbN7ur8urVoUsXN6IuuGL7u+6C996DjRvhzz9h3jyX8AGqVbOEb4wxoTZp0qTo1q1bt23ZsmW71NTU8JEjR/4Z6phKm0Cu9K8EOgFLAVR1h4jUDGpUJWT0aNd9rT9Vd1/+5ZddkzmAs85ykzHGmNJr7Nixf4wdOzbXceRzSk5ODu/atesxfQskJiaujYmJybN2f1kXSNLPUFUVEQUQkRpBjqnEbNmS+/J9+1wRvzHGmPIpJibmiK93vIokkNr774rIC8AJIjIE+ByYGtywSkZcXOGWG2OMMWVZgUlfVZ8E3gNmAicDY1T1P8EOrCSMH+/u3/urXt0tN8YYY8qbfIv3RSQcmKuqPYDPSiakkjNwoPvrau8rcXHC+PHZy40xxpjyJN8rfVU9AhwQkdolFE+JGzjQ9Zb35ZcL2LTJEr4xxpR3RRkmt7wI5J7+QeAXEXlZRJ7xTcEOzJhyYfp0aNKEC7p3hyZN3LwxFVBCAlGxsZwSFkZ8bCynJCQQVfBeprgFcqbzsTcZYwrD1xHEgQMIuA4hhg5166xIyVQgCQlE+fe9n5RElTvvpDG4nvqKcsxgDa1b3hWY9FX1NRGpArTyFq1V1cPBDcuYciC3jiAOHHDLLembcmTQIBqtWEGefdQvX06NjAyO6sLs4EHCRoygybRp1M1tn/btOTBtWt495wVraN3yLpAe+boC64FngeeAdSJyfpDjMqbsy6sjiLyWG1NO5Uz4BS0PxGmnnZb+1Vdf1br11lsbfPrpp5Fr166tknNoXd+2ixYtqjlo0KBd3vK9tWrVKred7xQkkOL9p4CLVXUtgIi0At4G4vPdy5iKLjoadu48drl1BGHKmfyuyAFiYzklKYkqOZfXr0/GDz+wNrd9ChKsoXXLu0Dehcq+hA+gqutw/e8bY/Ly8ssu4ef8obGOIEwFNGYM2yMiyPJfFhFB1pgxbC/qMYM1tG55F8iV/mIReRl4w5sfCCwJ5OAi0hOYDIQDL6nqhBzruwIfAr4R+2ap6jhv3Z3AYECBX4CbVLVQQxYaU+JUYcIEuO8+uPhiuOYaGDcO3bIF8Q3jaPfzTQXjq6w3bhwNkpOpEhNDxpgxbD+eoXaDNbRueRdI0r8V+H/APwABFuLu7efL69jnWeAiYBvwo4jMVtWcfR1/paq9cuzbwHu+tqqaLiLvAgOAVwOI15jQyMqCkSNh8mT4+9/h1VehShUYNIgFiYl07do11BEaEzLDhpFyPEk+p2ANrVveBZL0KwGTVXUi/JXMqwawXxdgg6r+5u03A+gDBDrAQSWgmogcBqoDOwLcz5iSl5EBN90Eb70F//gHPP30sUX7xpigmjRpUvTbb78dffjwYWnXrt0BG1r3WFJQe0URWQT0UNU0bz4SmKeqZxewXz+gp6oO9uavB85Q1eF+23TF9em/DZfU/6mqK711I4DxQLr3fLmWiYrIUGAoQL169eJnzJhR0GvOVVpaGpGRkUXaN5gsrsIJRVzh6em0GzOGqMWL+W3wYLZcey3I0ZWS7f0qHIurcI4nrm7dui1R1c6F3W/58uWbOnbsaEm1FFq+fHl0x44dm+S2LpAr/QhfwgdQ1TQRybM9pp/cmmLkPMNYCjT2jnkZ8AHQUkTq4EoFmgJ7gP+KyHWq+uYxB1R9EXgRoHPnzlrUItTEUlr8anEVTonHtXMnXH45LF0KU6fSbPBgmpWGuAJkcRWOxWXKukDKH/eLyGm+GRGJx119F2Qb0MhvviE5iuhVNdV3QqGqc4DKIhIN9AA2qupOryOgWUC+JQvGlLjNm+Hcc+GXX2DWLBg8ONQRGWNMvgK50r8Dd6XtS9j1gWsC2O9H3FV7U2A7riLetf4biEgM8Luqqoh0wZ2E7AK2AGd6JQrpwIXA4gCe05iSsWIFXHIJ7N8P8+bBeeeFOiJjjClQIN3w/igirYGTcUX2awLphldVM0VkODAX12RvmqquFJFh3voEoB9wq4hk4pL7AHWVDL4Xkfdwxf+ZwDK8InxjQu7rr+GKK6BaNVi4EDp0CHVExhgTkAKTvoj0Bz5V1RUicj/woIg8rKpLC9rXK7Kfk2NZgt/jKcCUPPYdC4wt6DmMKVH/+x9cfTU0auSu8Js0CXVExhgTsEDu6f9bVfeJyLnAJcBrwPPBDcuYUuiVV+DKK6FdO3e1bwnfmMAlJEQRG3sKYWHxxMaeQkJC0IfWfeaZZ0684YYbSrTf6759+zZ55ZVX6hRmn08//TSyRYsW7Vq3bt02LS1NbrnlloYtWrRod8sttzQcOXJk7JgxY+oVV3yBJH3fwASXA8+r6odwbB/KxpRbqvDYYzBoEHTrBvPnw0knhToqY8qOhIQo7ryzMUlJVVCFpKQq3Hln45JI/GXB66+/HnX77bcnr1mzZlVkZKROnz697i+//LLqhRde2FbczxVI0t8uIi8AVwNzRKRqgPsZU/ZlZcFdd8GoUa5L3Y8/hpo1Qx2VMaVPly4nHzNNmOCGzX3wwQYcPHh03jh4MIxRo1wLr6SkSsfsG4AePXo0b9euXZsWLVq0e/LJJ6MBJk+efGKTJk3an3766Sd/++23f3Ve8NZbb9Xu0KFD6zZt2rQ9++yzW23durUSwMiRI2OvuuqqJuecc07LBg0anPLaa6+dMGzYsIatWrVqe95557U8dOhQniMB3nbbbQ2aN2/erlWrVm2HDh3a0Ld8wYIFkZ06dWrdsGHDU3xX/R999FHNbt26tfBtc8MNN8Q988wzJ06cODH6448/jnr88cdje/fu3bR79+4t0tPTwzp16tRm6tSpR5UYrFy5sup5553Xsl27dm3i4+NPXrZsWUQg75O/QJL31bjKeD1VdQ8QBdxd2CcypszJyIAbbnC9691+u+ttr4oVchlTaL//nvsXZ+/eQFqQ5Wn69OmbVq5cufqnn35a9cILL9TbuHFj5QkTJsR+++23a7766qt169atq+bb9qKLLkr76aef1qxevXpVv379UsaNGxfjW7d58+aqX3755Yb33ntvw7Bhw5p27949dd26dasiIiKy3n333dq5v6Tfw+fMmVNn/fr1K9etW7fqkUceSfJbV3nx4sVrPvzww/Vjx45tkN9rGDly5J89evTY8/DDD2+bPXv2xi+//HJD1apVs9asWbNqyJAhu/23HTx4cOPnnntuy8qVK1c/8cQT22699dZC37oIpPb+AVw7ed98EpCU9x7GlAP790PfvjB3Ljz8sBtAR4o89Lcx5d8PP+Q9RG5MTAZJSccmft/AN/XrZ+a7fx4ee+yxeh9//PEJAMnJyZWnTp164plnnrkvNjY2E+Cqq65KWbduXQTAxo0bq/ztb39ruHPnzsoZGRlhjRo1OuQ7To8ePfZWrVpVu3Tpkn7kyBHp169fKkC7du3SN27cmOsJS1RU1JGqVatmDRgwoPHll1++95prrtnrW9e7d+894eHhxMfHH9y1a1exjEq7d+/esGXLlkX279+/uW9ZRkZGoX+UrJjemJz+/BO6d4fPPoMXX4TRoy3hG3M8xozZTkTEUUPrEhGRxZgxRR5a96OPPqq5YMGCmosXL16zdu3aVW3atElv06bNQcnjuzp8+PC422677Y9169atmjJlyuZDhw79lf+qVq2qAOHh4VSqVEnDvHEzwsLCyMzMzPWAlStX5qefflrdt2/fPR988MEJXbt2bZn90iL+6n3W19V95cqVNSsr+y3I77ZBbo4cOULNmjUz16xZs8o3/fbbbysLcwywpG/M0bZscb3sLV8OM2fCkCGhjsiYsm/YsBSefnoz9etnIOKu8J9+ejPDhhV51L09e/aE165d+0jNmjWzli1bFrF8+fIaBw4cCFu0aFHN5OTk8EOHDsn777//1z3xffv2hcfFxR0GePXVV0883pe0d+/esJSUlPBrrrlmb0JCwtbVq1fn2z198+bND23YsKFaenq67Nq1K/zrr7+uVZjni4qKymrYsGHGtGnT6gBkZWXx3XffVStov5wCaac/HJiuqrsL2taYMm3lStfL3r59rlj/ggtCHZEx5cewYSnHk+Rz6tu3794XX3yxbqtWrdo2b978YMeOHfc3aNDg8D333LPjzDPPbFO3bt3DHTp0OHDkyBEBGD169I6///3vzevVq5fRuXPn/Vu2bAlktNg87dmzJ7xXr14tfFfsDz/8cL7D9bZo0eLwFVdcsbtNmzbtmjZterBdu3YHCvucb7/99m9Dhgxp/Nhjj9XPzMyUK6+8MuWss84KpFv8vwRSiSIG+FFElgLTgLla0NB8xpQ1334LvXpB1aqul72OHUMdkTEmH9WqVdOFCxeuz23diBEjduVcdt111+257rrr9uRcPnHixKPGhDlw4MCyvNb5a9y48eFffvlldc7lM2fO3JTX8RISErbhxqUJeB//GFq3bp3x1Vdf5fqaA1Vg8b6q3g+0BF4G/g9YLyKPiEjzfHc0pqz4+GPo0QNOPNElf0v4xphyKqDmEt6AOMlAMq4v/DrAeyLymar+K5gBGhNUr70GN98Mp54Kc+ZYpzvGmGNcdNFFzbdu3XrU7YDx48dv69u3b2qoYiqqQO7p/wO4EfgTeAm4W1UPi0gYsB6wpG/KpieegH/9Cy68EN5/3zrdMcbk6rPPPvs11DEUl0Cu9KOBq1R1s/9CVc0SkV7BCcuYIMrKcsn+qafc4Dmvv+7u5RtjTDkXSJO9pjkTvoi8AaCqx1RiMKZUO3wY/u//XMIfPhzeftsSvjGmwgjkSr+d/4yIhAPxwQnHmCDavx/694dPPoFx4+D++63THWNMhZLnlb6I3Csi+4AOIpLqTfuAP4APSyxCY4rDrl2uhv7cufDCC/Dvf1vCN6acC8XQuqVdnklfVR9V1ZrAE6pay5tqquqJqnpvCcZozPHZuhXOOw+WLYP//heGDg11RMZUPAkJUcTGnkJYWDyxsafYsLqhkWfxvoi0VtU1wH9F5LSc61V1aVAjM6Y4rFrletlLTYVPP4WuXUMdkTEVT0JCFHfe2fiv4XWTkqpw552NAY6nl74ePXo0T0pKqnLo0KGwYcOG/f7Pf/7zz8mTJ5/49NNP169bt+7h5s2bH6xSpYqCG1p3woQJ9Q8fPhxWp06dzHfeeee3Ro0aZY4cOTJ206ZNVX7//ffKmzZtinjkkUe2fvfdd5FffvllrXr16h3+/PPPN/j65i8P8runPxIYCjyVyzoFugclImOKy3ffweWXu+FwFyxwbfGNMcVv0KBGrFiRd9/zy5fXIOeIcAcPhjFiRBOmTaub6z7t2x9g2rR8u7adPn36pnr16h1JS0uTTp06te3bt+/eCRMmxC5ZsmR1VFTUkbPPPvvk9u3bHwA3tO6AAQPWhIWFMXHixOhx48bFTJ06dRu4oXW//fbbdUuXLo3o3r1769dee+3XhISEbRdddFHzd999t/b1119/TE9+ZVWeSV9Vh3pt8e9X1W+KcnAR6QlMBsKBl1R1Qo71XXH1AzZ6i2ap6jhv3Qm4fgHa404yBqnqd0WJw1RAc+ZAv34QGwvz5kGzZqGOyJiKK68hYIswNKy/UA6tW1blW3vfa4v/JHBWYQ/s1fJ/FrgI19fwjyIyW1VX5dj0K1XNrb3/ZOBTVe0nIlWAfEcwMuYvr78OgwZBhw6upn69eqGOyJjyrYArcmJjTyEp6djkWb9+Bj/8sLYoT+k/tG7NmjWzunTpcnKbNm0OrlmzJiK37YcPHx43YsSI5IEDB+796KOPao4bNy7Wt64oQ+uWVYG0058nIn0lr0GK89YF2KCqv6lqBjAD6BPIjiJSCzgf198/qpqhquWmeMUET6N33oEbb3Qj5CUmWsI3pjQYM2Y7ERFZRy2LiMhizJjtRT1kqIfWLasCaac/EqgBZIrIQUBw3fEXNBZwA8D/7G8bcEYu250lIsuBHcA/VXUl0AzYCbwiIh2BJcAIVd2fc2cRGYqre0C9evVITEwM4CUdKy0trcj7BpPFFaCsLJq9+CLN33mHPy64gNX33IMuLT11TUvd++WxuArH4ioiX2W9ceMakJxchZiYDMaM2X48lfhCPbRuWSXBGiVXRPoDl6jqYG/+eqCLqt7ut00tIEtV00TkMmCyqrYUkc7AIuAcVf1eRCYDqar67/yes3Pnzrp48eIixZuYmEjXUliz2+IKwOHDMHgwvP462/v0ocHMmRAeHuqojlKq3i8/FlfhlMe4RGSJqnYu7H7Lly/f1LFjxz+L9KQmqJYvXx7dsWPHJrmtC2iUPRGpgxte9697Jaq6sIDdtgGN/OYb4q7m/6KqqX6P54jIcyIS7e27TVW/91a/B4wKJFZTwRw44PrP//hjePBB1p93Hg1KWcI3xpjSosB7+iIyGFgIzAUe9P4+EMCxfwRaikhTryLeAGB2jmPH+OoKiEgXL55dqpoMbBWRk71NLwRyVgA0FV1Kiutlb84ceP55GDPGetkzxph8BHKlPwI4HVikqt1EpDUu+edLVTNFZDjuJCEcmKaqK0VkmLc+AegH3CoimUA6MECz7zfcDkz3Thh+A24q5Gsz5dm2ba7TnQ0bXC97ffuGOiJjKpqsrKwsCQsLKzcd15QHWVlZAmTltT6QpH9QVQ+KCCJSVVXX+F2B50tV5wBzcixL8Hs8BZiSx74/AYW+z2QqgNWrXcLfs8f1stetW6gjMqYiWrFz5862devW3WuJv3TIysqSnTt31gZW5LVNIEl/m9dRzgfAZyKymxz35o0pMYsWuV72Kld2vex16hTqiIypkDIzMwcnJye/lJyc3J7Amn+b4MsCVmRmZg7Oa4MCk76qXuk9fEBE5gO1gU+LJz5jCuGTT1wvezExrpe95s1DHZExFVZ8fPwfQO9Qx2EKJ78Bd3IbAekX728kUOT2lcYU2ptvwk03Qfv2rkjfOt0xxphCy+9Kfwmuz/vcqkMrrgMdY4Jv4kS46y537/6DD6BWQf1CGWOMyU1+A+40LclAjDmGKowaBY8/7mrnv/kmROTarbYxxpgA5Fe839qrqX9abutVtfT0cWrKn8xMGDIEXn0Vhg2DKVNKXS97xhhT1uRXvD8S16f9U7msU6B7UCIy5sABuOYa+OgjGDvWTdbpjjHGHLf8iveHen+tEbQpOSkp0Ls3fPstPPcc3HprqCMyxphyo8AmeyISDlwONPHfXlUnBi8sUyFt2wY9e8L69fDuu655njHGmGITSOc8/wMO4prr5dm1nzHHZc0a18ve7t2uPX53u3tkjDHFLZCk31BVOwQ9ElNxff+962UvPBwSE+G0XOuOGmOMOU6BdJ34iYhcHPRITMU0d667qq9dG775xhK+McYEUSBJfxHwvoiki0iqiOwTkdRgB2YqgOnToVcvaNnSJfwWLUIdkTHGlGuBJP2ngLOA6qpaS1Vrqqp1iWaOz6RJcN11cM45buCcmJhQR2SMMeVeIEl/PbDCb5x7Y4pOFe69F+68E666yvWjX7t2qKMyxpgKIZCKfElAooh8AhzyLbQme6bQMjPhlltg2jQYOtS1w7de9owxpsQEkvQ3elMVbzKm8NLTYcAAmD0bxoyBBx6wXvaMMaaEFZj0VfXBkgjElGO7d7te9r75xvWh///+X6gjMsaYCim/AXcmqeodIvI/XF/7R1HV3kGNzJQP27e7XvbWroUZM+Dqq0MdkTHGVFj5Xem/4f19sqgHF5GewGQgHHhJVSfkWN8V+BB3+wBglqqO81sfDiwGtqtqr6LGYUJk7VrXy96uXa6XvQsvDHVExhhToeU34M4S7+8C3zIRqQM0UtWfCzqwl7CfBS4CtgE/ishsVV2VY9Ov8knoI4DVgDURLGt+/BEuu8zdt09MhPj4UEdkjDEVXoFN9kQkUURqiUgUsBx4RUQCqbnfBdigqr+pagYwA+gTaGAi0hA30M9Lge5jSol586BbN4iMdPfxLeEbY0ypIAU1vxeRZaraSUQG467yx4rIzwX1xy8i/YCeqjrYm78eOENVh/tt0xWYiSsJ2AH8U1VXeuveAx4FanrLcy0NEJGhwFCAevXqxc+YMSOAl32stLQ0IiMji7RvMJW1uE764gtaP/ooBxo35ufHHyfjxBNLRVyhZnEVjsVVOMcTV7du3ZaoaudiDsmUVqqa74QbXa8+MA843Vv2cwD79cfdx/fNXw/8J8c2tYBI7/FlwHrvcS/gOe9xV+Cjgp5PVYmPj9eimj9/fpH3DaYyFdfkyaqgev75qnv2lHhMqmXs/SoFLK7CKY9xAYs1gN9Xm8rHFEiPfOOAubii+h9FpBmul76CbAMa+c03xF3N+59wpKpqmvd4DlBZRKKBc4DeIrIJd1ugu4i8GcBzmlBQhdGjYcQI+Nvf3CA61sueMcaUOgUmfVX9r6p2UNXbvPnfVLVvAMf+EWgpIk1FpAowAJjtv4GIxIi4HlpEpIsXzy5VvVdVG6pqE2+/L1X1ukK9MlMyMjNhyBB45BH397//hYiIUEdljDEmF4H0yFckqpopIsNxpQThwDRVXSkiw7z1CUA/4FYRyQTSgQGqan38lxXp6fD3v8OHH8L998O4cdbLnjHGlGJBS/rwV5H9nBzLEvweTwGmFHCMRCAxCOGZ41ApLc21wf/6a3jmGbj99lCHZIwxpgBBTfqmnNqxg1NHjICtW+Htt+Gaa0IdkTHGmADk1w3vyPx2VBtlr2Jatw4uuYSI33+HOXOgR49QR2SMMSZA+V3p1/T+ngycTnYlvCuAhcEMypRSixfDpZeCCMuffpp4S/jGGFOm5NcN74MAIjIPOE1V93nzDwD/LZHoTOnx2Wdw1VVw4okwbx77duwoeB9jjDGlSiDt9OOADL/5DKBJUKIxpdOMGXD55dC0KXz7LbRqFeqIjDHGFEEgFfneAH4QkfdxQ+xeCbwW1KhM6fGf/7hOd849F2bPhhNOfddRrAAAFDJJREFUCHVExhhjiqjApK+q40XkE+A8b9FNqrosuGGZkFOFMWPg4YehTx9XS79atVBHZYwx5jjkm/RFJAzXz357YGnJhGRCLjMTbrsNpk6Fm2+GhASoZK07jTGmrMv3nr6qZgHLRSSuhOIxoXbwIPTv7xL+6NHuryV8Y4wpFwL5Na8PrBSRH4D9voWq2jtoUZnQ2LPHFeUvXGi97BljTDkUSNJ/MOhRmNBLSoKePWH1anjrLdenvjHGmHIlkIp8C0SkHq6DHoAfVPWP4IZlStT69a4f/T/+gI8+gosvDnVExhhjgqDAdvoicjXwA9AfuBr4XkT6BTswU0KWLIFzzoF9+2D+fEv4xhhTjgVSvD8aON13dS8idYHPgfeCGZgpAZ9/Dlde6XrZmzsXTj451BEZY4wJokB65AvLUZy/K8D9TGn27rtw2WXQpInrZc8SvjHGlHuBXOl/KiJzgbe9+WuAOcELyQTds8+6mvnnnON62atTJ9QRGWOMKQGBVOS7W0T6AucAAryoqu8HPTJT/FRh7Fh46CHo3dv1qW+97BljTIWRZ9IXkTuAb4BlqjoTmFliUZnid+SI62XvxRdh0CB44QXrdMcYYyqY/H71GwKTgdYi8jPwLe4k4DtVTSmJ4EwxOXgQBg6EWbPg3nth/HgQCXVUxhhjSlieFfJU9Z+qejYQA9wHpACDgBUisiqQg4tITxFZKyIbRGRULuu7isheEfnJm8Z4yxuJyHwRWS0iK0VkRJFenYG9e12nO7NmwaRJ8MgjlvCNMaaCCqR8txpQC6jtTTuAXwraSUTCgWeBi4BtwI8iMltVc54wfKWqvXIsywTuUtWlIlITWCIin+Wyr8lPUhJceimsXAnTp8O114Y6ImOMMSGU3z39F4F2wD7ge1zx/kRV3R3gsbsAG1T1N+94M4A+QIGJW1WTgCTv8T4RWQ00CGRf49mwwXW04+tl75JLQh2RMcaYEBNVzX2FyKdANLACl/C/A1ZoXjscu38/oKeqDvbmrwfOUNXhftt0xVUQ3IYrQfinqq7McZwmwEKgvaqm5vI8Q4GhAPXq1YufMWNGIOEdIy0tjcjIyCLtG0xFiSty3To6jBqFHDnCzxMmsK9Nm1IRV0mwuArH4iqc8hhXt27dlqhq52IOyZRWqprnhGui1x6XVF8FFgPzgAfz28/btz/wkt/89cB/cmxTC4j0Hl8GrM+xPhJYAlxV0POpKvHx8VpU8+fPL/K+wVTouL74QrVmTdW4ONXVq4MSk2o5er9KiMVVOBZX4RxPXMBiDeD31abyMeXbs573P7EC1xnPJ7ja+82BQCrWbQMa+c03xF3N+x8/VVXTvMdzgMoiEg0gIpVxpQDTVXVWAM9n3nvP3cOPi3O97LVuHeqIjDHGlCJ5Jn0R+YeIzBCRrbji9V7AWuAqICqAY/8ItBSRpiJSBRgAzM7xHDEiriq5iHTx4tnlLXsZWK2qE4vwuiqe55+Hq6+G00+Hr76CBg1CHZExxphSJr/a+01wg+rcqa5iXaGoaqaIDAfmAuHANFVdKSLDvPUJQD/gVhHJBNKBAaqqInIu7nbALyLyk3fI+7zSAONPFR580E29esE770D16qGOyhhjTCmUZ9JX1ZHHe3AvSc/JsSzB7/EUYEou+32Nq09g8nPkCAwfDgkJcNNNrrc962XPGGNMHmy0vLLq4EG45hqX8O+5B15+2RK+McaYfFmWKItSU6FPH0hMhIkT4c47Qx2RMcaYMsCSflmTnOxq6K9YAW+8AdddF+qIjDHGlBGW9MuSX391vewlJ8P//uf61DfGGGMCZEm/rFi2zF3hZ2bCl1/CGWeEOiJjjDFljFXkKwvmz4cLLoAqVeDrry3hG2OMKRJL+qVc9IIFrhi/USPrZc8YY8xxsaRfmiUk0O7BB6FzZ9fL3v9v796DrSrvM45/HxGrgDUqLaZekKiZRlpvXFRMFdqqBM0oiUxARJOJonbEaKLW6gztJHWsUWYyMTqUEo1OiNQYJYwx9YKIWscbCIiJJkgoJTjeYsUTEAR+/eNdR7fHc1n7cNZe+/J8Zvaw91rrXfs5a97ht9faa7/vAQeUncjMzBqYi349ah9l7+KL+cOxx8LDD8M+eUY+NjMz65pv5Ks327fDpZfCrbfCeeex6pxzOMnD6pqZWR/wmX492bIFpkxJBf+qq+D22wmPsmdmZn3EFaVebNwIEyemn+PddBN861tlJzIzsybjol8PXn8dJkyAlSvhzjth2rSyE5mZWRNy0S/bmjVplL0NG2DhwjQAj5mZWQFc9Mu0YkX6Df7Wremy/nHHlZ3IzMyamG/kK8uSJXDiiWk63CefdME3M7PCueiX4d574dRTYf/90yh7n/tc2YnMzKwFuOjX2pw5MGkSHH10GmXvwAPLTmRmZi3CRb9WIuA734ELL0zf4z/yCOy7b9mpzMyshRRa9CWNl/SKpNWSru5k/VhJ70panj1m5m3bULZvhxkzYOZMOPdcWLAABg4sO5WZmbWYwu7el9QPuAU4GVgPPCdpYUT8qsOmT0TE6b1sW/+2bEmF/u674Yor4IYbYBdfYDEzs9orsvqMBlZHxJqI2ArMB86oQdv68d57cNppqeDfeGN6uOCbmVlJFBHF7Fg6CxgfEednr6cBx0bEJRXbjAV+Rjqb3wBcEREv5WlbsY/pwHSAIUOGjJg/f36v8ra1tTFo0KBete1M/3fe4Yirr2bQ6tW8fNVVvH7qqXWRq684V3WcqzrOVZ2dyTVu3LilETGyjyNZvYqIQh7AJGBuxetpwM0dtvlTYFD2fALw27xtO3uMGDEiemvx4sW9bvsJa9ZEHHpoxB57RNx//07tqk9z9SHnqo5zVce5qrMzuYDno6A64Ef9PYq81rweqPw92gGks/kPRcTGiGjLnj8A9Jc0OE/burViBYwZA2+/DYsWpcv7ZmZmdaDIov8ccJikYZJ2AyYDCys3kLSfJGXPR2d53s7Tti49/ngaZa9fv/Qb/OOPLzuRmZnZhwq7ez8itkm6BHgQ6AfcFun7+ouy9bOBs4CLJW0DNgOTIyKATtsWlbVPLFgAkyfDsGHw4INw0EFlJzIzM/uYQifcyS7ZP9Bh2eyK5z8AfpC3bd2aOzcNujNqFPziFx50x8zM6pJ/P7YzIuC66+CCC9JY+osWueCbmVnd8tS6vbVjB1x2Gdx8M5xzDtx2G/TvX3YqMzOzLvlMvze2boWpU1PB/+Y34Y47XPDNzKzu+Uy/Wu+9B1/+Mjz8MHz3u3DllWUnMjMzy8VFvxpvvgkTJsALL8Dtt8NXv1p2IjMzs9xc9PNauxZOOQXWr08/zzv99B6bmJmZ1RMX/TxWroTx42HzZnjkkTTinpmZWYPxjXw9eeKJNMreLrvAk0+64JuZWcNy0e/OwoXpkv5++8FTT8Hw4WUnMjMz6zUX/a788IcwcSIccUQ6w/ewumZm1uBc9DuKgOuvh/PPh5NPhkcfhcGDy05lZma201z0K+3YAZdfDtdcA2efnS7vDxxYdiozM7M+4bv3582Da6/lpHXrYI89YNOmNLzurFnp5j0zM7Mm0dpFf948mD4dNm1CkAp+//4wcqQLvpmZNZ3WrmzXXpsKfaUPPkjLzczMmkxrF/1166pbbmZm1sBau+h39TM8/zzPzMyaUGsX/euugwEDPr5swIC03MzMrMkUWvQljZf0iqTVkq7uZrtRkrZLOqti2eWSXpK0StJdknbv84BTp8KcOTB0KCHB0KHp9dSpff5WZmZmZSus6EvqB9wCfAE4HJgi6fAutrsBeLBi2f7ApcDIiPgroB8wuZCgU6fC2rUsefTRNJOeC76ZmTWpIs/0RwOrI2JNRGwF5gNndLLdDOBnwBsdlu8K7CFpV2AAsKHArGZmZk2vyKK/P/C/Fa/XZ8s+lJ3RTwRmVy6PiN8DNwHrgNeAdyPioQKzmpmZNT1FRDE7liYBp0bE+dnracDoiJhRsc1PgVkR8bSkHwH3R8Q9kvYmnf1/Bfg/4KfAPRHx407eZzowHWDIkCEj5s+f36u8bW1tDBo0qFdti+Rc1XGu6jhXdZox17hx45ZGxMg+jmR1qsgR+dYDB1a8PoBPXqIfCcyXBDAYmCBpG9Af+F1EvAkg6V5gDPCJoh8Rc4A5ACNHjoyxY8f2Kuxjjz1Gb9sWybmq41zVca7qOJc1uiKL/nPAYZKGAb8n3Yh3duUGETGs/XnFmf4CSccCx0kaAGwG/g54vsCsZmZmTa+woh8R2yRdQrorvx9wW0S8JOmibP3sbto+I+keYBmwDXiB7Gy+O0uXLn1L0v/0MvJg4K1eti2Sc1XHuarjXNVpxlxD+zKI1bfCvtNvNJKer8fvtZyrOs5VHeeqjnNZo2vtEfnMzMxaiIu+mZlZi3DR/0iP9wyUxLmq41zVca7qOJc1NH+nb2Zm1iJ8pm9mZtYiXPTNzMxaRNMX/Z6m91Xy/Wz9SknH5G1bcK6pWZ6Vkp6SdGTFurWSXpS0XFKfDlqUI9dYSe9m771c0sy8bQvOdWVFplXZVM37ZOuKPF63SXpD0qou1pfVv3rKVVb/6ilXWf2rp1xl9a8DJS2W9Gulqca/0ck2pfQxa1AR0bQP0qBArwKfAXYDVgCHd9hmAvBLQMBxwDN52xacawywd/b8C+25stdrgcElHa+xpJETq25bZK4O238ReLTo45Xt+0TgGGBVF+tr3r9y5qp5/8qZq+b9K0+uEvvXp4Fjsud7Ar+ph//D/GjcR7Of6eeZ3vcM4M5IngY+JenTOdsWlisinoqId7KXT5PmLijazvzNpR6vDqYAd/XRe3crIh4H/tDNJmX0rx5zldS/8hyvrpR6vDqoZf96LSKWZc/fA35Nh9lKKamPWWNq9qLf4/S+3WyTp22RuSp9nfRJvl0AD0laqjTLYF/Jm+t4SSsk/VLS8CrbFpkLpfkaxpNmaWxX1PHKo4z+Va1a9a+8at2/ciuzf0k6GDgaeKbDqkboY1Ynipxwpx6ok2Udf6PY1TZ52vZW7n1LGkf6T/nzFYtPiIgNkv4ceFjSy9mZSi1yLQOGRkSbpAnAAuCwnG2LzNXui8B/R0TlWVtRxyuPMvpXbjXuX3mU0b+qUUr/kjSI9EHjsojY2HF1J03qpo9ZfWn2M/080/t2tU2etkXmQtIRwFzgjIh4u315RGzI/n0DuI90Ga8muSJiY0S0Zc8fAPpLGpynbZG5Kkymw6XXAo9XHmX0r1xK6F89Kql/VaPm/UtSf1LBnxcR93aySd32MatDZd9UUOSDdCVjDTCMj25kGd5hm9P4+E0wz+ZtW3Cug4DVwJgOywcCe1Y8fwoYX8Nc+/HRoE6jgXXZsSv1eGXb7UX6XnZgLY5XxXscTNc3ptW8f+XMVfP+lTNXzftXnlxl9a/sb78T+F4325TWx/xovEdTX96PfNP7PkC6+3U1sAn4Wndta5hrJrAvcKskgG2RZtEaAtyXLdsV+ElE/FcNc50FXCxpG7AZmBwRAZR9vAAmAg9FxB8rmhd2vAAk3UW643ywpPXAPwP9K3LVvH/lzFXz/pUzV837V85cUEL/Ak4ApgEvSlqeLbuG9KGt1D5mjcnD8JqZmbWIZv9O38zMzDIu+mZmZi3CRd/MzKxFuOibmZm1CBd9MzOzFuGibw1HUkiaVfH6Ckn/0kf7/pGks/piXz28z6Rs5rTFHZYfLGlzxYxuyyWd24fvO1bS/X21PzNrLE39O31rWluAL0m6PiLeKjtMO0n9ImJ7zs2/DvxDRCzuZN2rEXFUH0YzMwN8pm+NaRswB7i844qOZ+qS2rJ/x0paIuluSb+R9G9Kc8o/m82FfkjFbv5e0hPZdqdn7ftJulHSc9mc5RdW7HexpJ8AL3aSZ0q2/1WSbsiWzSSNdT9b0o15/2hJbZJmSVomaZGkP8uWHyXp6SzXfZL2zpYfKumRbPKaZRV/4yBJ90h6WdI8ZSPLZMfkV9l+bsqby8wah4u+NapbgKmS9qqizZHAN4C/Jo1y9tmIGE0af35GxXYHAyeRhjedLWl30pn5uxExChgFXCBpWLb9aODaiDi88s0k/QVwA/C3wFHAKElnRsS3geeBqRFxZSc5D+lwef9vsuUDgWURcQywhDRqHKRhWv8xIo4gffBoXz4PuCUijgTGAK9ly48GLgMOJ821foKkfUgjzg3P9vOvPR1MM2s8LvrWkCLNNHYncGkVzZ6LND/5FuBV4KFs+YukQt/u7ojYERG/JY1d/pfAKcC52VCoz5CGsD0s2/7ZiPhdJ+83CngsIt6MiG2kInxijpyvRsRRFY8nsuU7gP/Mnv8Y+Hz2oedTEbEkW34HcKKkPYH9I+I+gIh4PyI2VeRdHxE7gOXZ374ReB+YK+lLpOFczazJuOhbI/se6Qx8YMWybWT9OrtsvVvFui0Vz3dUvN7Bx+9v6Tg2dfs0pTMqCvGwiGj/0PBHOtfZ1KZ9qbsxtLt778rjsB3YNftQMpo0m9uZQF+OH29mdcJF3xpWpDnN7yYV/nZrgRHZ8zPIJk2p0iRJu2TfgX8GeIU0acnF2TSnSPqspIHd7YR0ReAkSYMl9QOmkC7L99YupAlpAM4GnoyId4F3Kr4CmAYsya6ErJd0Zpb3TyQN6GrHSvO17xVpOtvLSF9HmFmT8d371uhmAZdUvP4P4OeSngUW0fVZeHdeIRXnIcBFEfG+pLmky+DLsisIb5LOiLsUEa9J+idgMenM+4GI+HmO9z+kYkY1SLOjfZ/0twyXtBR4F/hKtv480r0HA0hfR3wtWz4N+HdJ3wY+ACZ18557ko7b7lnWT9wkaWaNz7PsmTUISW0RMajsHGbWuHx538zMrEX4TN/MzKxF+EzfzMysRbjom5mZtQgXfTMzsxbhom9mZtYiXPTNzMxaxP8DxdOv63ngfJsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Word similarity score')\n",
    "plt.title('Convergence Time According to the choosen Optimizer')\n",
    "# red dashes, blue squares and green triangles\n",
    "plt.plot(mean_list_sgd_shuffle, 'bo--',label='sgd_shuffle')\n",
    "plt.plot(mean_list_sgd , 'bo-',label='sgd')\n",
    "plt.plot(mean_list_adam_shuffle,'ro--',label='adam_shuffle')\n",
    "plt.plot(mean_list_adam,'ro-',label='adam')\n",
    "#plt.plot(mean_list_gensim,'go-',label='Gensim')\n",
    "plt.grid(True)\n",
    "plt.legend(loc=(1.04,0.5))\n",
    "plt.savefig('comparison.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
