
\section{Conclusion}\label{sec:conclusion}

This work provides an overview of the Skip Gram Model with negative Sampling (SGNS) and the numerous successful attempts of optimizing the throughput of the model. As this is the case, no effort went into optimizng the convergence time of the SGNS, therefore this work focused on the convergence time. We decided to use advanced optimizers, input shuffling and a batched approach with specific rules for the batch creation to achieve a better convergence time. We propose a batched version of the SGNS, where the idea is to compute the loss over the sum of a high number of training samples,  instead of computing it for each individually. The quality of each individual batch is hindered by words appearing multiple time in a batch, we therefore decided to create batches where this would not be the case. Furthermore we  decided to cut the dataset size by deleting each word that appears more often than the 99 percentile, this technique maintained the quality of the dataset, while drastically improving the computation time. We used the text8 dataset to train our model and  word similarity as a quality measure for the word embeddings (WE).
To compare our work, Gensim was used, which holds a state of the art implementation of the SGNS. We did achieve a better convergence time than Gensim with Adam as an optimizer and the use of input shuffling. Gensim convereged in 4 epochs to a word similarity of 0.66 and our model only took 2 epochs to achieve the same quality. The latter model was improved by deleting each  word that appears more often than the 99 percentile and using batches where words only appear once. Those results still need to be confirmed with more datasets. Finally, if this work would be combined with an optimized throughput it  could improve the state of the art run time of the SGNS.